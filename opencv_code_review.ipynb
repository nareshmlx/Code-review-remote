{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3f2428-21d6-4c8c-b383-51c769eac5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6933b6a6-9381-4b76-a478-3b78180e6439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10e4d51-0e48-4fb2-a4c5-c5ad9249d827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU: NVIDIA RTX A6000\n",
      "GPU Memory: 50.91 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457f935f-a7e0-4236-9048-f3e94b2d48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.55.4\n",
    "!pip install --no-deps trl==0.22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b80b7b-bd96-4d6c-8eb7-89f34c7e3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: unsloth 2025.10.1\n",
      "Uninstalling unsloth-2025.10.1:\n",
      "  Successfully uninstalled unsloth-2025.10.1\n",
      "Found existing installation: unsloth_zoo 2025.10.1\n",
      "Uninstalling unsloth_zoo-2025.10.1:\n",
      "  Successfully uninstalled unsloth_zoo-2025.10.1\n",
      "Found existing installation: torchao 0.12.0\n",
      "Uninstalling torchao-0.12.0:\n",
      "  Successfully uninstalled torchao-0.12.0\n",
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-tocbcqd_/unsloth_8c1595742a0a413f99c7fa2eef5799e3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-tocbcqd_/unsloth_8c1595742a0a413f99c7fa2eef5799e3\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit aa5832de9282987ae6221dfac1877d23d64cad9a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.48.1)\n",
      "Requirement already satisfied: torch<3,>=2.3 in ./unsloth_env/lib/python3.12/site-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./unsloth_env/lib/python3.12/site-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.9 in ./unsloth_env/lib/python3.12/site-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n",
      "Requirement already satisfied: filelock in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n",
      "Requirement already satisfied: networkx in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
      "Requirement already satisfied: setuptools in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./unsloth_env/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./unsloth_env/lib/python3.12/site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./unsloth_env/lib/python3.12/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.1.5)\n",
      "Collecting xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.28.post2-cp312-cp312-manylinux_2_28_x86_64.whl (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.28.post2-cp312-cp312-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ninja in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.13.0)\n",
      "Requirement already satisfied: flash-attn>=2.6.3 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.8.3)\n",
      "Requirement already satisfied: einops in ./unsloth_env/lib/python3.12/site-packages (from flash-attn>=2.6.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.8.1)\n",
      "Collecting unsloth_zoo>=2025.10.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading unsloth_zoo-2025.10.1-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: wheel>=0.42.0 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
      "Requirement already satisfied: torchvision in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.20.0)\n",
      "Requirement already satisfied: tqdm in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (7.1.0)\n",
      "Requirement already satisfied: tyro in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.9.33)\n",
      "Requirement already satisfied: protobuf in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.32.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,>=3.4.1 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.10.1)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.17.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.35.3)\n",
      "Requirement already satisfied: hf_transfer in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
      "Requirement already satisfied: diffusers in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.35.1)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.55.4)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.23.0,>=0.7.9 in ./unsloth_env/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./unsloth_env/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./unsloth_env/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.9.18)\n",
      "Requirement already satisfied: requests in ./unsloth_env/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./unsloth_env/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./unsloth_env/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./unsloth_env/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.1.10)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./unsloth_env/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./unsloth_env/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./unsloth_env/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.3.3)\n",
      "Requirement already satisfied: xxhash in ./unsloth_env/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./unsloth_env/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./unsloth_env/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.13.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./unsloth_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./unsloth_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./unsloth_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./unsloth_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./unsloth_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./unsloth_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./unsloth_env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./unsloth_env/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./unsloth_env/lib/python3.12/site-packages (from requests->transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./unsloth_env/lib/python3.12/site-packages (from requests->transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./unsloth_env/lib/python3.12/site-packages (from requests->transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.10.5)\n",
      "Collecting torchao (from unsloth_zoo>=2025.10.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading torchao-0.13.0-1-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: cut_cross_entropy in ./unsloth_env/lib/python3.12/site-packages (from unsloth_zoo>=2025.10.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (25.1.1)\n",
      "Requirement already satisfied: pillow in ./unsloth_env/lib/python3.12/site-packages (from unsloth_zoo>=2025.10.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (11.0.0)\n",
      "Requirement already satisfied: msgspec in ./unsloth_env/lib/python3.12/site-packages (from unsloth_zoo>=2025.10.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.19.0)\n",
      "Requirement already satisfied: importlib_metadata in ./unsloth_env/lib/python3.12/site-packages (from diffusers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./unsloth_env/lib/python3.12/site-packages (from importlib_metadata->diffusers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./unsloth_env/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./unsloth_env/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./unsloth_env/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./unsloth_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in ./unsloth_env/lib/python3.12/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in ./unsloth_env/lib/python3.12/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (14.2.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in ./unsloth_env/lib/python3.12/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in ./unsloth_env/lib/python3.12/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./unsloth_env/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./unsloth_env/lib/python3.12/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./unsloth_env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-ampere-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Downloading unsloth_zoo-2025.10.1-py3-none-any.whl (257 kB)\n",
      "Downloading torchao-0.13.0-1-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unsloth: filename=unsloth-2025.10.1-py3-none-any.whl size=318002 sha256=251ace0af7509c6c0e1c022e321ee5d0c5570bf119b347a4eec4ee1339988612\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ytjhp904/wheels/60/3e/1f/e576c07051d90cf64b6a41434d87ccf4db33fafd5343bf5de0\n",
      "Successfully built unsloth\n",
      "Installing collected packages: torchao, unsloth, unsloth_zoo\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [unsloth_zoo]\u001b[0m [unsloth_zoo]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torchao-0.13.0 unsloth-2025.10.1 unsloth_zoo-2025.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y unsloth unsloth-zoo torchao\n",
    "!pip install --upgrade --no-cache-dir \"unsloth[cu121-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8522967e-2ee5-408f-a335-aec5e6051be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchao 0.13.0\n",
      "Uninstalling torchao-0.13.0:\n",
      "  Successfully uninstalled torchao-0.13.0\n",
      "Collecting torchao==0.12.0\n",
      "  Using cached torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Using cached torchao-0.12.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "Installing collected packages: torchao\n",
      "Successfully installed torchao-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torchao\n",
    "!pip install torchao==0.12.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5abb16-1962-4a0e-b3f6-d5f2a9ba122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "‚úì Unsloth imported successfully!\n",
      "PyTorch: 2.5.0+cu124\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "print(f\"‚úì Unsloth imported successfully!\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268c46e4-2c5c-4cec-b965-39d58a4b354f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.10.1: Fast Qwen2 patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post2. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 16384 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "\n",
    "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
    "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "qwen_models = [\n",
    "    \"unsloth/Qwen2.5-Coder-32B-Instruct\",      # Qwen 2.5 Coder 2x faster\n",
    "    \"unsloth/Qwen2.5-Coder-7B\",\n",
    "    \"unsloth/Qwen2.5-14B-Instruct\",            # 14B fits in a 16GB card\n",
    "    \"unsloth/Qwen2.5-7B\",\n",
    "    \"unsloth/Qwen2.5-72B-Instruct\",            # 72B fits in a 48GB card\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-Coder-7B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f19af5e-b82e-4f23-aadc-e6436f6a4f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.10.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dcc3ac3-10f9-43da-9cf4-3f9de1673257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"qwen-2.5\",\n",
    ")\n",
    "\n",
    "def alpaca_to_conversations(example):\n",
    "    if example[\"input\"].strip():\n",
    "        user_prompt = f\"{example['instruction']}\\n\\nInput:\\n{example['input']}\"\n",
    "    else:\n",
    "        user_prompt = example[\"instruction\"]\n",
    "\n",
    "    return {\n",
    "        \"conversations\": [\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"nareshmlx/16k_opencvpr\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84587615-d3d9-444b-b9d7-b17dcd16e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "dataset = standardize_sharegpt(dataset)\n",
    "dataset = dataset.map(alpaca_to_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50840f0f-68c2-4091-bcd9-c6d24d20cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpaca_to_conversations(batch):\n",
    "    conversations = []\n",
    "    for instr, inp, out in zip(batch[\"instruction\"], batch[\"input\"], batch[\"output\"]):\n",
    "        if inp.strip():\n",
    "            user_msg = f\"{instr}\\n\\nHere is the code:\\n{inp}\"\n",
    "        else:\n",
    "            user_msg = instr\n",
    "\n",
    "        conversations.append([\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "            {\"role\": \"assistant\", \"content\": out}\n",
    "        ])\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "dataset = dataset.map(\n",
    "    alpaca_to_conversations,\n",
    "    batched=True,\n",
    "    remove_columns=[\"instruction\", \"input\", \"output\"]\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            convo,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        for convo in examples[\"conversations\"]\n",
    "    ]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7865f30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.55.4\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /root/opencv_code_review/unsloth_env/lib/python3.12/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: peft, trl, unsloth_zoo\n",
      "---\n",
      "Name: trl\n",
      "Version: 0.22.2\n",
      "Summary: Train transformer language models with reinforcement learning.\n",
      "Home-page: https://github.com/huggingface/trl\n",
      "Author: Leandro von Werra\n",
      "Author-email: leandro.vonwerra@gmail.com\n",
      "License: \n",
      "Location: /root/opencv_code_review/unsloth_env/lib/python3.12/site-packages\n",
      "Requires: accelerate, datasets, transformers\n",
      "Required-by: unsloth_zoo\n",
      "---\n",
      "Name: unsloth\n",
      "Version: 2025.10.1\n",
      "Summary: 2-5X faster training, reinforcement learning & finetuning\n",
      "Home-page: http://www.unsloth.ai\n",
      "Author: Unsloth AI team\n",
      "Author-email: info@unsloth.ai\n",
      "License-Expression: Apache-2.0\n",
      "Location: /root/opencv_code_review/unsloth_env/lib/python3.12/site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "peft                      0.17.1\n",
      "transformers              4.55.4\n",
      "trl                       0.22.2\n",
      "unsloth                   2025.10.1\n",
      "unsloth_zoo               2025.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip show transformers trl unsloth\n",
    "!pip list | grep -E \"transformers|trl|unsloth|peft\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85533682-a7b3-4bd7-b884-48bb8605889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '# OpenCV Expert Code Reviewer\\n\\nYou are a **world-class expert code reviewer** for the OpenCV computer vision library. Your mission is to conduct thorough, actionable reviews that maintain OpenCV\\'s high standards.\\n\\n## üéØ **Core Objectives**\\n1. **Improve code health** - Every change should enhance the codebase\\n2. **Maintain OpenCV standards** - Enforce C++11 compliance and cross-platform compatibility  \\n3. **Provide actionable feedback** - Specific, educational comments with clear paths forward\\n4. **Balance quality with progress** - Approve improvements even if not perfect\\n\\n## üîç **Systematic Review Checklist**\\n\\n**1. Code Logic & Functionality**\\n-  Verify correctness and algorithm efficiency\\n-  Handle edge cases (empty Mat, null pointers, boundaries)\\n-  Check OpenCV-specific patterns (Mat operations, empty() checks)\\n\\n**2. Error Handling & Safety** \\n-  Use CV_Assert() for preconditions, cv::Exception for errors\\n-  Validate inputs early, check null pointers\\n-  Follow RAII principles for resource management\\n\\n**3. Code Quality & Design**\\n-  Follow OpenCV naming: camelCase functions, PascalCase classes, UPPER_CASE constants\\n-  Use cv::Ptr<> for complex objects, avoid raw pointers\\n-  Maintain API consistency (input, output, optional parameter order)\\n\\n**4. Performance & Memory**\\n-  Minimize unnecessary allocations, prefer in-place operations\\n-  Leverage SIMD/vectorization opportunities where applicable\\n-  Ensure proper memory alignment and efficient Mat handling\\n\\n**5. Documentation & Testing**\\n-  Include Doxygen documentation (@param, @return, @brief)\\n-  Provide clear usage examples for complex functions\\n-  Ensure adequate test coverage using GTest framework\\n\\n## üí¨ **Structured Feedback Format**\\n\\nUse **Conventional Comments** structure:\\n- `issue (blocking):` - Critical problems requiring fixes\\n- `suggestion (non-blocking):` - Improvements to consider\\n- `praise:` - Acknowledge good practices\\n- `question:` - Request clarification\\n- `nitpick (non-blocking):` - Minor style preferences\\n\\n## üìã **Review Output Structure**\\n```markdown\\n## Code Review Summary\\n**Overall Assessment**: [APPROVE/REQUEST_CHANGES/COMMENT]\\n**Priority**: [HIGH/MEDIUM/LOW]\\n**Focus Areas**: [Primary review categories]\\n\\n## Critical Issues (Blocking)\\n[Problems that must be fixed]\\n\\n## Suggestions for Improvement  \\n[Non-blocking enhancements with specific recommendations]\\n\\n## Positive Aspects\\n[Good practices and well-written code acknowledgment]\\n```\\n\\n\\n## üîí **Security Expert Specialization**\\n\\n**Your specialized focus:**\\n- **Input Validation**: Check for null pointers, empty Mat, invalid sizes/parameters\\n- **Memory Safety**: Buffer overflows, uninitialized memory, proper bounds checking\\n- **Resource Management**: Memory leaks, double-free issues, exception safety\\n- **Thread Safety**: Race conditions, synchronization, deadlock prevention\\n\\n**Key Areas to Scrutinize:**\\n- Potential security vulnerabilities and stability issues\\n- Proper error handling using CV_Assert and cv::Exception\\n- Memory allocation patterns and cleanup procedures\\n- Thread safety in multi-threaded contexts\\n- Input sanitization and validation completeness\\n\\n## üìã **Your Specific Task**\\n\\nReview the following code change and provide feedback on the specific line indicated. Consider code quality, best practices, API design, and potential improvements.\\n\\n---\\n\\n**Remember**: Focus on your area of expertise while maintaining the systematic review approach. Provide specific, actionable feedback that helps improve the OpenCV codebase.\\n\\nHere is the code:\\n{\\n  \"pr_title\": \"\\\\ud83d\\\\udc1b Fix: pyrUp throws allocation error for oversized matrix requests\",\\n  \"pr_description\": \"This PR ensures `cv::pyrUp` raises an allocation error when attempting to create a matrix larger than supported, preventing silent crashes or overflows.\",\\n  \"file_path\": \"modules/imgproc/src/pyramids.cpp\",\\n  \"language\": \"cpp\",\\n  \"full_diff\": \"diff --git a/GAPI_CUSTOM_STREAM_DESIGN.md b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\nnew file mode 100644\\\\nindex 000000000000..d95498075959\\\\n--- /dev/null\\\\n+++ b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\n@@ -0,0 +1,268 @@\\\\n+# G-API Custom Stream Sources in Python - Design Document\\\\n+\\\\n+## Issue #27276: Add support for custom stream sources in Python for G-API\\\\n+\\\\n+### Problem Statement\\\\n+\\\\n+Currently, OpenCV G-API supports custom stream sources in C++ through the `IStreamSource` interface, but Python users are limited to predefined sources like:\\\\n+- `cv.gapi.wip.make_capture_src()` for video files/cameras\\\\n+- `QueueSource` for programmatic data feeding\\\\n+\\\\n+There\\'s no straightforward way for Python developers to create custom streaming sources for scenarios like:\\\\n+- Custom hardware device interfaces\\\\n+- Network streaming protocols\\\\n+- Database-backed data streams  \\\\n+- Real-time sensor data\\\\n+- Custom data transformations/generators\\\\n+\\\\n+### Current Architecture\\\\n+\\\\n+```cpp\\\\n+// C++ IStreamSource interface\\\\n+class IStreamSource: public std::enable_shared_from_this<IStreamSource>\\\\n+{\\\\n+public:\\\\n+    using Ptr = std::shared_ptr<IStreamSource>;\\\\n+    virtual bool pull(Data &data) = 0;\\\\n+    virtual GMetaArg descr_of() const = 0;\\\\n+    virtual void halt() = 0;\\\\n+    virtual ~IStreamSource() = default;\\\\n+};\\\\n+```\\\\n+\\\\n+Python currently only exposes:\\\\n+```python\\\\n+# Existing Python sources\\\\n+source = cv.gapi.wip.make_capture_src(path)  # VideoCapture wrapper\\\\n+# Limited to predefined implementations\\\\n+```\\\\n+\\\\n+### Proposed Solution\\\\n+\\\\n+#### 1. Python Stream Source Interface\\\\n+\\\\n+Create a Python-friendly interface that matches the C++ `IStreamSource` pattern:\\\\n+\\\\n+```python\\\\n+class PyStreamSource:\\\\n+    \\\\\"\\\\\"\\\\\"Base class for custom Python stream sources.\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def pull(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull next data item from stream.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success: bool, data: Any) where data can be:\\\\n+                   - cv.Mat for image streams\\\\n+                   - tuple of values for multi-input streams\\\\n+                   - None if stream ended\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of stream output.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output type\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"Stop the stream source (optional override).\\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+```\\\\n+\\\\n+#### 2. C++ Bridge Implementation\\\\n+\\\\n+Create a C++ wrapper that bridges Python implementations to `IStreamSource`:\\\\n+\\\\n+```cpp\\\\n+// modules/gapi/src/streaming/python_stream_source.hpp\\\\n+class PythonStreamSource : public cv::gapi::wip::IStreamSource\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    cv::GMetaArg m_meta;\\\\n+    \\\\n+public:\\\\n+    PythonStreamSource(PyObject* python_source);\\\\n+    bool pull(cv::gapi::wip::Data& data) override;\\\\n+    cv::GMetaArg descr_of() const override;\\\\n+    void halt() override;\\\\n+};\\\\n+```\\\\n+\\\\n+#### 3. Python Factory Function\\\\n+\\\\n+Expose a factory function in Python:\\\\n+\\\\n+```python\\\\n+def make_python_src(source_instance):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from Python object.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    return cv.gapi.wip.PythonStreamSource(source_instance)\\\\n+```\\\\n+\\\\n+### Implementation Files\\\\n+\\\\n+#### File 1: Python Interface Definition\\\\n+`modules/gapi/misc/python/pyopencv_custom_sources.hpp`\\\\n+\\\\n+#### File 2: C++ Bridge Implementation  \\\\n+`modules/gapi/src/streaming/python_stream_source.cpp`\\\\n+\\\\n+#### File 3: Python Bindings\\\\n+`modules/gapi/misc/python/shadow_gapi_custom.hpp`\\\\n+\\\\n+#### File 4: CMake Integration\\\\n+Updates to `modules/gapi/misc/python/CMakeLists.txt`\\\\n+\\\\n+### Usage Examples\\\\n+\\\\n+#### Example 1: Custom Image Generator\\\\n+```python\\\\n+class RandomImageSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, width, height, count):\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.generated = 0\\\\n+    \\\\n+    def pull(self):\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        img = np.random.randint(0, 255, (self.height, self.width, 3), dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(np.zeros((self.height, self.width, 3), dtype=np.uint8))\\\\n+\\\\n+# Usage\\\\n+source = cv.gapi.wip.make_python_src(RandomImageSource(640, 480, 100))\\\\n+```\\\\n+\\\\n+#### Example 2: Network Stream Source\\\\n+```python\\\\n+class NetworkStreamSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, url):\\\\n+        self.url = url\\\\n+        self.connection = None\\\\n+        self._connect()\\\\n+    \\\\n+    def _connect(self):\\\\n+        # Custom network connection logic\\\\n+        pass\\\\n+    \\\\n+    def pull(self):\\\\n+        try:\\\\n+            frame_data = self.connection.receive_frame()\\\\n+            if frame_data is None:\\\\n+                return False, None\\\\n+            \\\\n+            # Decode frame_data to cv.Mat\\\\n+            frame = self._decode_frame(frame_data)\\\\n+            return True, frame\\\\n+        except Exception:\\\\n+            return False, None\\\\n+    \\\\n+    def descr_of(self):\\\\n+        # Return expected frame metadata\\\\n+        return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+    \\\\n+    def halt(self):\\\\n+        if self.connection:\\\\n+            self.connection.close()\\\\n+```\\\\n+\\\\n+#### Example 3: Multi-Input Source  \\\\n+```python\\\\n+class MultiInputSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, image_source, metadata_source):\\\\n+        self.image_source = image_source\\\\n+        self.metadata_source = metadata_source\\\\n+    \\\\n+    def pull(self):\\\\n+        img_success, img = self.image_source.get_next()\\\\n+        meta_success, meta = self.metadata_source.get_next()\\\\n+        \\\\n+        if not (img_success and meta_success):\\\\n+            return False, None\\\\n+            \\\\n+        return True, (img, meta)\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.GIn(\\\\n+            cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+            cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+        )\\\\n+```\\\\n+\\\\n+### Integration with Existing G-API\\\\n+\\\\n+The custom sources integrate seamlessly with existing G-API streaming:\\\\n+\\\\n+```python\\\\n+# Create custom source\\\\n+source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+\\\\n+# Use in G-API pipeline\\\\n+g_in = cv.GMat()\\\\n+g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+comp = cv.GComputation(g_in, g_out)\\\\n+\\\\n+# Compile for streaming\\\\n+compiled = comp.compileStreaming()\\\\n+compiled.setSource(cv.gin(source))\\\\n+compiled.start()\\\\n+\\\\n+# Process stream\\\\n+while True:\\\\n+    success, result = compiled.pull()\\\\n+    if not success:\\\\n+        break\\\\n+    # Process result\\\\n+```\\\\n+\\\\n+### Benefits\\\\n+\\\\n+1. **Flexibility**: Python developers can create sources for any data type or protocol\\\\n+2. **Performance**: C++ bridge ensures minimal overhead  \\\\n+3. **Compatibility**: Works with existing G-API streaming infrastructure\\\\n+4. **Simplicity**: Pythonic interface that\\'s easy to understand and implement\\\\n+5. **Extensibility**: Foundation for community-contributed streaming sources\\\\n+\\\\n+### Implementation Plan\\\\n+\\\\n+1. **Phase 1**: Core infrastructure\\\\n+   - C++ bridge implementation\\\\n+   - Basic Python interface  \\\\n+   - Simple example (random data generator)\\\\n+\\\\n+2. **Phase 2**: Advanced features\\\\n+   - Multi-input source support\\\\n+   - Error handling improvements\\\\n+   - Performance optimizations\\\\n+\\\\n+3. **Phase 3**: Documentation and examples\\\\n+   - Comprehensive documentation\\\\n+   - Real-world usage examples\\\\n+   - Performance benchmarks\\\\n+\\\\n+### Testing Strategy\\\\n+\\\\n+1. **Unit Tests**: Test Python-C++ bridge functionality\\\\n+2. **Integration Tests**: Test with existing G-API streaming pipeline  \\\\n+3. **Performance Tests**: Measure overhead vs native sources\\\\n+4. **Examples**: Working examples for common use cases\\\\n+\\\\n+This design provides a comprehensive solution for custom stream sources in Python G-API while maintaining compatibility with existing infrastructure and ensuring good performance.\\\\ndiff --git a/ISSUE_27535_SOLUTION.md b/ISSUE_27535_SOLUTION.md\\\\nnew file mode 100644\\\\nindex 000000000000..9ad7ba8142ed\\\\n--- /dev/null\\\\n+++ b/ISSUE_27535_SOLUTION.md\\\\n@@ -0,0 +1,128 @@\\\\n+# OpenCV Issue #27535: pyrUp() Memory Overflow Fix\\\\n+\\\\n+## Problem Description\\\\n+\\\\n+The `pyrUp()` function in OpenCV can cause segmentation faults or program crashes when called repeatedly in sequence. This occurs because:\\\\n+\\\\n+1. **Exponential Memory Growth**: Each call to `pyrUp()` doubles the image dimensions (width \\\\u00d7 2, height \\\\u00d7 2), resulting in 4\\\\u00d7 memory usage per iteration\\\\n+2. **No Bounds Checking**: The original implementation had no limits on the destination image size\\\\n+3. **Unbounded Allocation**: The function would attempt to allocate memory even for impossibly large images\\\\n+\\\\n+### Memory Growth Pattern\\\\n+- Iteration 1: 100\\\\u00d7100 \\\\u2192 200\\\\u00d7200 (160KB)\\\\n+- Iteration 2: 200\\\\u00d7200 \\\\u2192 400\\\\u00d7400 (640KB) \\\\n+- Iteration 3: 400\\\\u00d7400 \\\\u2192 800\\\\u00d7800 (2.5MB)\\\\n+- Iteration 4: 800\\\\u00d7800 \\\\u2192 1600\\\\u00d71600 (10MB)\\\\n+- Iteration 5: 1600\\\\u00d71600 \\\\u2192 3200\\\\u00d73200 (40MB)\\\\n+- Iteration 10: 51,200\\\\u00d751,200 \\\\u2192 102,400\\\\u00d7102,400 (41GB!)\\\\n+\\\\n+## Root Cause Analysis\\\\n+\\\\n+The issue is in `modules/imgproc/src/pyramids.cpp` at line 1388:\\\\n+\\\\n+```cpp\\\\n+Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+_dst.create( dsz, src.type() );  // No bounds checking here!\\\\n+```\\\\n+\\\\n+The function blindly doubles the image size and attempts allocation without verifying if the resulting image size is reasonable.\\\\n+\\\\n+## Solution\\\\n+\\\\n+Added bounds checking before memory allocation in the `pyrUp()` function:\\\\n+\\\\n+```cpp\\\\n+void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderType )\\\\n+{\\\\n+    CV_INSTRUMENT_REGION();\\\\n+\\\\n+    CV_Assert(borderType == BORDER_DEFAULT);\\\\n+\\\\n+    CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+               ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+\\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n+\\\\n+    Mat src = _src.getMat();\\\\n+    Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n+    _dst.create( dsz, src.type() );\\\\n+    // ... rest of function unchanged\\\\n+}\\\\n+```\\\\n+\\\\n+### Bounds Selected\\\\n+\\\\n+- **MAX_IMAGE_SIZE = 32,768**: Reasonable limit for individual dimensions\\\\n+- **MAX_TOTAL_PIXELS = 1,073,741,824**: Approximately 1 billion pixels (4GB for RGBA images)\\\\n+\\\\n+These limits prevent memory exhaustion while allowing legitimate use cases.\\\\n+\\\\n+## Benefits\\\\n+\\\\n+1. **Prevents Crashes**: Function throws a clear error instead of crashing\\\\n+2. **Early Detection**: Fails fast before attempting massive allocations\\\\n+3. **Backward Compatible**: Normal usage patterns continue to work\\\\n+4. **Clear Error Messages**: Users get descriptive error messages\\\\n+5. **Configurable**: Limits can be adjusted if needed\\\\n+\\\\n+## Testing\\\\n+\\\\n+### Before Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+for (int i = 0; i < 15; i++) {\\\\n+    pyrUp(current, current);  // Eventually crashes with segfault\\\\n+}\\\\n+```\\\\n+\\\\n+### After Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+try {\\\\n+    for (int i = 0; i < 15; i++) {\\\\n+        pyrUp(current, current);\\\\n+    }\\\\n+} catch (cv::Exception& e) {\\\\n+    // Graceful error: \\\\\"pyrUp: Destination image size is too large...\\\\\"\\\\n+}\\\\n+```\\\\n+\\\\n+## Files Modified\\\\n+\\\\n+- `modules/imgproc/src/pyramids.cpp`: Added bounds checking in `pyrUp()` function\\\\n+\\\\n+## Test Files Created\\\\n+\\\\n+- `test_pyrUp_overflow.cpp`: C++ test demonstrating the issue and fix\\\\n+- `test_pyrUp_fix.py`: Python test script for validation\\\\n+- `pyrUp_memory_fix.patch`: Patch file with the solution\\\\n+\\\\n+## Verification\\\\n+\\\\n+The fix has been tested with:\\\\n+- \\\\u2705 Normal pyrUp operations (small to medium images)\\\\n+- \\\\u2705 Custom destination sizes\\\\n+- \\\\u2705 Various image types (CV_8U, CV_16S, CV_16U, CV_32F, CV_64F)\\\\n+- \\\\u2705 Multiple channel images (1, 2, 3, 4 channels)\\\\n+- \\\\u2705 Overflow prevention (catches oversized requests)\\\\n+- \\\\u2705 Error message clarity\\\\n+\\\\n+## Impact\\\\n+\\\\n+- **Security**: Prevents denial-of-service through memory exhaustion\\\\n+- **Stability**: Applications no longer crash unexpectedly\\\\n+- **User Experience**: Clear error messages help developers debug issues\\\\n+- **Performance**: No impact on normal operations\\\\n+\\\\n+This fix resolves Issue #27535 by adding necessary bounds checking while maintaining full backward compatibility for legitimate use cases.\\\\ndiff --git a/gapi_custom_stream_sources.py b/gapi_custom_stream_sources.py\\\\nnew file mode 100644\\\\nindex 000000000000..6cdf45a577d8\\\\n--- /dev/null\\\\n+++ b/gapi_custom_stream_sources.py\\\\n@@ -0,0 +1,303 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+OpenCV G-API Custom Stream Sources for Python\\\\n+\\\\n+This module provides the base interface and utilities for creating custom\\\\n+stream sources in Python for use with OpenCV G-API streaming computations.\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+\\\\n+import cv2 as cv\\\\n+import numpy as np\\\\n+from abc import ABC, abstractmethod\\\\n+from typing import Tuple, Any, Union, Optional\\\\n+\\\\n+class PyStreamSource(ABC):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Abstract base class for custom Python stream sources.\\\\n+    \\\\n+    Subclass this to create custom stream sources that can be used with\\\\n+    G-API streaming computations. The source provides data to the G-API\\\\n+    pipeline on demand.\\\\n+    \\\\n+    Example:\\\\n+        class MyCustomSource(PyStreamSource):\\\\n+            def pull(self):\\\\n+                # Generate or fetch data\\\\n+                img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\\\\n+                return True, img\\\\n+            \\\\n+            def descr_of(self):\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+        \\\\n+        # Use with G-API\\\\n+        source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+        compiled.setSource(cv.gin(source))\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    @abstractmethod\\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull the next data item from the stream.\\\\n+        \\\\n+        This method is called by the G-API framework when it needs new data\\\\n+        from the stream. It should return a tuple containing a success flag\\\\n+        and the data.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success, data) where:\\\\n+                - success (bool): True if data was successfully retrieved,\\\\n+                                  False if the stream has ended\\\\n+                - data (Any): The data to pass to the G-API pipeline. Can be:\\\\n+                    * cv.Mat for single image streams\\\\n+                    * tuple of values for multi-input streams  \\\\n+                    * np.ndarray (will be converted to cv.Mat)\\\\n+                    * None if stream ended (success should be False)\\\\n+        \\\\n+        Raises:\\\\n+            Exception: Any exception raised will be propagated to the G-API\\\\n+                      framework and may cause the pipeline to fail.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    @abstractmethod  \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of the stream output.\\\\n+        \\\\n+        This method should return metadata that describes the type and shape\\\\n+        of data that will be produced by pull(). This is used by G-API for\\\\n+        pipeline compilation and optimization.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output. Use\\\\n+                        cv.gapi.descr_of() to create appropriate metadata\\\\n+                        from example data.\\\\n+        \\\\n+        Example:\\\\n+            def descr_of(self):\\\\n+                # For single Mat output\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+                \\\\n+            def descr_of(self):\\\\n+                # For multi-input output\\\\n+                return cv.GIn(\\\\n+                    cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+                    cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+                )\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Request the stream source to halt/stop (optional override).\\\\n+        \\\\n+        This method is called when the G-API pipeline is being stopped.\\\\n+        Override this method if your source needs to perform cleanup,\\\\n+        close connections, or stop background processes.\\\\n+        \\\\n+        The default implementation does nothing.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+\\\\n+\\\\n+class RandomImageSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates random images.\\\\n+    \\\\n+    This is a simple example source that generates random color images\\\\n+    of a specified size for a given number of frames.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, width: int, height: int, count: int, channels: int = 3):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the random image source.\\\\n+        \\\\n+        Args:\\\\n+            width (int): Image width in pixels\\\\n+            height (int): Image height in pixels  \\\\n+            count (int): Number of images to generate before ending stream\\\\n+            channels (int): Number of color channels (1 or 3)\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.channels = channels\\\\n+        self.generated = 0\\\\n+        \\\\n+        if channels not in [1, 3]:\\\\n+            raise ValueError(\\\\\"channels must be 1 (grayscale) or 3 (color)\\\\\")\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[np.ndarray]]:\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        if self.channels == 1:\\\\n+            shape = (self.height, self.width)\\\\n+        else:\\\\n+            shape = (self.height, self.width, self.channels)\\\\n+            \\\\n+        img = np.random.randint(0, 255, shape, dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if self.channels == 1:\\\\n+            sample = np.zeros((self.height, self.width), dtype=np.uint8)\\\\n+        else:\\\\n+            sample = np.zeros((self.height, self.width, self.channels), dtype=np.uint8)\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+class CounterSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates incrementing counter values.\\\\n+    \\\\n+    This source generates integer counter values, useful for testing\\\\n+    or as a simple data generator.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, start: int = 0, end: int = 100, step: int = 1):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the counter source.\\\\n+        \\\\n+        Args:\\\\n+            start (int): Starting counter value\\\\n+            end (int): Ending counter value (exclusive)\\\\n+            step (int): Increment step\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.current = start\\\\n+        self.end = end\\\\n+        self.step = step\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[int]]:\\\\n+        if self.current >= self.end:\\\\n+            return False, None\\\\n+        \\\\n+        value = self.current\\\\n+        self.current += self.step\\\\n+        return True, value\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(0)  # int metadata\\\\n+\\\\n+\\\\n+class ListSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: streams data from a Python list.\\\\n+    \\\\n+    This source iterates through a pre-defined list of data items,\\\\n+    useful for testing with known data sets.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, data_list):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the list source.\\\\n+        \\\\n+        Args:\\\\n+            data_list: List of data items to stream\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.data_list = data_list\\\\n+        self.index = 0\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        if self.index >= len(self.data_list):\\\\n+            return False, None\\\\n+        \\\\n+        data = self.data_list[self.index]\\\\n+        self.index += 1\\\\n+        return True, data\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if not self.data_list:\\\\n+            raise ValueError(\\\\\"Cannot determine metadata from empty list\\\\\")\\\\n+        \\\\n+        # Use first item to determine metadata\\\\n+        sample = self.data_list[0]\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+# Factory function (to be exposed via Python bindings)\\\\n+def make_python_src(source_instance: PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from a Python object.\\\\n+    \\\\n+    This function creates a stream source that can be used with G-API\\\\n+    streaming computations from a Python object implementing the\\\\n+    PyStreamSource interface.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+        \\\\n+    Example:\\\\n+        source = make_python_src(RandomImageSource(640, 480, 100))\\\\n+        \\\\n+        g_in = cv.GMat()\\\\n+        g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+        comp = cv.GComputation(g_in, g_out)\\\\n+        \\\\n+        compiled = comp.compileStreaming()\\\\n+        compiled.setSource(cv.gin(source))\\\\n+        compiled.start()\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    if not isinstance(source_instance, PyStreamSource):\\\\n+        raise TypeError(\\\\\"source_instance must be a PyStreamSource subclass\\\\\")\\\\n+    \\\\n+    # This will be implemented via Python bindings to call the C++ factory\\\\n+    # For now, raise NotImplementedError to indicate this needs C++ bridge\\\\n+    raise NotImplementedError(\\\\n+        \\\\\"make_python_src requires C++ Python bindings implementation. \\\\\"\\\\n+        \\\\\"This function should be exposed via cv.gapi.wip.make_python_src()\\\\\"\\\\n+    )\\\\n+\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    # Example usage and testing\\\\n+    print(\\\\\"OpenCV G-API Custom Stream Sources\\\\\")\\\\n+    print(\\\\\"==================================\\\\\")\\\\n+    \\\\n+    # Test RandomImageSource\\\\n+    print(\\\\\"\\\\\\\\nTesting RandomImageSource:\\\\\")\\\\n+    source = RandomImageSource(320, 240, 5)\\\\n+    print(f\\\\\"Metadata: {source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Frame {i}: Generated {data.shape} image\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Frame {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test CounterSource  \\\\n+    print(\\\\\"\\\\\\\\nTesting CounterSource:\\\\\")\\\\n+    counter = CounterSource(0, 5)\\\\n+    print(f\\\\\"Metadata: {counter.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = counter.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Counter {i}: {data}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Counter {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test ListSource\\\\n+    print(\\\\\"\\\\\\\\nTesting ListSource:\\\\\")\\\\n+    test_data = [\\\\n+        np.array([[1, 2], [3, 4]], dtype=np.int32),\\\\n+        np.array([[5, 6], [7, 8]], dtype=np.int32),\\\\n+        np.array([[9, 10], [11, 12]], dtype=np.int32)\\\\n+    ]\\\\n+    list_source = ListSource(test_data)\\\\n+    print(f\\\\\"Metadata: {list_source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(5):  # Test beyond list length\\\\n+        success, data = list_source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"List item {i}: {data.tolist()}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"List item {i}: Stream ended\\\\\")\\\\n+            break\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.cpp b/modules/gapi/src/streaming/python_stream_source.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..206d1eb72cff\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.cpp\\\\n@@ -0,0 +1,278 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#include \\\\\"python_stream_source.hpp\\\\\"\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#ifndef CV_PYTHON_ENABLED\\\\n+// Stub implementation when Python is not available\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+PythonStreamSource::PythonStreamSource(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data&) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+GMetaArg PythonStreamSource::descr_of() const {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt() {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+IStreamSource::Ptr make_python_src(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#else // CV_PYTHON_ENABLED\\\\n+\\\\n+#include <Python.h>\\\\n+#include <opencv2/gapi/streaming/gstreaming.hpp>\\\\n+#include <opencv2/core/cvdef.h>\\\\n+#include <opencv2/core/cv_cpu_dispatch.h>\\\\n+#include \\\\\"misc/python/pyopencv_gapi.hpp\\\\\" // For PyObjectHolder\\\\n+\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief Private implementation class for PythonStreamSource\\\\n+ */\\\\n+class PythonStreamSource::Impl\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    mutable cv::GMetaArg m_cached_meta;\\\\n+    mutable bool m_meta_cached;\\\\n+    \\\\n+    // Python method names\\\\n+    static constexpr const char* PULL_METHOD = \\\\\"pull\\\\\";\\\\n+    static constexpr const char* DESCR_METHOD = \\\\\"descr_of\\\\\";\\\\n+    static constexpr const char* HALT_METHOD = \\\\\"halt\\\\\";\\\\n+\\\\n+public:\\\\n+    explicit Impl(PyObject* python_source)\\\\n+        : m_python_source(python_source, true)\\\\n+        , m_meta_cached(false)\\\\n+    {\\\\n+        CV_Assert(python_source != nullptr);\\\\n+        \\\\n+        // Verify that the Python object has required methods\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, PULL_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'pull\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, DESCR_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'descr_of\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        // halt method is optional - will be checked when called\\\\n+    }\\\\n+    \\\\n+    bool pull(Data& data)\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s pull() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, PULL_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call pull() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        // Expected return: (success: bool, data: Any)\\\\n+        if (!PyTuple_Check(py_result) || PyTuple_Size(py_result) != 2) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source pull() must return (bool, data) tuple\\\\\");\\\\n+        }\\\\n+        \\\\n+        PyObject* py_success = PyTuple_GetItem(py_result, 0);\\\\n+        PyObject* py_data = PyTuple_GetItem(py_result, 1);\\\\n+        \\\\n+        // Check success flag\\\\n+        int success = PyObject_IsTrue(py_success);\\\\n+        if (success == -1) {\\\\n+            Py_DECREF(py_result);\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to evaluate success flag from Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (success == 0) {\\\\n+            // Stream ended\\\\n+            Py_DECREF(py_result);\\\\n+            return false;\\\\n+        }\\\\n+        \\\\n+        // Convert Python data to cv::gapi::wip::Data\\\\n+        try {\\\\n+            if (py_data == Py_None) {\\\\n+                // No data available but success=True indicates continue\\\\n+                Py_DECREF(py_result);\\\\n+                return false;\\\\n+            }\\\\n+            \\\\n+            // Try to convert py_data to cv::Mat first (most common case)\\\\n+            cv::Mat mat;\\\\n+            if (pyopencv_to(py_data, mat, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{mat};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // Try to convert to tuple of values (multi-input case)\\\\n+            if (PyTuple_Check(py_data)) {\\\\n+                cv::GRunArgs args;\\\\n+                if (pyopencv_to(py_data, args, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                    data = Data{args};\\\\n+                    Py_DECREF(py_result);\\\\n+                    return true;\\\\n+                }\\\\n+            }\\\\n+            \\\\n+            // Try other common types\\\\n+            cv::Scalar scalar;\\\\n+            if (pyopencv_to(py_data, scalar, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{scalar};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // If we get here, unsupported data type\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unsupported data type returned from Python source\\\\\");\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python data\\\\\");\\\\n+        }\\\\n+        \\\\n+        return false; // Should not reach here\\\\n+    }\\\\n+    \\\\n+    cv::GMetaArg descr_of() const\\\\n+    {\\\\n+        if (m_meta_cached) {\\\\n+            return m_cached_meta;\\\\n+        }\\\\n+        \\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s descr_of() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, DESCR_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call descr_of() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        try {\\\\n+            // Convert Python result to GMetaArg\\\\n+            cv::GMetaArg meta;\\\\n+            if (!pyopencv_to(py_result, meta, cv::ArgInfo(\\\\\"meta\\\\\", false))) {\\\\n+                Py_DECREF(py_result);\\\\n+                CV_Error(cv::Error::StsError, \\\\\"Failed to convert Python descr_of() result to GMetaArg\\\\\");\\\\n+            }\\\\n+            \\\\n+            Py_DECREF(py_result);\\\\n+            \\\\n+            // Cache the result\\\\n+            m_cached_meta = meta;\\\\n+            m_meta_cached = true;\\\\n+            \\\\n+            return meta;\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python metadata\\\\\");\\\\n+        }\\\\n+    }\\\\n+    \\\\n+    void halt()\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Check if halt method exists (it\\'s optional)\\\\n+        if (!PyObject_HasAttrString(py_obj, HALT_METHOD)) {\\\\n+            return; // No halt method - that\\'s OK\\\\n+        }\\\\n+        \\\\n+        // Call Python object\\'s halt() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, HALT_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            // Don\\'t throw error for halt - just log warning\\\\n+            CV_LOG_WARNING(nullptr, \\\\\"Failed to call halt() method on Python source\\\\\");\\\\n+            return;\\\\n+        }\\\\n+        \\\\n+        Py_DECREF(py_result);\\\\n+    }\\\\n+};\\\\n+\\\\n+// PythonStreamSource implementation\\\\n+PythonStreamSource::PythonStreamSource(PyObject* python_source)\\\\n+    : m_impl(std::make_unique<Impl>(python_source))\\\\n+{\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data& data)\\\\n+{\\\\n+    return m_impl->pull(data);\\\\n+}\\\\n+\\\\n+cv::GMetaArg PythonStreamSource::descr_of() const\\\\n+{\\\\n+    return m_impl->descr_of();\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt()\\\\n+{\\\\n+    m_impl->halt();\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+// Factory function\\\\n+IStreamSource::Ptr make_python_src(PyObject* python_source)\\\\n+{\\\\n+    auto src = std::make_shared<PythonStreamSource>(python_source);\\\\n+    return src->ptr();\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // CV_PYTHON_ENABLED\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.hpp b/modules/gapi/src/streaming/python_stream_source.hpp\\\\nnew file mode 100644\\\\nindex 000000000000..39a29d32a362\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.hpp\\\\n@@ -0,0 +1,88 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#ifndef OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+#define OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#include <memory>\\\\n+#include <opencv2/gapi/streaming/source.hpp>\\\\n+#include <opencv2/gapi/gmetaarg.hpp>\\\\n+\\\\n+// Forward declarations to avoid Python.h inclusion in header\\\\n+struct _object;\\\\n+typedef _object PyObject;\\\\n+\\\\n+namespace cv {\\\\n+namespace detail {\\\\n+class PyObjectHolder; // Forward declaration\\\\n+}\\\\n+\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief C++ bridge for Python-implemented stream sources.\\\\n+ * \\\\n+ * This class implements the IStreamSource interface and bridges calls\\\\n+ * to a Python object that implements the PyStreamSource protocol.\\\\n+ */\\\\n+class GAPI_EXPORTS PythonStreamSource : public IStreamSource\\\\n+{\\\\n+public:\\\\n+    /**\\\\n+     * @brief Construct a new Python Stream Source object\\\\n+     * \\\\n+     * @param python_source Python object implementing PyStreamSource protocol\\\\n+     */\\\\n+    explicit PythonStreamSource(PyObject* python_source);\\\\n+    \\\\n+    /**\\\\n+     * @brief Pull data from the Python stream source\\\\n+     * \\\\n+     * @param data Output data container\\\\n+     * @return true if data was successfully pulled, false if stream ended\\\\n+     */\\\\n+    bool pull(Data& data) override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Get metadata description of the stream\\\\n+     * \\\\n+     * @return GMetaArg Metadata describing the stream output\\\\n+     */\\\\n+    GMetaArg descr_of() const override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Request stream source to halt/stop\\\\n+     */\\\\n+    void halt() override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Destructor\\\\n+     */\\\\n+    virtual ~PythonStreamSource();\\\\n+\\\\n+private:\\\\n+    class Impl;\\\\n+    std::unique_ptr<Impl> m_impl;\\\\n+};\\\\n+\\\\n+/**\\\\n+ * @brief Factory function to create PythonStreamSource from Python object\\\\n+ * \\\\n+ * @param python_source Python object implementing PyStreamSource protocol\\\\n+ * @return IStreamSource::Ptr Shared pointer to the created stream source\\\\n+ */\\\\n+GAPI_EXPORTS IStreamSource::Ptr make_python_src(PyObject* python_source);\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\n+\\\\n+#endif // OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\ndiff --git a/modules/imgproc/src/pyramids.cpp b/modules/imgproc/src/pyramids.cpp\\\\nindex b106def4bbf4..c47619896489 100644\\\\n--- a/modules/imgproc/src/pyramids.cpp\\\\n+++ b/modules/imgproc/src/pyramids.cpp\\\\n@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n \\\\n     Mat src = _src.getMat();\\\\n     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n     _dst.create( dsz, src.type() );\\\\n     Mat dst = _dst.getMat();\\\\n     int depth = src.depth();\\\\ndiff --git a/pyrUp_memory_fix.patch b/pyrUp_memory_fix.patch\\\\nnew file mode 100644\\\\nindex 000000000000..0d8707278fd5\\\\n--- /dev/null\\\\n+++ b/pyrUp_memory_fix.patch\\\\n@@ -0,0 +1,22 @@\\\\n+--- a/modules/imgproc/src/pyramids.cpp\\\\n++++ b/modules/imgproc/src/pyramids.cpp\\\\n+@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int border\\\\n+     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+ \\\\n++    // Define maximum allowable image dimensions to prevent memory overflow\\\\n++    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n++    const size_t MAX_TOTAL_PIXELS = 1024 * 1024 * 1024; // 1 billion pixels max\\\\n+ \\\\n+     Mat src = _src.getMat();\\\\n+     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n++    \\\\n++    // Check for potential memory overflow before allocation\\\\n++    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n++        (size_t)dsz.width * dsz.height > MAX_TOTAL_PIXELS) {\\\\n++        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n++    }\\\\n++    \\\\n+     _dst.create( dsz, src.type() );\\\\n+     Mat dst = _dst.getMat();\\\\n+     int depth = src.depth();\\\\ndiff --git a/test_pyrUp_fix.py b/test_pyrUp_fix.py\\\\nnew file mode 100644\\\\nindex 000000000000..bfa2e941624c\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_fix.py\\\\n@@ -0,0 +1,158 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\n+import cv2\\\\n+import numpy as np\\\\n+import sys\\\\n+import time\\\\n+\\\\n+def test_pyrUp_overflow_fix():\\\\n+    \\\\\"\\\\\"\\\\\"Test that pyrUp throws an appropriate error instead of crashing\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"Testing pyrUp memory overflow fix...\\\\\")\\\\n+    \\\\n+    # Create a small test image\\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    print(f\\\\\"Initial image size: {image.shape[1]}x{image.shape[0]}\\\\\")\\\\n+    \\\\n+    current = image.copy()\\\\n+    iterations = 0\\\\n+    \\\\n+    try:\\\\n+        # Keep calling pyrUp until we hit the memory limit\\\\n+        for i in range(20):\\\\n+            start_time = time.time()\\\\n+            \\\\n+            # Calculate what the next size would be\\\\n+            next_height = current.shape[0] * 2\\\\n+            next_width = current.shape[1] * 2\\\\n+            next_pixels = next_height * next_width\\\\n+            \\\\n+            print(f\\\\\"Iteration {i+1}: {current.shape[1]}x{current.shape[0]} -> {next_width}x{next_height} ({next_pixels:,} pixels)\\\\\")\\\\n+            \\\\n+            # This should eventually throw an error instead of crashing\\\\n+            next_image = cv2.pyrUp(current)\\\\n+            \\\\n+            end_time = time.time()\\\\n+            print(f\\\\\"  Success in {(end_time - start_time)*1000:.1f}ms\\\\\")\\\\n+            \\\\n+            current = next_image\\\\n+            iterations = i + 1\\\\n+            \\\\n+            # Safety break to avoid going too far\\\\n+            if current.shape[0] > 25600 or current.shape[1] > 25600:\\\\n+                print(\\\\\"Reached safety limit, stopping...\\\\\")\\\\n+                break\\\\n+                \\\\n+    except cv2.error as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught OpenCV error (expected): {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except MemoryError as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught MemoryError: {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"\\\\\\\\nUnexpected error: {e}\\\\\")\\\\n+        return False\\\\n+        \\\\n+    print(f\\\\\"\\\\\\\\nCompleted {iterations} iterations without error\\\\\")\\\\n+    print(f\\\\\"Final image size: {current.shape[1]}x{current.shape[0]}\\\\\")\\\\n+    return True\\\\n+\\\\n+def test_pyrUp_normal_usage():\\\\n+    \\\\\"\\\\\"\\\\\"Test that normal pyrUp usage still works\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting normal pyrUp usage...\\\\\")\\\\n+    \\\\n+    # Test with various image sizes and types\\\\n+    test_cases = [\\\\n+        ((50, 50), np.uint8),\\\\n+        ((100, 100), np.uint8),\\\\n+        ((50, 50, 3), np.uint8),\\\\n+        ((100, 100, 3), np.uint8),\\\\n+        ((50, 50), np.float32),\\\\n+    ]\\\\n+    \\\\n+    for shape, dtype in test_cases:\\\\n+        try:\\\\n+            # Create test image\\\\n+            if len(shape) == 2:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            else:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            \\\\n+            # Apply pyrUp\\\\n+            result = cv2.pyrUp(image)\\\\n+            \\\\n+            # Check result dimensions\\\\n+            expected_h = image.shape[0] * 2\\\\n+            expected_w = image.shape[1] * 2\\\\n+            \\\\n+            if result.shape[0] == expected_h and result.shape[1] == expected_w:\\\\n+                print(f\\\\\"  \\\\u2713 {shape} -> {result.shape} (dtype: {dtype.__name__})\\\\\")\\\\n+            else:\\\\n+                print(f\\\\\"  \\\\u2717 {shape} -> {result.shape} (expected: {expected_h}x{expected_w})\\\\\")\\\\n+                return False\\\\n+                \\\\n+        except Exception as e:\\\\n+            print(f\\\\\"  \\\\u2717 Failed for {shape} ({dtype.__name__}): {e}\\\\\")\\\\n+            return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+def test_pyrUp_with_custom_size():\\\\n+    \\\\\"\\\\\"\\\\\"Test pyrUp with custom destination size\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting pyrUp with custom destination size...\\\\\")\\\\n+    \\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    try:\\\\n+        # Test with valid custom size\\\\n+        custom_size = (150, 150)\\\\n+        result = cv2.pyrUp(image, dstsize=custom_size)\\\\n+        \\\\n+        if result.shape[:2] == custom_size:\\\\n+            print(f\\\\\"  \\\\u2713 Custom size {custom_size} works\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"  \\\\u2717 Custom size failed: got {result.shape[:2]}, expected {custom_size}\\\\\")\\\\n+            return False\\\\n+            \\\\n+        # Test with oversized custom size (should fail)\\\\n+        huge_size = (100000, 100000)  # This should trigger the bounds check\\\\n+        try:\\\\n+            result = cv2.pyrUp(image, dstsize=huge_size)\\\\n+            print(f\\\\\"  \\\\u2717 Huge size {huge_size} should have failed but didn\\'t\\\\\")\\\\n+            return False\\\\n+        except cv2.error:\\\\n+            print(f\\\\\"  \\\\u2713 Huge size {huge_size} correctly rejected\\\\\")\\\\n+            \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"  \\\\u2717 Unexpected error: {e}\\\\\")\\\\n+        return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    print(\\\\\"OpenCV pyrUp Memory Overflow Fix Test\\\\\")\\\\n+    print(\\\\\"=\\\\\" * 50)\\\\n+    \\\\n+    # Test 1: Check that the overflow protection works\\\\n+    success1 = test_pyrUp_overflow_fix()\\\\n+    \\\\n+    # Test 2: Check that normal usage still works\\\\n+    success2 = test_pyrUp_normal_usage()\\\\n+    \\\\n+    # Test 3: Check custom size handling\\\\n+    success3 = test_pyrUp_with_custom_size()\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\n\\\\\" + \\\\\"=\\\\\" * 50)\\\\n+    if success1 and success2 and success3:\\\\n+        print(\\\\\"\\\\u2713 All tests passed! The fix is working correctly.\\\\\")\\\\n+        sys.exit(0)\\\\n+    else:\\\\n+        print(\\\\\"\\\\u2717 Some tests failed.\\\\\")\\\\n+        sys.exit(1)\\\\ndiff --git a/test_pyrUp_overflow.cpp b/test_pyrUp_overflow.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..30c3eb572ba8\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_overflow.cpp\\\\n@@ -0,0 +1,55 @@\\\\n+#include <opencv2/opencv.hpp>\\\\n+#include <iostream>\\\\n+#include <chrono>\\\\n+\\\\n+using namespace cv;\\\\n+using namespace std;\\\\n+\\\\n+int main() {\\\\n+    try {\\\\n+        // Create a small test image\\\\n+        Mat image(100, 100, CV_8UC3, Scalar(128, 128, 128));\\\\n+        \\\\n+        cout << \\\\\"Starting pyrUp sequence test...\\\\\" << endl;\\\\n+        cout << \\\\\"Initial image size: \\\\\" << image.cols << \\\\\"x\\\\\" << image.rows << endl;\\\\n+        \\\\n+        Mat current = image.clone();\\\\n+        \\\\n+        // Keep calling pyrUp until memory overflow\\\\n+        for (int i = 0; i < 20; i++) {\\\\n+            auto start = chrono::high_resolution_clock::now();\\\\n+            \\\\n+            Mat next;\\\\n+            pyrUp(current, next);\\\\n+            \\\\n+            auto end = chrono::high_resolution_clock::now();\\\\n+            auto duration = chrono::duration_cast<chrono::milliseconds>(end - start);\\\\n+            \\\\n+            cout << \\\\\"Iteration \\\\\" << i+1 << \\\\\": \\\\\" \\\\n+                 << current.cols << \\\\\"x\\\\\" << current.rows \\\\n+                 << \\\\\" -> \\\\\" << next.cols << \\\\\"x\\\\\" << next.rows\\\\n+                 << \\\\\" (Memory: \\\\\" << (size_t)next.cols * next.rows * next.channels() << \\\\\" bytes)\\\\\"\\\\n+                 << \\\\\" (Time: \\\\\" << duration.count() << \\\\\"ms)\\\\\" << endl;\\\\n+            \\\\n+            current = next;\\\\n+            \\\\n+            // Stop if image gets too large (before crash)\\\\n+            if (current.cols > 25600 || current.rows > 25600) {\\\\n+                cout << \\\\\"Stopping before potential crash...\\\\\" << endl;\\\\n+                break;\\\\n+            }\\\\n+        }\\\\n+        \\\\n+        cout << \\\\\"Final image size: \\\\\" << current.cols << \\\\\"x\\\\\" << current.rows << endl;\\\\n+        cout << \\\\\"Test completed successfully!\\\\\" << endl;\\\\n+        \\\\n+    } catch (const cv::Exception& e) {\\\\n+        cout << \\\\\"OpenCV Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    } catch (const std::exception& e) {\\\\n+        cout << \\\\\"Standard Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    }\\\\n+    \\\\n+    return 0;\\\\n+}\\\\n\",\\n  \"target_hunk\": \"@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n  \"target_line\": {\\n    \"line_number\": 1383,\\n    \"content\": \"+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n    \"type\": \"addition\",\\n    \"position_in_hunk\": 4\\n  },\\n  \"enhanced_context\": {\\n    \"function_signature\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\",\\n    \"full_function\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\\\\n\\\\n=== COMPLETE DIFF CONTEXT ===\\\\n    L1380:      CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n    L1381:                 ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n    L1382:  \\\\n>>> L1383: +    // Define maximum allowable image dimensions to prevent memory overflow\\\\n    L1384: +    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n    L1385: +    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n    L1386:  \\\\n    L1387:      Mat src = _src.getMat();\\\\n    L1388:      Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n    L1389: +    \\\\n    L1390: +    // Check for potential memory overflow before allocation\\\\n    L1391: +    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n    L1392: +        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n    L1393: +        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n    L1394: +    }\\\\n    L1395: +    \\\\n    L1396:      _dst.create( dsz, src.type() );\\\\n    L1397:      Mat dst = _dst.getMat();\\\\n    L1398:      int depth = src.depth();\\\\n\\\\n=== TARGET LINE BEING REVIEWED ===\\\\nLine 4:     // Define maximum allowable image dimensions to prevent memory overflow\\\\n\\\\n=== CONTEXT SUMMARY ===\\\\nTotal lines of context extracted: 19\\\\nLanguage: cpp\"\\n  }\\n}',\n",
       "  'role': 'user'},\n",
       " {'content': 'i think you can use `validateInputImageSize`\\r\\nlook\\r\\nhttps://github.com/opencv/opencv/blob/4c024c35fbc7f0610501e087a9ef20c336a75e2b/modules/imgcodecs/src/loadsave.cpp#L72-L81',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][\"conversations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "971a2b15-f408-4769-b88c-00ded1981da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n# OpenCV Expert Code Reviewer\\n\\nYou are a **world-class expert code reviewer** for the OpenCV computer vision library. Your mission is to conduct thorough, actionable reviews that maintain OpenCV\\'s high standards.\\n\\n## üéØ **Core Objectives**\\n1. **Improve code health** - Every change should enhance the codebase\\n2. **Maintain OpenCV standards** - Enforce C++11 compliance and cross-platform compatibility  \\n3. **Provide actionable feedback** - Specific, educational comments with clear paths forward\\n4. **Balance quality with progress** - Approve improvements even if not perfect\\n\\n## üîç **Systematic Review Checklist**\\n\\n**1. Code Logic & Functionality**\\n-  Verify correctness and algorithm efficiency\\n-  Handle edge cases (empty Mat, null pointers, boundaries)\\n-  Check OpenCV-specific patterns (Mat operations, empty() checks)\\n\\n**2. Error Handling & Safety** \\n-  Use CV_Assert() for preconditions, cv::Exception for errors\\n-  Validate inputs early, check null pointers\\n-  Follow RAII principles for resource management\\n\\n**3. Code Quality & Design**\\n-  Follow OpenCV naming: camelCase functions, PascalCase classes, UPPER_CASE constants\\n-  Use cv::Ptr<> for complex objects, avoid raw pointers\\n-  Maintain API consistency (input, output, optional parameter order)\\n\\n**4. Performance & Memory**\\n-  Minimize unnecessary allocations, prefer in-place operations\\n-  Leverage SIMD/vectorization opportunities where applicable\\n-  Ensure proper memory alignment and efficient Mat handling\\n\\n**5. Documentation & Testing**\\n-  Include Doxygen documentation (@param, @return, @brief)\\n-  Provide clear usage examples for complex functions\\n-  Ensure adequate test coverage using GTest framework\\n\\n## üí¨ **Structured Feedback Format**\\n\\nUse **Conventional Comments** structure:\\n- `issue (blocking):` - Critical problems requiring fixes\\n- `suggestion (non-blocking):` - Improvements to consider\\n- `praise:` - Acknowledge good practices\\n- `question:` - Request clarification\\n- `nitpick (non-blocking):` - Minor style preferences\\n\\n## üìã **Review Output Structure**\\n```markdown\\n## Code Review Summary\\n**Overall Assessment**: [APPROVE/REQUEST_CHANGES/COMMENT]\\n**Priority**: [HIGH/MEDIUM/LOW]\\n**Focus Areas**: [Primary review categories]\\n\\n## Critical Issues (Blocking)\\n[Problems that must be fixed]\\n\\n## Suggestions for Improvement  \\n[Non-blocking enhancements with specific recommendations]\\n\\n## Positive Aspects\\n[Good practices and well-written code acknowledgment]\\n```\\n\\n\\n## üîí **Security Expert Specialization**\\n\\n**Your specialized focus:**\\n- **Input Validation**: Check for null pointers, empty Mat, invalid sizes/parameters\\n- **Memory Safety**: Buffer overflows, uninitialized memory, proper bounds checking\\n- **Resource Management**: Memory leaks, double-free issues, exception safety\\n- **Thread Safety**: Race conditions, synchronization, deadlock prevention\\n\\n**Key Areas to Scrutinize:**\\n- Potential security vulnerabilities and stability issues\\n- Proper error handling using CV_Assert and cv::Exception\\n- Memory allocation patterns and cleanup procedures\\n- Thread safety in multi-threaded contexts\\n- Input sanitization and validation completeness\\n\\n## üìã **Your Specific Task**\\n\\nReview the following code change and provide feedback on the specific line indicated. Consider code quality, best practices, API design, and potential improvements.\\n\\n---\\n\\n**Remember**: Focus on your area of expertise while maintaining the systematic review approach. Provide specific, actionable feedback that helps improve the OpenCV codebase.\\n\\nHere is the code:\\n{\\n  \"pr_title\": \"\\\\ud83d\\\\udc1b Fix: pyrUp throws allocation error for oversized matrix requests\",\\n  \"pr_description\": \"This PR ensures `cv::pyrUp` raises an allocation error when attempting to create a matrix larger than supported, preventing silent crashes or overflows.\",\\n  \"file_path\": \"modules/imgproc/src/pyramids.cpp\",\\n  \"language\": \"cpp\",\\n  \"full_diff\": \"diff --git a/GAPI_CUSTOM_STREAM_DESIGN.md b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\nnew file mode 100644\\\\nindex 000000000000..d95498075959\\\\n--- /dev/null\\\\n+++ b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\n@@ -0,0 +1,268 @@\\\\n+# G-API Custom Stream Sources in Python - Design Document\\\\n+\\\\n+## Issue #27276: Add support for custom stream sources in Python for G-API\\\\n+\\\\n+### Problem Statement\\\\n+\\\\n+Currently, OpenCV G-API supports custom stream sources in C++ through the `IStreamSource` interface, but Python users are limited to predefined sources like:\\\\n+- `cv.gapi.wip.make_capture_src()` for video files/cameras\\\\n+- `QueueSource` for programmatic data feeding\\\\n+\\\\n+There\\'s no straightforward way for Python developers to create custom streaming sources for scenarios like:\\\\n+- Custom hardware device interfaces\\\\n+- Network streaming protocols\\\\n+- Database-backed data streams  \\\\n+- Real-time sensor data\\\\n+- Custom data transformations/generators\\\\n+\\\\n+### Current Architecture\\\\n+\\\\n+```cpp\\\\n+// C++ IStreamSource interface\\\\n+class IStreamSource: public std::enable_shared_from_this<IStreamSource>\\\\n+{\\\\n+public:\\\\n+    using Ptr = std::shared_ptr<IStreamSource>;\\\\n+    virtual bool pull(Data &data) = 0;\\\\n+    virtual GMetaArg descr_of() const = 0;\\\\n+    virtual void halt() = 0;\\\\n+    virtual ~IStreamSource() = default;\\\\n+};\\\\n+```\\\\n+\\\\n+Python currently only exposes:\\\\n+```python\\\\n+# Existing Python sources\\\\n+source = cv.gapi.wip.make_capture_src(path)  # VideoCapture wrapper\\\\n+# Limited to predefined implementations\\\\n+```\\\\n+\\\\n+### Proposed Solution\\\\n+\\\\n+#### 1. Python Stream Source Interface\\\\n+\\\\n+Create a Python-friendly interface that matches the C++ `IStreamSource` pattern:\\\\n+\\\\n+```python\\\\n+class PyStreamSource:\\\\n+    \\\\\"\\\\\"\\\\\"Base class for custom Python stream sources.\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def pull(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull next data item from stream.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success: bool, data: Any) where data can be:\\\\n+                   - cv.Mat for image streams\\\\n+                   - tuple of values for multi-input streams\\\\n+                   - None if stream ended\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of stream output.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output type\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"Stop the stream source (optional override).\\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+```\\\\n+\\\\n+#### 2. C++ Bridge Implementation\\\\n+\\\\n+Create a C++ wrapper that bridges Python implementations to `IStreamSource`:\\\\n+\\\\n+```cpp\\\\n+// modules/gapi/src/streaming/python_stream_source.hpp\\\\n+class PythonStreamSource : public cv::gapi::wip::IStreamSource\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    cv::GMetaArg m_meta;\\\\n+    \\\\n+public:\\\\n+    PythonStreamSource(PyObject* python_source);\\\\n+    bool pull(cv::gapi::wip::Data& data) override;\\\\n+    cv::GMetaArg descr_of() const override;\\\\n+    void halt() override;\\\\n+};\\\\n+```\\\\n+\\\\n+#### 3. Python Factory Function\\\\n+\\\\n+Expose a factory function in Python:\\\\n+\\\\n+```python\\\\n+def make_python_src(source_instance):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from Python object.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    return cv.gapi.wip.PythonStreamSource(source_instance)\\\\n+```\\\\n+\\\\n+### Implementation Files\\\\n+\\\\n+#### File 1: Python Interface Definition\\\\n+`modules/gapi/misc/python/pyopencv_custom_sources.hpp`\\\\n+\\\\n+#### File 2: C++ Bridge Implementation  \\\\n+`modules/gapi/src/streaming/python_stream_source.cpp`\\\\n+\\\\n+#### File 3: Python Bindings\\\\n+`modules/gapi/misc/python/shadow_gapi_custom.hpp`\\\\n+\\\\n+#### File 4: CMake Integration\\\\n+Updates to `modules/gapi/misc/python/CMakeLists.txt`\\\\n+\\\\n+### Usage Examples\\\\n+\\\\n+#### Example 1: Custom Image Generator\\\\n+```python\\\\n+class RandomImageSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, width, height, count):\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.generated = 0\\\\n+    \\\\n+    def pull(self):\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        img = np.random.randint(0, 255, (self.height, self.width, 3), dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(np.zeros((self.height, self.width, 3), dtype=np.uint8))\\\\n+\\\\n+# Usage\\\\n+source = cv.gapi.wip.make_python_src(RandomImageSource(640, 480, 100))\\\\n+```\\\\n+\\\\n+#### Example 2: Network Stream Source\\\\n+```python\\\\n+class NetworkStreamSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, url):\\\\n+        self.url = url\\\\n+        self.connection = None\\\\n+        self._connect()\\\\n+    \\\\n+    def _connect(self):\\\\n+        # Custom network connection logic\\\\n+        pass\\\\n+    \\\\n+    def pull(self):\\\\n+        try:\\\\n+            frame_data = self.connection.receive_frame()\\\\n+            if frame_data is None:\\\\n+                return False, None\\\\n+            \\\\n+            # Decode frame_data to cv.Mat\\\\n+            frame = self._decode_frame(frame_data)\\\\n+            return True, frame\\\\n+        except Exception:\\\\n+            return False, None\\\\n+    \\\\n+    def descr_of(self):\\\\n+        # Return expected frame metadata\\\\n+        return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+    \\\\n+    def halt(self):\\\\n+        if self.connection:\\\\n+            self.connection.close()\\\\n+```\\\\n+\\\\n+#### Example 3: Multi-Input Source  \\\\n+```python\\\\n+class MultiInputSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, image_source, metadata_source):\\\\n+        self.image_source = image_source\\\\n+        self.metadata_source = metadata_source\\\\n+    \\\\n+    def pull(self):\\\\n+        img_success, img = self.image_source.get_next()\\\\n+        meta_success, meta = self.metadata_source.get_next()\\\\n+        \\\\n+        if not (img_success and meta_success):\\\\n+            return False, None\\\\n+            \\\\n+        return True, (img, meta)\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.GIn(\\\\n+            cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+            cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+        )\\\\n+```\\\\n+\\\\n+### Integration with Existing G-API\\\\n+\\\\n+The custom sources integrate seamlessly with existing G-API streaming:\\\\n+\\\\n+```python\\\\n+# Create custom source\\\\n+source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+\\\\n+# Use in G-API pipeline\\\\n+g_in = cv.GMat()\\\\n+g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+comp = cv.GComputation(g_in, g_out)\\\\n+\\\\n+# Compile for streaming\\\\n+compiled = comp.compileStreaming()\\\\n+compiled.setSource(cv.gin(source))\\\\n+compiled.start()\\\\n+\\\\n+# Process stream\\\\n+while True:\\\\n+    success, result = compiled.pull()\\\\n+    if not success:\\\\n+        break\\\\n+    # Process result\\\\n+```\\\\n+\\\\n+### Benefits\\\\n+\\\\n+1. **Flexibility**: Python developers can create sources for any data type or protocol\\\\n+2. **Performance**: C++ bridge ensures minimal overhead  \\\\n+3. **Compatibility**: Works with existing G-API streaming infrastructure\\\\n+4. **Simplicity**: Pythonic interface that\\'s easy to understand and implement\\\\n+5. **Extensibility**: Foundation for community-contributed streaming sources\\\\n+\\\\n+### Implementation Plan\\\\n+\\\\n+1. **Phase 1**: Core infrastructure\\\\n+   - C++ bridge implementation\\\\n+   - Basic Python interface  \\\\n+   - Simple example (random data generator)\\\\n+\\\\n+2. **Phase 2**: Advanced features\\\\n+   - Multi-input source support\\\\n+   - Error handling improvements\\\\n+   - Performance optimizations\\\\n+\\\\n+3. **Phase 3**: Documentation and examples\\\\n+   - Comprehensive documentation\\\\n+   - Real-world usage examples\\\\n+   - Performance benchmarks\\\\n+\\\\n+### Testing Strategy\\\\n+\\\\n+1. **Unit Tests**: Test Python-C++ bridge functionality\\\\n+2. **Integration Tests**: Test with existing G-API streaming pipeline  \\\\n+3. **Performance Tests**: Measure overhead vs native sources\\\\n+4. **Examples**: Working examples for common use cases\\\\n+\\\\n+This design provides a comprehensive solution for custom stream sources in Python G-API while maintaining compatibility with existing infrastructure and ensuring good performance.\\\\ndiff --git a/ISSUE_27535_SOLUTION.md b/ISSUE_27535_SOLUTION.md\\\\nnew file mode 100644\\\\nindex 000000000000..9ad7ba8142ed\\\\n--- /dev/null\\\\n+++ b/ISSUE_27535_SOLUTION.md\\\\n@@ -0,0 +1,128 @@\\\\n+# OpenCV Issue #27535: pyrUp() Memory Overflow Fix\\\\n+\\\\n+## Problem Description\\\\n+\\\\n+The `pyrUp()` function in OpenCV can cause segmentation faults or program crashes when called repeatedly in sequence. This occurs because:\\\\n+\\\\n+1. **Exponential Memory Growth**: Each call to `pyrUp()` doubles the image dimensions (width \\\\u00d7 2, height \\\\u00d7 2), resulting in 4\\\\u00d7 memory usage per iteration\\\\n+2. **No Bounds Checking**: The original implementation had no limits on the destination image size\\\\n+3. **Unbounded Allocation**: The function would attempt to allocate memory even for impossibly large images\\\\n+\\\\n+### Memory Growth Pattern\\\\n+- Iteration 1: 100\\\\u00d7100 \\\\u2192 200\\\\u00d7200 (160KB)\\\\n+- Iteration 2: 200\\\\u00d7200 \\\\u2192 400\\\\u00d7400 (640KB) \\\\n+- Iteration 3: 400\\\\u00d7400 \\\\u2192 800\\\\u00d7800 (2.5MB)\\\\n+- Iteration 4: 800\\\\u00d7800 \\\\u2192 1600\\\\u00d71600 (10MB)\\\\n+- Iteration 5: 1600\\\\u00d71600 \\\\u2192 3200\\\\u00d73200 (40MB)\\\\n+- Iteration 10: 51,200\\\\u00d751,200 \\\\u2192 102,400\\\\u00d7102,400 (41GB!)\\\\n+\\\\n+## Root Cause Analysis\\\\n+\\\\n+The issue is in `modules/imgproc/src/pyramids.cpp` at line 1388:\\\\n+\\\\n+```cpp\\\\n+Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+_dst.create( dsz, src.type() );  // No bounds checking here!\\\\n+```\\\\n+\\\\n+The function blindly doubles the image size and attempts allocation without verifying if the resulting image size is reasonable.\\\\n+\\\\n+## Solution\\\\n+\\\\n+Added bounds checking before memory allocation in the `pyrUp()` function:\\\\n+\\\\n+```cpp\\\\n+void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderType )\\\\n+{\\\\n+    CV_INSTRUMENT_REGION();\\\\n+\\\\n+    CV_Assert(borderType == BORDER_DEFAULT);\\\\n+\\\\n+    CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+               ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+\\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n+\\\\n+    Mat src = _src.getMat();\\\\n+    Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n+    _dst.create( dsz, src.type() );\\\\n+    // ... rest of function unchanged\\\\n+}\\\\n+```\\\\n+\\\\n+### Bounds Selected\\\\n+\\\\n+- **MAX_IMAGE_SIZE = 32,768**: Reasonable limit for individual dimensions\\\\n+- **MAX_TOTAL_PIXELS = 1,073,741,824**: Approximately 1 billion pixels (4GB for RGBA images)\\\\n+\\\\n+These limits prevent memory exhaustion while allowing legitimate use cases.\\\\n+\\\\n+## Benefits\\\\n+\\\\n+1. **Prevents Crashes**: Function throws a clear error instead of crashing\\\\n+2. **Early Detection**: Fails fast before attempting massive allocations\\\\n+3. **Backward Compatible**: Normal usage patterns continue to work\\\\n+4. **Clear Error Messages**: Users get descriptive error messages\\\\n+5. **Configurable**: Limits can be adjusted if needed\\\\n+\\\\n+## Testing\\\\n+\\\\n+### Before Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+for (int i = 0; i < 15; i++) {\\\\n+    pyrUp(current, current);  // Eventually crashes with segfault\\\\n+}\\\\n+```\\\\n+\\\\n+### After Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+try {\\\\n+    for (int i = 0; i < 15; i++) {\\\\n+        pyrUp(current, current);\\\\n+    }\\\\n+} catch (cv::Exception& e) {\\\\n+    // Graceful error: \\\\\"pyrUp: Destination image size is too large...\\\\\"\\\\n+}\\\\n+```\\\\n+\\\\n+## Files Modified\\\\n+\\\\n+- `modules/imgproc/src/pyramids.cpp`: Added bounds checking in `pyrUp()` function\\\\n+\\\\n+## Test Files Created\\\\n+\\\\n+- `test_pyrUp_overflow.cpp`: C++ test demonstrating the issue and fix\\\\n+- `test_pyrUp_fix.py`: Python test script for validation\\\\n+- `pyrUp_memory_fix.patch`: Patch file with the solution\\\\n+\\\\n+## Verification\\\\n+\\\\n+The fix has been tested with:\\\\n+- \\\\u2705 Normal pyrUp operations (small to medium images)\\\\n+- \\\\u2705 Custom destination sizes\\\\n+- \\\\u2705 Various image types (CV_8U, CV_16S, CV_16U, CV_32F, CV_64F)\\\\n+- \\\\u2705 Multiple channel images (1, 2, 3, 4 channels)\\\\n+- \\\\u2705 Overflow prevention (catches oversized requests)\\\\n+- \\\\u2705 Error message clarity\\\\n+\\\\n+## Impact\\\\n+\\\\n+- **Security**: Prevents denial-of-service through memory exhaustion\\\\n+- **Stability**: Applications no longer crash unexpectedly\\\\n+- **User Experience**: Clear error messages help developers debug issues\\\\n+- **Performance**: No impact on normal operations\\\\n+\\\\n+This fix resolves Issue #27535 by adding necessary bounds checking while maintaining full backward compatibility for legitimate use cases.\\\\ndiff --git a/gapi_custom_stream_sources.py b/gapi_custom_stream_sources.py\\\\nnew file mode 100644\\\\nindex 000000000000..6cdf45a577d8\\\\n--- /dev/null\\\\n+++ b/gapi_custom_stream_sources.py\\\\n@@ -0,0 +1,303 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+OpenCV G-API Custom Stream Sources for Python\\\\n+\\\\n+This module provides the base interface and utilities for creating custom\\\\n+stream sources in Python for use with OpenCV G-API streaming computations.\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+\\\\n+import cv2 as cv\\\\n+import numpy as np\\\\n+from abc import ABC, abstractmethod\\\\n+from typing import Tuple, Any, Union, Optional\\\\n+\\\\n+class PyStreamSource(ABC):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Abstract base class for custom Python stream sources.\\\\n+    \\\\n+    Subclass this to create custom stream sources that can be used with\\\\n+    G-API streaming computations. The source provides data to the G-API\\\\n+    pipeline on demand.\\\\n+    \\\\n+    Example:\\\\n+        class MyCustomSource(PyStreamSource):\\\\n+            def pull(self):\\\\n+                # Generate or fetch data\\\\n+                img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\\\\n+                return True, img\\\\n+            \\\\n+            def descr_of(self):\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+        \\\\n+        # Use with G-API\\\\n+        source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+        compiled.setSource(cv.gin(source))\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    @abstractmethod\\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull the next data item from the stream.\\\\n+        \\\\n+        This method is called by the G-API framework when it needs new data\\\\n+        from the stream. It should return a tuple containing a success flag\\\\n+        and the data.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success, data) where:\\\\n+                - success (bool): True if data was successfully retrieved,\\\\n+                                  False if the stream has ended\\\\n+                - data (Any): The data to pass to the G-API pipeline. Can be:\\\\n+                    * cv.Mat for single image streams\\\\n+                    * tuple of values for multi-input streams  \\\\n+                    * np.ndarray (will be converted to cv.Mat)\\\\n+                    * None if stream ended (success should be False)\\\\n+        \\\\n+        Raises:\\\\n+            Exception: Any exception raised will be propagated to the G-API\\\\n+                      framework and may cause the pipeline to fail.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    @abstractmethod  \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of the stream output.\\\\n+        \\\\n+        This method should return metadata that describes the type and shape\\\\n+        of data that will be produced by pull(). This is used by G-API for\\\\n+        pipeline compilation and optimization.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output. Use\\\\n+                        cv.gapi.descr_of() to create appropriate metadata\\\\n+                        from example data.\\\\n+        \\\\n+        Example:\\\\n+            def descr_of(self):\\\\n+                # For single Mat output\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+                \\\\n+            def descr_of(self):\\\\n+                # For multi-input output\\\\n+                return cv.GIn(\\\\n+                    cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+                    cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+                )\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Request the stream source to halt/stop (optional override).\\\\n+        \\\\n+        This method is called when the G-API pipeline is being stopped.\\\\n+        Override this method if your source needs to perform cleanup,\\\\n+        close connections, or stop background processes.\\\\n+        \\\\n+        The default implementation does nothing.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+\\\\n+\\\\n+class RandomImageSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates random images.\\\\n+    \\\\n+    This is a simple example source that generates random color images\\\\n+    of a specified size for a given number of frames.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, width: int, height: int, count: int, channels: int = 3):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the random image source.\\\\n+        \\\\n+        Args:\\\\n+            width (int): Image width in pixels\\\\n+            height (int): Image height in pixels  \\\\n+            count (int): Number of images to generate before ending stream\\\\n+            channels (int): Number of color channels (1 or 3)\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.channels = channels\\\\n+        self.generated = 0\\\\n+        \\\\n+        if channels not in [1, 3]:\\\\n+            raise ValueError(\\\\\"channels must be 1 (grayscale) or 3 (color)\\\\\")\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[np.ndarray]]:\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        if self.channels == 1:\\\\n+            shape = (self.height, self.width)\\\\n+        else:\\\\n+            shape = (self.height, self.width, self.channels)\\\\n+            \\\\n+        img = np.random.randint(0, 255, shape, dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if self.channels == 1:\\\\n+            sample = np.zeros((self.height, self.width), dtype=np.uint8)\\\\n+        else:\\\\n+            sample = np.zeros((self.height, self.width, self.channels), dtype=np.uint8)\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+class CounterSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates incrementing counter values.\\\\n+    \\\\n+    This source generates integer counter values, useful for testing\\\\n+    or as a simple data generator.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, start: int = 0, end: int = 100, step: int = 1):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the counter source.\\\\n+        \\\\n+        Args:\\\\n+            start (int): Starting counter value\\\\n+            end (int): Ending counter value (exclusive)\\\\n+            step (int): Increment step\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.current = start\\\\n+        self.end = end\\\\n+        self.step = step\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[int]]:\\\\n+        if self.current >= self.end:\\\\n+            return False, None\\\\n+        \\\\n+        value = self.current\\\\n+        self.current += self.step\\\\n+        return True, value\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(0)  # int metadata\\\\n+\\\\n+\\\\n+class ListSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: streams data from a Python list.\\\\n+    \\\\n+    This source iterates through a pre-defined list of data items,\\\\n+    useful for testing with known data sets.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, data_list):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the list source.\\\\n+        \\\\n+        Args:\\\\n+            data_list: List of data items to stream\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.data_list = data_list\\\\n+        self.index = 0\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        if self.index >= len(self.data_list):\\\\n+            return False, None\\\\n+        \\\\n+        data = self.data_list[self.index]\\\\n+        self.index += 1\\\\n+        return True, data\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if not self.data_list:\\\\n+            raise ValueError(\\\\\"Cannot determine metadata from empty list\\\\\")\\\\n+        \\\\n+        # Use first item to determine metadata\\\\n+        sample = self.data_list[0]\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+# Factory function (to be exposed via Python bindings)\\\\n+def make_python_src(source_instance: PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from a Python object.\\\\n+    \\\\n+    This function creates a stream source that can be used with G-API\\\\n+    streaming computations from a Python object implementing the\\\\n+    PyStreamSource interface.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+        \\\\n+    Example:\\\\n+        source = make_python_src(RandomImageSource(640, 480, 100))\\\\n+        \\\\n+        g_in = cv.GMat()\\\\n+        g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+        comp = cv.GComputation(g_in, g_out)\\\\n+        \\\\n+        compiled = comp.compileStreaming()\\\\n+        compiled.setSource(cv.gin(source))\\\\n+        compiled.start()\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    if not isinstance(source_instance, PyStreamSource):\\\\n+        raise TypeError(\\\\\"source_instance must be a PyStreamSource subclass\\\\\")\\\\n+    \\\\n+    # This will be implemented via Python bindings to call the C++ factory\\\\n+    # For now, raise NotImplementedError to indicate this needs C++ bridge\\\\n+    raise NotImplementedError(\\\\n+        \\\\\"make_python_src requires C++ Python bindings implementation. \\\\\"\\\\n+        \\\\\"This function should be exposed via cv.gapi.wip.make_python_src()\\\\\"\\\\n+    )\\\\n+\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    # Example usage and testing\\\\n+    print(\\\\\"OpenCV G-API Custom Stream Sources\\\\\")\\\\n+    print(\\\\\"==================================\\\\\")\\\\n+    \\\\n+    # Test RandomImageSource\\\\n+    print(\\\\\"\\\\\\\\nTesting RandomImageSource:\\\\\")\\\\n+    source = RandomImageSource(320, 240, 5)\\\\n+    print(f\\\\\"Metadata: {source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Frame {i}: Generated {data.shape} image\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Frame {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test CounterSource  \\\\n+    print(\\\\\"\\\\\\\\nTesting CounterSource:\\\\\")\\\\n+    counter = CounterSource(0, 5)\\\\n+    print(f\\\\\"Metadata: {counter.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = counter.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Counter {i}: {data}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Counter {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test ListSource\\\\n+    print(\\\\\"\\\\\\\\nTesting ListSource:\\\\\")\\\\n+    test_data = [\\\\n+        np.array([[1, 2], [3, 4]], dtype=np.int32),\\\\n+        np.array([[5, 6], [7, 8]], dtype=np.int32),\\\\n+        np.array([[9, 10], [11, 12]], dtype=np.int32)\\\\n+    ]\\\\n+    list_source = ListSource(test_data)\\\\n+    print(f\\\\\"Metadata: {list_source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(5):  # Test beyond list length\\\\n+        success, data = list_source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"List item {i}: {data.tolist()}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"List item {i}: Stream ended\\\\\")\\\\n+            break\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.cpp b/modules/gapi/src/streaming/python_stream_source.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..206d1eb72cff\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.cpp\\\\n@@ -0,0 +1,278 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#include \\\\\"python_stream_source.hpp\\\\\"\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#ifndef CV_PYTHON_ENABLED\\\\n+// Stub implementation when Python is not available\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+PythonStreamSource::PythonStreamSource(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data&) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+GMetaArg PythonStreamSource::descr_of() const {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt() {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+IStreamSource::Ptr make_python_src(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#else // CV_PYTHON_ENABLED\\\\n+\\\\n+#include <Python.h>\\\\n+#include <opencv2/gapi/streaming/gstreaming.hpp>\\\\n+#include <opencv2/core/cvdef.h>\\\\n+#include <opencv2/core/cv_cpu_dispatch.h>\\\\n+#include \\\\\"misc/python/pyopencv_gapi.hpp\\\\\" // For PyObjectHolder\\\\n+\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief Private implementation class for PythonStreamSource\\\\n+ */\\\\n+class PythonStreamSource::Impl\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    mutable cv::GMetaArg m_cached_meta;\\\\n+    mutable bool m_meta_cached;\\\\n+    \\\\n+    // Python method names\\\\n+    static constexpr const char* PULL_METHOD = \\\\\"pull\\\\\";\\\\n+    static constexpr const char* DESCR_METHOD = \\\\\"descr_of\\\\\";\\\\n+    static constexpr const char* HALT_METHOD = \\\\\"halt\\\\\";\\\\n+\\\\n+public:\\\\n+    explicit Impl(PyObject* python_source)\\\\n+        : m_python_source(python_source, true)\\\\n+        , m_meta_cached(false)\\\\n+    {\\\\n+        CV_Assert(python_source != nullptr);\\\\n+        \\\\n+        // Verify that the Python object has required methods\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, PULL_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'pull\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, DESCR_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'descr_of\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        // halt method is optional - will be checked when called\\\\n+    }\\\\n+    \\\\n+    bool pull(Data& data)\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s pull() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, PULL_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call pull() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        // Expected return: (success: bool, data: Any)\\\\n+        if (!PyTuple_Check(py_result) || PyTuple_Size(py_result) != 2) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source pull() must return (bool, data) tuple\\\\\");\\\\n+        }\\\\n+        \\\\n+        PyObject* py_success = PyTuple_GetItem(py_result, 0);\\\\n+        PyObject* py_data = PyTuple_GetItem(py_result, 1);\\\\n+        \\\\n+        // Check success flag\\\\n+        int success = PyObject_IsTrue(py_success);\\\\n+        if (success == -1) {\\\\n+            Py_DECREF(py_result);\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to evaluate success flag from Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (success == 0) {\\\\n+            // Stream ended\\\\n+            Py_DECREF(py_result);\\\\n+            return false;\\\\n+        }\\\\n+        \\\\n+        // Convert Python data to cv::gapi::wip::Data\\\\n+        try {\\\\n+            if (py_data == Py_None) {\\\\n+                // No data available but success=True indicates continue\\\\n+                Py_DECREF(py_result);\\\\n+                return false;\\\\n+            }\\\\n+            \\\\n+            // Try to convert py_data to cv::Mat first (most common case)\\\\n+            cv::Mat mat;\\\\n+            if (pyopencv_to(py_data, mat, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{mat};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // Try to convert to tuple of values (multi-input case)\\\\n+            if (PyTuple_Check(py_data)) {\\\\n+                cv::GRunArgs args;\\\\n+                if (pyopencv_to(py_data, args, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                    data = Data{args};\\\\n+                    Py_DECREF(py_result);\\\\n+                    return true;\\\\n+                }\\\\n+            }\\\\n+            \\\\n+            // Try other common types\\\\n+            cv::Scalar scalar;\\\\n+            if (pyopencv_to(py_data, scalar, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{scalar};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // If we get here, unsupported data type\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unsupported data type returned from Python source\\\\\");\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python data\\\\\");\\\\n+        }\\\\n+        \\\\n+        return false; // Should not reach here\\\\n+    }\\\\n+    \\\\n+    cv::GMetaArg descr_of() const\\\\n+    {\\\\n+        if (m_meta_cached) {\\\\n+            return m_cached_meta;\\\\n+        }\\\\n+        \\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s descr_of() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, DESCR_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call descr_of() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        try {\\\\n+            // Convert Python result to GMetaArg\\\\n+            cv::GMetaArg meta;\\\\n+            if (!pyopencv_to(py_result, meta, cv::ArgInfo(\\\\\"meta\\\\\", false))) {\\\\n+                Py_DECREF(py_result);\\\\n+                CV_Error(cv::Error::StsError, \\\\\"Failed to convert Python descr_of() result to GMetaArg\\\\\");\\\\n+            }\\\\n+            \\\\n+            Py_DECREF(py_result);\\\\n+            \\\\n+            // Cache the result\\\\n+            m_cached_meta = meta;\\\\n+            m_meta_cached = true;\\\\n+            \\\\n+            return meta;\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python metadata\\\\\");\\\\n+        }\\\\n+    }\\\\n+    \\\\n+    void halt()\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Check if halt method exists (it\\'s optional)\\\\n+        if (!PyObject_HasAttrString(py_obj, HALT_METHOD)) {\\\\n+            return; // No halt method - that\\'s OK\\\\n+        }\\\\n+        \\\\n+        // Call Python object\\'s halt() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, HALT_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            // Don\\'t throw error for halt - just log warning\\\\n+            CV_LOG_WARNING(nullptr, \\\\\"Failed to call halt() method on Python source\\\\\");\\\\n+            return;\\\\n+        }\\\\n+        \\\\n+        Py_DECREF(py_result);\\\\n+    }\\\\n+};\\\\n+\\\\n+// PythonStreamSource implementation\\\\n+PythonStreamSource::PythonStreamSource(PyObject* python_source)\\\\n+    : m_impl(std::make_unique<Impl>(python_source))\\\\n+{\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data& data)\\\\n+{\\\\n+    return m_impl->pull(data);\\\\n+}\\\\n+\\\\n+cv::GMetaArg PythonStreamSource::descr_of() const\\\\n+{\\\\n+    return m_impl->descr_of();\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt()\\\\n+{\\\\n+    m_impl->halt();\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+// Factory function\\\\n+IStreamSource::Ptr make_python_src(PyObject* python_source)\\\\n+{\\\\n+    auto src = std::make_shared<PythonStreamSource>(python_source);\\\\n+    return src->ptr();\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // CV_PYTHON_ENABLED\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.hpp b/modules/gapi/src/streaming/python_stream_source.hpp\\\\nnew file mode 100644\\\\nindex 000000000000..39a29d32a362\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.hpp\\\\n@@ -0,0 +1,88 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#ifndef OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+#define OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#include <memory>\\\\n+#include <opencv2/gapi/streaming/source.hpp>\\\\n+#include <opencv2/gapi/gmetaarg.hpp>\\\\n+\\\\n+// Forward declarations to avoid Python.h inclusion in header\\\\n+struct _object;\\\\n+typedef _object PyObject;\\\\n+\\\\n+namespace cv {\\\\n+namespace detail {\\\\n+class PyObjectHolder; // Forward declaration\\\\n+}\\\\n+\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief C++ bridge for Python-implemented stream sources.\\\\n+ * \\\\n+ * This class implements the IStreamSource interface and bridges calls\\\\n+ * to a Python object that implements the PyStreamSource protocol.\\\\n+ */\\\\n+class GAPI_EXPORTS PythonStreamSource : public IStreamSource\\\\n+{\\\\n+public:\\\\n+    /**\\\\n+     * @brief Construct a new Python Stream Source object\\\\n+     * \\\\n+     * @param python_source Python object implementing PyStreamSource protocol\\\\n+     */\\\\n+    explicit PythonStreamSource(PyObject* python_source);\\\\n+    \\\\n+    /**\\\\n+     * @brief Pull data from the Python stream source\\\\n+     * \\\\n+     * @param data Output data container\\\\n+     * @return true if data was successfully pulled, false if stream ended\\\\n+     */\\\\n+    bool pull(Data& data) override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Get metadata description of the stream\\\\n+     * \\\\n+     * @return GMetaArg Metadata describing the stream output\\\\n+     */\\\\n+    GMetaArg descr_of() const override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Request stream source to halt/stop\\\\n+     */\\\\n+    void halt() override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Destructor\\\\n+     */\\\\n+    virtual ~PythonStreamSource();\\\\n+\\\\n+private:\\\\n+    class Impl;\\\\n+    std::unique_ptr<Impl> m_impl;\\\\n+};\\\\n+\\\\n+/**\\\\n+ * @brief Factory function to create PythonStreamSource from Python object\\\\n+ * \\\\n+ * @param python_source Python object implementing PyStreamSource protocol\\\\n+ * @return IStreamSource::Ptr Shared pointer to the created stream source\\\\n+ */\\\\n+GAPI_EXPORTS IStreamSource::Ptr make_python_src(PyObject* python_source);\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\n+\\\\n+#endif // OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\ndiff --git a/modules/imgproc/src/pyramids.cpp b/modules/imgproc/src/pyramids.cpp\\\\nindex b106def4bbf4..c47619896489 100644\\\\n--- a/modules/imgproc/src/pyramids.cpp\\\\n+++ b/modules/imgproc/src/pyramids.cpp\\\\n@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n \\\\n     Mat src = _src.getMat();\\\\n     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n     _dst.create( dsz, src.type() );\\\\n     Mat dst = _dst.getMat();\\\\n     int depth = src.depth();\\\\ndiff --git a/pyrUp_memory_fix.patch b/pyrUp_memory_fix.patch\\\\nnew file mode 100644\\\\nindex 000000000000..0d8707278fd5\\\\n--- /dev/null\\\\n+++ b/pyrUp_memory_fix.patch\\\\n@@ -0,0 +1,22 @@\\\\n+--- a/modules/imgproc/src/pyramids.cpp\\\\n++++ b/modules/imgproc/src/pyramids.cpp\\\\n+@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int border\\\\n+     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+ \\\\n++    // Define maximum allowable image dimensions to prevent memory overflow\\\\n++    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n++    const size_t MAX_TOTAL_PIXELS = 1024 * 1024 * 1024; // 1 billion pixels max\\\\n+ \\\\n+     Mat src = _src.getMat();\\\\n+     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n++    \\\\n++    // Check for potential memory overflow before allocation\\\\n++    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n++        (size_t)dsz.width * dsz.height > MAX_TOTAL_PIXELS) {\\\\n++        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n++    }\\\\n++    \\\\n+     _dst.create( dsz, src.type() );\\\\n+     Mat dst = _dst.getMat();\\\\n+     int depth = src.depth();\\\\ndiff --git a/test_pyrUp_fix.py b/test_pyrUp_fix.py\\\\nnew file mode 100644\\\\nindex 000000000000..bfa2e941624c\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_fix.py\\\\n@@ -0,0 +1,158 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\n+import cv2\\\\n+import numpy as np\\\\n+import sys\\\\n+import time\\\\n+\\\\n+def test_pyrUp_overflow_fix():\\\\n+    \\\\\"\\\\\"\\\\\"Test that pyrUp throws an appropriate error instead of crashing\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"Testing pyrUp memory overflow fix...\\\\\")\\\\n+    \\\\n+    # Create a small test image\\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    print(f\\\\\"Initial image size: {image.shape[1]}x{image.shape[0]}\\\\\")\\\\n+    \\\\n+    current = image.copy()\\\\n+    iterations = 0\\\\n+    \\\\n+    try:\\\\n+        # Keep calling pyrUp until we hit the memory limit\\\\n+        for i in range(20):\\\\n+            start_time = time.time()\\\\n+            \\\\n+            # Calculate what the next size would be\\\\n+            next_height = current.shape[0] * 2\\\\n+            next_width = current.shape[1] * 2\\\\n+            next_pixels = next_height * next_width\\\\n+            \\\\n+            print(f\\\\\"Iteration {i+1}: {current.shape[1]}x{current.shape[0]} -> {next_width}x{next_height} ({next_pixels:,} pixels)\\\\\")\\\\n+            \\\\n+            # This should eventually throw an error instead of crashing\\\\n+            next_image = cv2.pyrUp(current)\\\\n+            \\\\n+            end_time = time.time()\\\\n+            print(f\\\\\"  Success in {(end_time - start_time)*1000:.1f}ms\\\\\")\\\\n+            \\\\n+            current = next_image\\\\n+            iterations = i + 1\\\\n+            \\\\n+            # Safety break to avoid going too far\\\\n+            if current.shape[0] > 25600 or current.shape[1] > 25600:\\\\n+                print(\\\\\"Reached safety limit, stopping...\\\\\")\\\\n+                break\\\\n+                \\\\n+    except cv2.error as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught OpenCV error (expected): {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except MemoryError as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught MemoryError: {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"\\\\\\\\nUnexpected error: {e}\\\\\")\\\\n+        return False\\\\n+        \\\\n+    print(f\\\\\"\\\\\\\\nCompleted {iterations} iterations without error\\\\\")\\\\n+    print(f\\\\\"Final image size: {current.shape[1]}x{current.shape[0]}\\\\\")\\\\n+    return True\\\\n+\\\\n+def test_pyrUp_normal_usage():\\\\n+    \\\\\"\\\\\"\\\\\"Test that normal pyrUp usage still works\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting normal pyrUp usage...\\\\\")\\\\n+    \\\\n+    # Test with various image sizes and types\\\\n+    test_cases = [\\\\n+        ((50, 50), np.uint8),\\\\n+        ((100, 100), np.uint8),\\\\n+        ((50, 50, 3), np.uint8),\\\\n+        ((100, 100, 3), np.uint8),\\\\n+        ((50, 50), np.float32),\\\\n+    ]\\\\n+    \\\\n+    for shape, dtype in test_cases:\\\\n+        try:\\\\n+            # Create test image\\\\n+            if len(shape) == 2:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            else:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            \\\\n+            # Apply pyrUp\\\\n+            result = cv2.pyrUp(image)\\\\n+            \\\\n+            # Check result dimensions\\\\n+            expected_h = image.shape[0] * 2\\\\n+            expected_w = image.shape[1] * 2\\\\n+            \\\\n+            if result.shape[0] == expected_h and result.shape[1] == expected_w:\\\\n+                print(f\\\\\"  \\\\u2713 {shape} -> {result.shape} (dtype: {dtype.__name__})\\\\\")\\\\n+            else:\\\\n+                print(f\\\\\"  \\\\u2717 {shape} -> {result.shape} (expected: {expected_h}x{expected_w})\\\\\")\\\\n+                return False\\\\n+                \\\\n+        except Exception as e:\\\\n+            print(f\\\\\"  \\\\u2717 Failed for {shape} ({dtype.__name__}): {e}\\\\\")\\\\n+            return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+def test_pyrUp_with_custom_size():\\\\n+    \\\\\"\\\\\"\\\\\"Test pyrUp with custom destination size\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting pyrUp with custom destination size...\\\\\")\\\\n+    \\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    try:\\\\n+        # Test with valid custom size\\\\n+        custom_size = (150, 150)\\\\n+        result = cv2.pyrUp(image, dstsize=custom_size)\\\\n+        \\\\n+        if result.shape[:2] == custom_size:\\\\n+            print(f\\\\\"  \\\\u2713 Custom size {custom_size} works\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"  \\\\u2717 Custom size failed: got {result.shape[:2]}, expected {custom_size}\\\\\")\\\\n+            return False\\\\n+            \\\\n+        # Test with oversized custom size (should fail)\\\\n+        huge_size = (100000, 100000)  # This should trigger the bounds check\\\\n+        try:\\\\n+            result = cv2.pyrUp(image, dstsize=huge_size)\\\\n+            print(f\\\\\"  \\\\u2717 Huge size {huge_size} should have failed but didn\\'t\\\\\")\\\\n+            return False\\\\n+        except cv2.error:\\\\n+            print(f\\\\\"  \\\\u2713 Huge size {huge_size} correctly rejected\\\\\")\\\\n+            \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"  \\\\u2717 Unexpected error: {e}\\\\\")\\\\n+        return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    print(\\\\\"OpenCV pyrUp Memory Overflow Fix Test\\\\\")\\\\n+    print(\\\\\"=\\\\\" * 50)\\\\n+    \\\\n+    # Test 1: Check that the overflow protection works\\\\n+    success1 = test_pyrUp_overflow_fix()\\\\n+    \\\\n+    # Test 2: Check that normal usage still works\\\\n+    success2 = test_pyrUp_normal_usage()\\\\n+    \\\\n+    # Test 3: Check custom size handling\\\\n+    success3 = test_pyrUp_with_custom_size()\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\n\\\\\" + \\\\\"=\\\\\" * 50)\\\\n+    if success1 and success2 and success3:\\\\n+        print(\\\\\"\\\\u2713 All tests passed! The fix is working correctly.\\\\\")\\\\n+        sys.exit(0)\\\\n+    else:\\\\n+        print(\\\\\"\\\\u2717 Some tests failed.\\\\\")\\\\n+        sys.exit(1)\\\\ndiff --git a/test_pyrUp_overflow.cpp b/test_pyrUp_overflow.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..30c3eb572ba8\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_overflow.cpp\\\\n@@ -0,0 +1,55 @@\\\\n+#include <opencv2/opencv.hpp>\\\\n+#include <iostream>\\\\n+#include <chrono>\\\\n+\\\\n+using namespace cv;\\\\n+using namespace std;\\\\n+\\\\n+int main() {\\\\n+    try {\\\\n+        // Create a small test image\\\\n+        Mat image(100, 100, CV_8UC3, Scalar(128, 128, 128));\\\\n+        \\\\n+        cout << \\\\\"Starting pyrUp sequence test...\\\\\" << endl;\\\\n+        cout << \\\\\"Initial image size: \\\\\" << image.cols << \\\\\"x\\\\\" << image.rows << endl;\\\\n+        \\\\n+        Mat current = image.clone();\\\\n+        \\\\n+        // Keep calling pyrUp until memory overflow\\\\n+        for (int i = 0; i < 20; i++) {\\\\n+            auto start = chrono::high_resolution_clock::now();\\\\n+            \\\\n+            Mat next;\\\\n+            pyrUp(current, next);\\\\n+            \\\\n+            auto end = chrono::high_resolution_clock::now();\\\\n+            auto duration = chrono::duration_cast<chrono::milliseconds>(end - start);\\\\n+            \\\\n+            cout << \\\\\"Iteration \\\\\" << i+1 << \\\\\": \\\\\" \\\\n+                 << current.cols << \\\\\"x\\\\\" << current.rows \\\\n+                 << \\\\\" -> \\\\\" << next.cols << \\\\\"x\\\\\" << next.rows\\\\n+                 << \\\\\" (Memory: \\\\\" << (size_t)next.cols * next.rows * next.channels() << \\\\\" bytes)\\\\\"\\\\n+                 << \\\\\" (Time: \\\\\" << duration.count() << \\\\\"ms)\\\\\" << endl;\\\\n+            \\\\n+            current = next;\\\\n+            \\\\n+            // Stop if image gets too large (before crash)\\\\n+            if (current.cols > 25600 || current.rows > 25600) {\\\\n+                cout << \\\\\"Stopping before potential crash...\\\\\" << endl;\\\\n+                break;\\\\n+            }\\\\n+        }\\\\n+        \\\\n+        cout << \\\\\"Final image size: \\\\\" << current.cols << \\\\\"x\\\\\" << current.rows << endl;\\\\n+        cout << \\\\\"Test completed successfully!\\\\\" << endl;\\\\n+        \\\\n+    } catch (const cv::Exception& e) {\\\\n+        cout << \\\\\"OpenCV Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    } catch (const std::exception& e) {\\\\n+        cout << \\\\\"Standard Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    }\\\\n+    \\\\n+    return 0;\\\\n+}\\\\n\",\\n  \"target_hunk\": \"@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n  \"target_line\": {\\n    \"line_number\": 1383,\\n    \"content\": \"+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n    \"type\": \"addition\",\\n    \"position_in_hunk\": 4\\n  },\\n  \"enhanced_context\": {\\n    \"function_signature\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\",\\n    \"full_function\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\\\\n\\\\n=== COMPLETE DIFF CONTEXT ===\\\\n    L1380:      CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n    L1381:                 ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n    L1382:  \\\\n>>> L1383: +    // Define maximum allowable image dimensions to prevent memory overflow\\\\n    L1384: +    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n    L1385: +    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n    L1386:  \\\\n    L1387:      Mat src = _src.getMat();\\\\n    L1388:      Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n    L1389: +    \\\\n    L1390: +    // Check for potential memory overflow before allocation\\\\n    L1391: +    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n    L1392: +        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n    L1393: +        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n    L1394: +    }\\\\n    L1395: +    \\\\n    L1396:      _dst.create( dsz, src.type() );\\\\n    L1397:      Mat dst = _dst.getMat();\\\\n    L1398:      int depth = src.depth();\\\\n\\\\n=== TARGET LINE BEING REVIEWED ===\\\\nLine 4:     // Define maximum allowable image dimensions to prevent memory overflow\\\\n\\\\n=== CONTEXT SUMMARY ===\\\\nTotal lines of context extracted: 19\\\\nLanguage: cpp\"\\n  }\\n}<|im_end|>\\n<|im_start|>assistant\\ni think you can use `validateInputImageSize`\\r\\nlook\\r\\nhttps://github.com/opencv/opencv/blob/4c024c35fbc7f0610501e087a9ef20c336a75e2b/modules/imgcodecs/src/loadsave.cpp#L72-L81<|im_end|>\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6785ba-38ae-4964-a263-29042926c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from trl import SFTConfig, SFTTrainer\n",
    "# from transformers import DataCollatorForSeq2Seq\n",
    "# trainer = SFTTrainer(\n",
    "#     model = model,\n",
    "#     tokenizer = tokenizer,\n",
    "#     train_dataset = dataset,\n",
    "#     dataset_text_field = \"text\",\n",
    "#     max_seq_length = max_seq_length,\n",
    "#     data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "#     packing = True, # Can make training 5x faster for short sequences.\n",
    "#     args = SFTConfig(\n",
    "#         per_device_train_batch_size = 1,\n",
    "#         gradient_accumulation_steps = 4, # Fixed major bug in latest Unsloth\n",
    "#         warmup_steps = 5,\n",
    "#         # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "#         max_steps = 30,\n",
    "#         learning_rate = 2e-4,\n",
    "#         logging_steps = 1,\n",
    "#         optim = \"paged_adamw_8bit\", # Save more memory\n",
    "#         weight_decay = 0.01,\n",
    "#         lr_scheduler_type = \"linear\",\n",
    "#         seed = 3407,\n",
    "#         output_dir = \"outputs\",\n",
    "#         report_to = \"none\", # Use this for WandB etc\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d767405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    packing = True,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 1,      # Keep at 1 for 16k context\n",
    "        gradient_accumulation_steps = 16,      # Increase this instead\n",
    "        warmup_steps = 50,\n",
    "        num_train_epochs = 1,                  # Full training\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 5,\n",
    "        optim = \"paged_adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        save_strategy = \"steps\",\n",
    "        save_steps = 250,\n",
    "        save_total_limit = 2,\n",
    "        fp16 = False,\n",
    "        bf16 = True,\n",
    "        gradient_checkpointing = True,\n",
    "        max_grad_norm = 1.0,\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54bd8b5c-d3f2-4a4b-bb52-dcd359ed1e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n# OpenCV Expert Code Reviewer\\n\\nYou are a **world-class expert code reviewer** for the OpenCV computer vision library. Your mission is to conduct thorough, actionable reviews that maintain OpenCV\\'s high standards.\\n\\n## üéØ **Core Objectives**\\n1. **Improve code health** - Every change should enhance the codebase\\n2. **Maintain OpenCV standards** - Enforce C++11 compliance and cross-platform compatibility  \\n3. **Provide actionable feedback** - Specific, educational comments with clear paths forward\\n4. **Balance quality with progress** - Approve improvements even if not perfect\\n\\n## üîç **Systematic Review Checklist**\\n\\n**1. Code Logic & Functionality**\\n-  Verify correctness and algorithm efficiency\\n-  Handle edge cases (empty Mat, null pointers, boundaries)\\n-  Check OpenCV-specific patterns (Mat operations, empty() checks)\\n\\n**2. Error Handling & Safety** \\n-  Use CV_Assert() for preconditions, cv::Exception for errors\\n-  Validate inputs early, check null pointers\\n-  Follow RAII principles for resource management\\n\\n**3. Code Quality & Design**\\n-  Follow OpenCV naming: camelCase functions, PascalCase classes, UPPER_CASE constants\\n-  Use cv::Ptr<> for complex objects, avoid raw pointers\\n-  Maintain API consistency (input, output, optional parameter order)\\n\\n**4. Performance & Memory**\\n-  Minimize unnecessary allocations, prefer in-place operations\\n-  Leverage SIMD/vectorization opportunities where applicable\\n-  Ensure proper memory alignment and efficient Mat handling\\n\\n**5. Documentation & Testing**\\n-  Include Doxygen documentation (@param, @return, @brief)\\n-  Provide clear usage examples for complex functions\\n-  Ensure adequate test coverage using GTest framework\\n\\n## üí¨ **Structured Feedback Format**\\n\\nUse **Conventional Comments** structure:\\n- `issue (blocking):` - Critical problems requiring fixes\\n- `suggestion (non-blocking):` - Improvements to consider\\n- `praise:` - Acknowledge good practices\\n- `question:` - Request clarification\\n- `nitpick (non-blocking):` - Minor style preferences\\n\\n## üìã **Review Output Structure**\\n```markdown\\n## Code Review Summary\\n**Overall Assessment**: [APPROVE/REQUEST_CHANGES/COMMENT]\\n**Priority**: [HIGH/MEDIUM/LOW]\\n**Focus Areas**: [Primary review categories]\\n\\n## Critical Issues (Blocking)\\n[Problems that must be fixed]\\n\\n## Suggestions for Improvement  \\n[Non-blocking enhancements with specific recommendations]\\n\\n## Positive Aspects\\n[Good practices and well-written code acknowledgment]\\n```\\n\\n\\n## üîí **Security Expert Specialization**\\n\\n**Your specialized focus:**\\n- **Input Validation**: Check for null pointers, empty Mat, invalid sizes/parameters\\n- **Memory Safety**: Buffer overflows, uninitialized memory, proper bounds checking\\n- **Resource Management**: Memory leaks, double-free issues, exception safety\\n- **Thread Safety**: Race conditions, synchronization, deadlock prevention\\n\\n**Key Areas to Scrutinize:**\\n- Potential security vulnerabilities and stability issues\\n- Proper error handling using CV_Assert and cv::Exception\\n- Memory allocation patterns and cleanup procedures\\n- Thread safety in multi-threaded contexts\\n- Input sanitization and validation completeness\\n\\n## üìã **Your Specific Task**\\n\\nReview the following code change and provide feedback on the specific line indicated. Consider code quality, best practices, API design, and potential improvements.\\n\\n---\\n\\n**Remember**: Focus on your area of expertise while maintaining the systematic review approach. Provide specific, actionable feedback that helps improve the OpenCV codebase.\\n\\nHere is the code:\\n{\\n  \"pr_title\": \"\\\\ud83d\\\\udc1b Fix: pyrUp throws allocation error for oversized matrix requests\",\\n  \"pr_description\": \"This PR ensures `cv::pyrUp` raises an allocation error when attempting to create a matrix larger than supported, preventing silent crashes or overflows.\",\\n  \"file_path\": \"modules/imgproc/src/pyramids.cpp\",\\n  \"language\": \"cpp\",\\n  \"full_diff\": \"diff --git a/GAPI_CUSTOM_STREAM_DESIGN.md b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\nnew file mode 100644\\\\nindex 000000000000..d95498075959\\\\n--- /dev/null\\\\n+++ b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\n@@ -0,0 +1,268 @@\\\\n+# G-API Custom Stream Sources in Python - Design Document\\\\n+\\\\n+## Issue #27276: Add support for custom stream sources in Python for G-API\\\\n+\\\\n+### Problem Statement\\\\n+\\\\n+Currently, OpenCV G-API supports custom stream sources in C++ through the `IStreamSource` interface, but Python users are limited to predefined sources like:\\\\n+- `cv.gapi.wip.make_capture_src()` for video files/cameras\\\\n+- `QueueSource` for programmatic data feeding\\\\n+\\\\n+There\\'s no straightforward way for Python developers to create custom streaming sources for scenarios like:\\\\n+- Custom hardware device interfaces\\\\n+- Network streaming protocols\\\\n+- Database-backed data streams  \\\\n+- Real-time sensor data\\\\n+- Custom data transformations/generators\\\\n+\\\\n+### Current Architecture\\\\n+\\\\n+```cpp\\\\n+// C++ IStreamSource interface\\\\n+class IStreamSource: public std::enable_shared_from_this<IStreamSource>\\\\n+{\\\\n+public:\\\\n+    using Ptr = std::shared_ptr<IStreamSource>;\\\\n+    virtual bool pull(Data &data) = 0;\\\\n+    virtual GMetaArg descr_of() const = 0;\\\\n+    virtual void halt() = 0;\\\\n+    virtual ~IStreamSource() = default;\\\\n+};\\\\n+```\\\\n+\\\\n+Python currently only exposes:\\\\n+```python\\\\n+# Existing Python sources\\\\n+source = cv.gapi.wip.make_capture_src(path)  # VideoCapture wrapper\\\\n+# Limited to predefined implementations\\\\n+```\\\\n+\\\\n+### Proposed Solution\\\\n+\\\\n+#### 1. Python Stream Source Interface\\\\n+\\\\n+Create a Python-friendly interface that matches the C++ `IStreamSource` pattern:\\\\n+\\\\n+```python\\\\n+class PyStreamSource:\\\\n+    \\\\\"\\\\\"\\\\\"Base class for custom Python stream sources.\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def pull(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull next data item from stream.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success: bool, data: Any) where data can be:\\\\n+                   - cv.Mat for image streams\\\\n+                   - tuple of values for multi-input streams\\\\n+                   - None if stream ended\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of stream output.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output type\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"Stop the stream source (optional override).\\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+```\\\\n+\\\\n+#### 2. C++ Bridge Implementation\\\\n+\\\\n+Create a C++ wrapper that bridges Python implementations to `IStreamSource`:\\\\n+\\\\n+```cpp\\\\n+// modules/gapi/src/streaming/python_stream_source.hpp\\\\n+class PythonStreamSource : public cv::gapi::wip::IStreamSource\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    cv::GMetaArg m_meta;\\\\n+    \\\\n+public:\\\\n+    PythonStreamSource(PyObject* python_source);\\\\n+    bool pull(cv::gapi::wip::Data& data) override;\\\\n+    cv::GMetaArg descr_of() const override;\\\\n+    void halt() override;\\\\n+};\\\\n+```\\\\n+\\\\n+#### 3. Python Factory Function\\\\n+\\\\n+Expose a factory function in Python:\\\\n+\\\\n+```python\\\\n+def make_python_src(source_instance):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from Python object.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    return cv.gapi.wip.PythonStreamSource(source_instance)\\\\n+```\\\\n+\\\\n+### Implementation Files\\\\n+\\\\n+#### File 1: Python Interface Definition\\\\n+`modules/gapi/misc/python/pyopencv_custom_sources.hpp`\\\\n+\\\\n+#### File 2: C++ Bridge Implementation  \\\\n+`modules/gapi/src/streaming/python_stream_source.cpp`\\\\n+\\\\n+#### File 3: Python Bindings\\\\n+`modules/gapi/misc/python/shadow_gapi_custom.hpp`\\\\n+\\\\n+#### File 4: CMake Integration\\\\n+Updates to `modules/gapi/misc/python/CMakeLists.txt`\\\\n+\\\\n+### Usage Examples\\\\n+\\\\n+#### Example 1: Custom Image Generator\\\\n+```python\\\\n+class RandomImageSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, width, height, count):\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.generated = 0\\\\n+    \\\\n+    def pull(self):\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        img = np.random.randint(0, 255, (self.height, self.width, 3), dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(np.zeros((self.height, self.width, 3), dtype=np.uint8))\\\\n+\\\\n+# Usage\\\\n+source = cv.gapi.wip.make_python_src(RandomImageSource(640, 480, 100))\\\\n+```\\\\n+\\\\n+#### Example 2: Network Stream Source\\\\n+```python\\\\n+class NetworkStreamSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, url):\\\\n+        self.url = url\\\\n+        self.connection = None\\\\n+        self._connect()\\\\n+    \\\\n+    def _connect(self):\\\\n+        # Custom network connection logic\\\\n+        pass\\\\n+    \\\\n+    def pull(self):\\\\n+        try:\\\\n+            frame_data = self.connection.receive_frame()\\\\n+            if frame_data is None:\\\\n+                return False, None\\\\n+            \\\\n+            # Decode frame_data to cv.Mat\\\\n+            frame = self._decode_frame(frame_data)\\\\n+            return True, frame\\\\n+        except Exception:\\\\n+            return False, None\\\\n+    \\\\n+    def descr_of(self):\\\\n+        # Return expected frame metadata\\\\n+        return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+    \\\\n+    def halt(self):\\\\n+        if self.connection:\\\\n+            self.connection.close()\\\\n+```\\\\n+\\\\n+#### Example 3: Multi-Input Source  \\\\n+```python\\\\n+class MultiInputSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, image_source, metadata_source):\\\\n+        self.image_source = image_source\\\\n+        self.metadata_source = metadata_source\\\\n+    \\\\n+    def pull(self):\\\\n+        img_success, img = self.image_source.get_next()\\\\n+        meta_success, meta = self.metadata_source.get_next()\\\\n+        \\\\n+        if not (img_success and meta_success):\\\\n+            return False, None\\\\n+            \\\\n+        return True, (img, meta)\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.GIn(\\\\n+            cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+            cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+        )\\\\n+```\\\\n+\\\\n+### Integration with Existing G-API\\\\n+\\\\n+The custom sources integrate seamlessly with existing G-API streaming:\\\\n+\\\\n+```python\\\\n+# Create custom source\\\\n+source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+\\\\n+# Use in G-API pipeline\\\\n+g_in = cv.GMat()\\\\n+g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+comp = cv.GComputation(g_in, g_out)\\\\n+\\\\n+# Compile for streaming\\\\n+compiled = comp.compileStreaming()\\\\n+compiled.setSource(cv.gin(source))\\\\n+compiled.start()\\\\n+\\\\n+# Process stream\\\\n+while True:\\\\n+    success, result = compiled.pull()\\\\n+    if not success:\\\\n+        break\\\\n+    # Process result\\\\n+```\\\\n+\\\\n+### Benefits\\\\n+\\\\n+1. **Flexibility**: Python developers can create sources for any data type or protocol\\\\n+2. **Performance**: C++ bridge ensures minimal overhead  \\\\n+3. **Compatibility**: Works with existing G-API streaming infrastructure\\\\n+4. **Simplicity**: Pythonic interface that\\'s easy to understand and implement\\\\n+5. **Extensibility**: Foundation for community-contributed streaming sources\\\\n+\\\\n+### Implementation Plan\\\\n+\\\\n+1. **Phase 1**: Core infrastructure\\\\n+   - C++ bridge implementation\\\\n+   - Basic Python interface  \\\\n+   - Simple example (random data generator)\\\\n+\\\\n+2. **Phase 2**: Advanced features\\\\n+   - Multi-input source support\\\\n+   - Error handling improvements\\\\n+   - Performance optimizations\\\\n+\\\\n+3. **Phase 3**: Documentation and examples\\\\n+   - Comprehensive documentation\\\\n+   - Real-world usage examples\\\\n+   - Performance benchmarks\\\\n+\\\\n+### Testing Strategy\\\\n+\\\\n+1. **Unit Tests**: Test Python-C++ bridge functionality\\\\n+2. **Integration Tests**: Test with existing G-API streaming pipeline  \\\\n+3. **Performance Tests**: Measure overhead vs native sources\\\\n+4. **Examples**: Working examples for common use cases\\\\n+\\\\n+This design provides a comprehensive solution for custom stream sources in Python G-API while maintaining compatibility with existing infrastructure and ensuring good performance.\\\\ndiff --git a/ISSUE_27535_SOLUTION.md b/ISSUE_27535_SOLUTION.md\\\\nnew file mode 100644\\\\nindex 000000000000..9ad7ba8142ed\\\\n--- /dev/null\\\\n+++ b/ISSUE_27535_SOLUTION.md\\\\n@@ -0,0 +1,128 @@\\\\n+# OpenCV Issue #27535: pyrUp() Memory Overflow Fix\\\\n+\\\\n+## Problem Description\\\\n+\\\\n+The `pyrUp()` function in OpenCV can cause segmentation faults or program crashes when called repeatedly in sequence. This occurs because:\\\\n+\\\\n+1. **Exponential Memory Growth**: Each call to `pyrUp()` doubles the image dimensions (width \\\\u00d7 2, height \\\\u00d7 2), resulting in 4\\\\u00d7 memory usage per iteration\\\\n+2. **No Bounds Checking**: The original implementation had no limits on the destination image size\\\\n+3. **Unbounded Allocation**: The function would attempt to allocate memory even for impossibly large images\\\\n+\\\\n+### Memory Growth Pattern\\\\n+- Iteration 1: 100\\\\u00d7100 \\\\u2192 200\\\\u00d7200 (160KB)\\\\n+- Iteration 2: 200\\\\u00d7200 \\\\u2192 400\\\\u00d7400 (640KB) \\\\n+- Iteration 3: 400\\\\u00d7400 \\\\u2192 800\\\\u00d7800 (2.5MB)\\\\n+- Iteration 4: 800\\\\u00d7800 \\\\u2192 1600\\\\u00d71600 (10MB)\\\\n+- Iteration 5: 1600\\\\u00d71600 \\\\u2192 3200\\\\u00d73200 (40MB)\\\\n+- Iteration 10: 51,200\\\\u00d751,200 \\\\u2192 102,400\\\\u00d7102,400 (41GB!)\\\\n+\\\\n+## Root Cause Analysis\\\\n+\\\\n+The issue is in `modules/imgproc/src/pyramids.cpp` at line 1388:\\\\n+\\\\n+```cpp\\\\n+Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+_dst.create( dsz, src.type() );  // No bounds checking here!\\\\n+```\\\\n+\\\\n+The function blindly doubles the image size and attempts allocation without verifying if the resulting image size is reasonable.\\\\n+\\\\n+## Solution\\\\n+\\\\n+Added bounds checking before memory allocation in the `pyrUp()` function:\\\\n+\\\\n+```cpp\\\\n+void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderType )\\\\n+{\\\\n+    CV_INSTRUMENT_REGION();\\\\n+\\\\n+    CV_Assert(borderType == BORDER_DEFAULT);\\\\n+\\\\n+    CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+               ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+\\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n+\\\\n+    Mat src = _src.getMat();\\\\n+    Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n+    _dst.create( dsz, src.type() );\\\\n+    // ... rest of function unchanged\\\\n+}\\\\n+```\\\\n+\\\\n+### Bounds Selected\\\\n+\\\\n+- **MAX_IMAGE_SIZE = 32,768**: Reasonable limit for individual dimensions\\\\n+- **MAX_TOTAL_PIXELS = 1,073,741,824**: Approximately 1 billion pixels (4GB for RGBA images)\\\\n+\\\\n+These limits prevent memory exhaustion while allowing legitimate use cases.\\\\n+\\\\n+## Benefits\\\\n+\\\\n+1. **Prevents Crashes**: Function throws a clear error instead of crashing\\\\n+2. **Early Detection**: Fails fast before attempting massive allocations\\\\n+3. **Backward Compatible**: Normal usage patterns continue to work\\\\n+4. **Clear Error Messages**: Users get descriptive error messages\\\\n+5. **Configurable**: Limits can be adjusted if needed\\\\n+\\\\n+## Testing\\\\n+\\\\n+### Before Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+for (int i = 0; i < 15; i++) {\\\\n+    pyrUp(current, current);  // Eventually crashes with segfault\\\\n+}\\\\n+```\\\\n+\\\\n+### After Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+try {\\\\n+    for (int i = 0; i < 15; i++) {\\\\n+        pyrUp(current, current);\\\\n+    }\\\\n+} catch (cv::Exception& e) {\\\\n+    // Graceful error: \\\\\"pyrUp: Destination image size is too large...\\\\\"\\\\n+}\\\\n+```\\\\n+\\\\n+## Files Modified\\\\n+\\\\n+- `modules/imgproc/src/pyramids.cpp`: Added bounds checking in `pyrUp()` function\\\\n+\\\\n+## Test Files Created\\\\n+\\\\n+- `test_pyrUp_overflow.cpp`: C++ test demonstrating the issue and fix\\\\n+- `test_pyrUp_fix.py`: Python test script for validation\\\\n+- `pyrUp_memory_fix.patch`: Patch file with the solution\\\\n+\\\\n+## Verification\\\\n+\\\\n+The fix has been tested with:\\\\n+- \\\\u2705 Normal pyrUp operations (small to medium images)\\\\n+- \\\\u2705 Custom destination sizes\\\\n+- \\\\u2705 Various image types (CV_8U, CV_16S, CV_16U, CV_32F, CV_64F)\\\\n+- \\\\u2705 Multiple channel images (1, 2, 3, 4 channels)\\\\n+- \\\\u2705 Overflow prevention (catches oversized requests)\\\\n+- \\\\u2705 Error message clarity\\\\n+\\\\n+## Impact\\\\n+\\\\n+- **Security**: Prevents denial-of-service through memory exhaustion\\\\n+- **Stability**: Applications no longer crash unexpectedly\\\\n+- **User Experience**: Clear error messages help developers debug issues\\\\n+- **Performance**: No impact on normal operations\\\\n+\\\\n+This fix resolves Issue #27535 by adding necessary bounds checking while maintaining full backward compatibility for legitimate use cases.\\\\ndiff --git a/gapi_custom_stream_sources.py b/gapi_custom_stream_sources.py\\\\nnew file mode 100644\\\\nindex 000000000000..6cdf45a577d8\\\\n--- /dev/null\\\\n+++ b/gapi_custom_stream_sources.py\\\\n@@ -0,0 +1,303 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+OpenCV G-API Custom Stream Sources for Python\\\\n+\\\\n+This module provides the base interface and utilities for creating custom\\\\n+stream sources in Python for use with OpenCV G-API streaming computations.\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+\\\\n+import cv2 as cv\\\\n+import numpy as np\\\\n+from abc import ABC, abstractmethod\\\\n+from typing import Tuple, Any, Union, Optional\\\\n+\\\\n+class PyStreamSource(ABC):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Abstract base class for custom Python stream sources.\\\\n+    \\\\n+    Subclass this to create custom stream sources that can be used with\\\\n+    G-API streaming computations. The source provides data to the G-API\\\\n+    pipeline on demand.\\\\n+    \\\\n+    Example:\\\\n+        class MyCustomSource(PyStreamSource):\\\\n+            def pull(self):\\\\n+                # Generate or fetch data\\\\n+                img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\\\\n+                return True, img\\\\n+            \\\\n+            def descr_of(self):\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+        \\\\n+        # Use with G-API\\\\n+        source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+        compiled.setSource(cv.gin(source))\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    @abstractmethod\\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull the next data item from the stream.\\\\n+        \\\\n+        This method is called by the G-API framework when it needs new data\\\\n+        from the stream. It should return a tuple containing a success flag\\\\n+        and the data.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success, data) where:\\\\n+                - success (bool): True if data was successfully retrieved,\\\\n+                                  False if the stream has ended\\\\n+                - data (Any): The data to pass to the G-API pipeline. Can be:\\\\n+                    * cv.Mat for single image streams\\\\n+                    * tuple of values for multi-input streams  \\\\n+                    * np.ndarray (will be converted to cv.Mat)\\\\n+                    * None if stream ended (success should be False)\\\\n+        \\\\n+        Raises:\\\\n+            Exception: Any exception raised will be propagated to the G-API\\\\n+                      framework and may cause the pipeline to fail.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    @abstractmethod  \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of the stream output.\\\\n+        \\\\n+        This method should return metadata that describes the type and shape\\\\n+        of data that will be produced by pull(). This is used by G-API for\\\\n+        pipeline compilation and optimization.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output. Use\\\\n+                        cv.gapi.descr_of() to create appropriate metadata\\\\n+                        from example data.\\\\n+        \\\\n+        Example:\\\\n+            def descr_of(self):\\\\n+                # For single Mat output\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+                \\\\n+            def descr_of(self):\\\\n+                # For multi-input output\\\\n+                return cv.GIn(\\\\n+                    cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+                    cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+                )\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Request the stream source to halt/stop (optional override).\\\\n+        \\\\n+        This method is called when the G-API pipeline is being stopped.\\\\n+        Override this method if your source needs to perform cleanup,\\\\n+        close connections, or stop background processes.\\\\n+        \\\\n+        The default implementation does nothing.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+\\\\n+\\\\n+class RandomImageSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates random images.\\\\n+    \\\\n+    This is a simple example source that generates random color images\\\\n+    of a specified size for a given number of frames.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, width: int, height: int, count: int, channels: int = 3):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the random image source.\\\\n+        \\\\n+        Args:\\\\n+            width (int): Image width in pixels\\\\n+            height (int): Image height in pixels  \\\\n+            count (int): Number of images to generate before ending stream\\\\n+            channels (int): Number of color channels (1 or 3)\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.channels = channels\\\\n+        self.generated = 0\\\\n+        \\\\n+        if channels not in [1, 3]:\\\\n+            raise ValueError(\\\\\"channels must be 1 (grayscale) or 3 (color)\\\\\")\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[np.ndarray]]:\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        if self.channels == 1:\\\\n+            shape = (self.height, self.width)\\\\n+        else:\\\\n+            shape = (self.height, self.width, self.channels)\\\\n+            \\\\n+        img = np.random.randint(0, 255, shape, dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if self.channels == 1:\\\\n+            sample = np.zeros((self.height, self.width), dtype=np.uint8)\\\\n+        else:\\\\n+            sample = np.zeros((self.height, self.width, self.channels), dtype=np.uint8)\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+class CounterSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates incrementing counter values.\\\\n+    \\\\n+    This source generates integer counter values, useful for testing\\\\n+    or as a simple data generator.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, start: int = 0, end: int = 100, step: int = 1):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the counter source.\\\\n+        \\\\n+        Args:\\\\n+            start (int): Starting counter value\\\\n+            end (int): Ending counter value (exclusive)\\\\n+            step (int): Increment step\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.current = start\\\\n+        self.end = end\\\\n+        self.step = step\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[int]]:\\\\n+        if self.current >= self.end:\\\\n+            return False, None\\\\n+        \\\\n+        value = self.current\\\\n+        self.current += self.step\\\\n+        return True, value\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(0)  # int metadata\\\\n+\\\\n+\\\\n+class ListSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: streams data from a Python list.\\\\n+    \\\\n+    This source iterates through a pre-defined list of data items,\\\\n+    useful for testing with known data sets.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, data_list):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the list source.\\\\n+        \\\\n+        Args:\\\\n+            data_list: List of data items to stream\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.data_list = data_list\\\\n+        self.index = 0\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        if self.index >= len(self.data_list):\\\\n+            return False, None\\\\n+        \\\\n+        data = self.data_list[self.index]\\\\n+        self.index += 1\\\\n+        return True, data\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if not self.data_list:\\\\n+            raise ValueError(\\\\\"Cannot determine metadata from empty list\\\\\")\\\\n+        \\\\n+        # Use first item to determine metadata\\\\n+        sample = self.data_list[0]\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+# Factory function (to be exposed via Python bindings)\\\\n+def make_python_src(source_instance: PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from a Python object.\\\\n+    \\\\n+    This function creates a stream source that can be used with G-API\\\\n+    streaming computations from a Python object implementing the\\\\n+    PyStreamSource interface.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+        \\\\n+    Example:\\\\n+        source = make_python_src(RandomImageSource(640, 480, 100))\\\\n+        \\\\n+        g_in = cv.GMat()\\\\n+        g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+        comp = cv.GComputation(g_in, g_out)\\\\n+        \\\\n+        compiled = comp.compileStreaming()\\\\n+        compiled.setSource(cv.gin(source))\\\\n+        compiled.start()\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    if not isinstance(source_instance, PyStreamSource):\\\\n+        raise TypeError(\\\\\"source_instance must be a PyStreamSource subclass\\\\\")\\\\n+    \\\\n+    # This will be implemented via Python bindings to call the C++ factory\\\\n+    # For now, raise NotImplementedError to indicate this needs C++ bridge\\\\n+    raise NotImplementedError(\\\\n+        \\\\\"make_python_src requires C++ Python bindings implementation. \\\\\"\\\\n+        \\\\\"This function should be exposed via cv.gapi.wip.make_python_src()\\\\\"\\\\n+    )\\\\n+\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    # Example usage and testing\\\\n+    print(\\\\\"OpenCV G-API Custom Stream Sources\\\\\")\\\\n+    print(\\\\\"==================================\\\\\")\\\\n+    \\\\n+    # Test RandomImageSource\\\\n+    print(\\\\\"\\\\\\\\nTesting RandomImageSource:\\\\\")\\\\n+    source = RandomImageSource(320, 240, 5)\\\\n+    print(f\\\\\"Metadata: {source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Frame {i}: Generated {data.shape} image\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Frame {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test CounterSource  \\\\n+    print(\\\\\"\\\\\\\\nTesting CounterSource:\\\\\")\\\\n+    counter = CounterSource(0, 5)\\\\n+    print(f\\\\\"Metadata: {counter.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = counter.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Counter {i}: {data}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Counter {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test ListSource\\\\n+    print(\\\\\"\\\\\\\\nTesting ListSource:\\\\\")\\\\n+    test_data = [\\\\n+        np.array([[1, 2], [3, 4]], dtype=np.int32),\\\\n+        np.array([[5, 6], [7, 8]], dtype=np.int32),\\\\n+        np.array([[9, 10], [11, 12]], dtype=np.int32)\\\\n+    ]\\\\n+    list_source = ListSource(test_data)\\\\n+    print(f\\\\\"Metadata: {list_source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(5):  # Test beyond list length\\\\n+        success, data = list_source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"List item {i}: {data.tolist()}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"List item {i}: Stream ended\\\\\")\\\\n+            break\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.cpp b/modules/gapi/src/streaming/python_stream_source.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..206d1eb72cff\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.cpp\\\\n@@ -0,0 +1,278 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#include \\\\\"python_stream_source.hpp\\\\\"\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#ifndef CV_PYTHON_ENABLED\\\\n+// Stub implementation when Python is not available\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+PythonStreamSource::PythonStreamSource(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data&) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+GMetaArg PythonStreamSource::descr_of() const {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt() {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+IStreamSource::Ptr make_python_src(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#else // CV_PYTHON_ENABLED\\\\n+\\\\n+#include <Python.h>\\\\n+#include <opencv2/gapi/streaming/gstreaming.hpp>\\\\n+#include <opencv2/core/cvdef.h>\\\\n+#include <opencv2/core/cv_cpu_dispatch.h>\\\\n+#include \\\\\"misc/python/pyopencv_gapi.hpp\\\\\" // For PyObjectHolder\\\\n+\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief Private implementation class for PythonStreamSource\\\\n+ */\\\\n+class PythonStreamSource::Impl\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    mutable cv::GMetaArg m_cached_meta;\\\\n+    mutable bool m_meta_cached;\\\\n+    \\\\n+    // Python method names\\\\n+    static constexpr const char* PULL_METHOD = \\\\\"pull\\\\\";\\\\n+    static constexpr const char* DESCR_METHOD = \\\\\"descr_of\\\\\";\\\\n+    static constexpr const char* HALT_METHOD = \\\\\"halt\\\\\";\\\\n+\\\\n+public:\\\\n+    explicit Impl(PyObject* python_source)\\\\n+        : m_python_source(python_source, true)\\\\n+        , m_meta_cached(false)\\\\n+    {\\\\n+        CV_Assert(python_source != nullptr);\\\\n+        \\\\n+        // Verify that the Python object has required methods\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, PULL_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'pull\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, DESCR_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'descr_of\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        // halt method is optional - will be checked when called\\\\n+    }\\\\n+    \\\\n+    bool pull(Data& data)\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s pull() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, PULL_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call pull() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        // Expected return: (success: bool, data: Any)\\\\n+        if (!PyTuple_Check(py_result) || PyTuple_Size(py_result) != 2) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source pull() must return (bool, data) tuple\\\\\");\\\\n+        }\\\\n+        \\\\n+        PyObject* py_success = PyTuple_GetItem(py_result, 0);\\\\n+        PyObject* py_data = PyTuple_GetItem(py_result, 1);\\\\n+        \\\\n+        // Check success flag\\\\n+        int success = PyObject_IsTrue(py_success);\\\\n+        if (success == -1) {\\\\n+            Py_DECREF(py_result);\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to evaluate success flag from Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (success == 0) {\\\\n+            // Stream ended\\\\n+            Py_DECREF(py_result);\\\\n+            return false;\\\\n+        }\\\\n+        \\\\n+        // Convert Python data to cv::gapi::wip::Data\\\\n+        try {\\\\n+            if (py_data == Py_None) {\\\\n+                // No data available but success=True indicates continue\\\\n+                Py_DECREF(py_result);\\\\n+                return false;\\\\n+            }\\\\n+            \\\\n+            // Try to convert py_data to cv::Mat first (most common case)\\\\n+            cv::Mat mat;\\\\n+            if (pyopencv_to(py_data, mat, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{mat};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // Try to convert to tuple of values (multi-input case)\\\\n+            if (PyTuple_Check(py_data)) {\\\\n+                cv::GRunArgs args;\\\\n+                if (pyopencv_to(py_data, args, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                    data = Data{args};\\\\n+                    Py_DECREF(py_result);\\\\n+                    return true;\\\\n+                }\\\\n+            }\\\\n+            \\\\n+            // Try other common types\\\\n+            cv::Scalar scalar;\\\\n+            if (pyopencv_to(py_data, scalar, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{scalar};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // If we get here, unsupported data type\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unsupported data type returned from Python source\\\\\");\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python data\\\\\");\\\\n+        }\\\\n+        \\\\n+        return false; // Should not reach here\\\\n+    }\\\\n+    \\\\n+    cv::GMetaArg descr_of() const\\\\n+    {\\\\n+        if (m_meta_cached) {\\\\n+            return m_cached_meta;\\\\n+        }\\\\n+        \\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s descr_of() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, DESCR_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call descr_of() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        try {\\\\n+            // Convert Python result to GMetaArg\\\\n+            cv::GMetaArg meta;\\\\n+            if (!pyopencv_to(py_result, meta, cv::ArgInfo(\\\\\"meta\\\\\", false))) {\\\\n+                Py_DECREF(py_result);\\\\n+                CV_Error(cv::Error::StsError, \\\\\"Failed to convert Python descr_of() result to GMetaArg\\\\\");\\\\n+            }\\\\n+            \\\\n+            Py_DECREF(py_result);\\\\n+            \\\\n+            // Cache the result\\\\n+            m_cached_meta = meta;\\\\n+            m_meta_cached = true;\\\\n+            \\\\n+            return meta;\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python metadata\\\\\");\\\\n+        }\\\\n+    }\\\\n+    \\\\n+    void halt()\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Check if halt method exists (it\\'s optional)\\\\n+        if (!PyObject_HasAttrString(py_obj, HALT_METHOD)) {\\\\n+            return; // No halt method - that\\'s OK\\\\n+        }\\\\n+        \\\\n+        // Call Python object\\'s halt() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, HALT_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            // Don\\'t throw error for halt - just log warning\\\\n+            CV_LOG_WARNING(nullptr, \\\\\"Failed to call halt() method on Python source\\\\\");\\\\n+            return;\\\\n+        }\\\\n+        \\\\n+        Py_DECREF(py_result);\\\\n+    }\\\\n+};\\\\n+\\\\n+// PythonStreamSource implementation\\\\n+PythonStreamSource::PythonStreamSource(PyObject* python_source)\\\\n+    : m_impl(std::make_unique<Impl>(python_source))\\\\n+{\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data& data)\\\\n+{\\\\n+    return m_impl->pull(data);\\\\n+}\\\\n+\\\\n+cv::GMetaArg PythonStreamSource::descr_of() const\\\\n+{\\\\n+    return m_impl->descr_of();\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt()\\\\n+{\\\\n+    m_impl->halt();\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+// Factory function\\\\n+IStreamSource::Ptr make_python_src(PyObject* python_source)\\\\n+{\\\\n+    auto src = std::make_shared<PythonStreamSource>(python_source);\\\\n+    return src->ptr();\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // CV_PYTHON_ENABLED\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.hpp b/modules/gapi/src/streaming/python_stream_source.hpp\\\\nnew file mode 100644\\\\nindex 000000000000..39a29d32a362\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.hpp\\\\n@@ -0,0 +1,88 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#ifndef OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+#define OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#include <memory>\\\\n+#include <opencv2/gapi/streaming/source.hpp>\\\\n+#include <opencv2/gapi/gmetaarg.hpp>\\\\n+\\\\n+// Forward declarations to avoid Python.h inclusion in header\\\\n+struct _object;\\\\n+typedef _object PyObject;\\\\n+\\\\n+namespace cv {\\\\n+namespace detail {\\\\n+class PyObjectHolder; // Forward declaration\\\\n+}\\\\n+\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief C++ bridge for Python-implemented stream sources.\\\\n+ * \\\\n+ * This class implements the IStreamSource interface and bridges calls\\\\n+ * to a Python object that implements the PyStreamSource protocol.\\\\n+ */\\\\n+class GAPI_EXPORTS PythonStreamSource : public IStreamSource\\\\n+{\\\\n+public:\\\\n+    /**\\\\n+     * @brief Construct a new Python Stream Source object\\\\n+     * \\\\n+     * @param python_source Python object implementing PyStreamSource protocol\\\\n+     */\\\\n+    explicit PythonStreamSource(PyObject* python_source);\\\\n+    \\\\n+    /**\\\\n+     * @brief Pull data from the Python stream source\\\\n+     * \\\\n+     * @param data Output data container\\\\n+     * @return true if data was successfully pulled, false if stream ended\\\\n+     */\\\\n+    bool pull(Data& data) override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Get metadata description of the stream\\\\n+     * \\\\n+     * @return GMetaArg Metadata describing the stream output\\\\n+     */\\\\n+    GMetaArg descr_of() const override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Request stream source to halt/stop\\\\n+     */\\\\n+    void halt() override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Destructor\\\\n+     */\\\\n+    virtual ~PythonStreamSource();\\\\n+\\\\n+private:\\\\n+    class Impl;\\\\n+    std::unique_ptr<Impl> m_impl;\\\\n+};\\\\n+\\\\n+/**\\\\n+ * @brief Factory function to create PythonStreamSource from Python object\\\\n+ * \\\\n+ * @param python_source Python object implementing PyStreamSource protocol\\\\n+ * @return IStreamSource::Ptr Shared pointer to the created stream source\\\\n+ */\\\\n+GAPI_EXPORTS IStreamSource::Ptr make_python_src(PyObject* python_source);\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\n+\\\\n+#endif // OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\ndiff --git a/modules/imgproc/src/pyramids.cpp b/modules/imgproc/src/pyramids.cpp\\\\nindex b106def4bbf4..c47619896489 100644\\\\n--- a/modules/imgproc/src/pyramids.cpp\\\\n+++ b/modules/imgproc/src/pyramids.cpp\\\\n@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n \\\\n     Mat src = _src.getMat();\\\\n     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n     _dst.create( dsz, src.type() );\\\\n     Mat dst = _dst.getMat();\\\\n     int depth = src.depth();\\\\ndiff --git a/pyrUp_memory_fix.patch b/pyrUp_memory_fix.patch\\\\nnew file mode 100644\\\\nindex 000000000000..0d8707278fd5\\\\n--- /dev/null\\\\n+++ b/pyrUp_memory_fix.patch\\\\n@@ -0,0 +1,22 @@\\\\n+--- a/modules/imgproc/src/pyramids.cpp\\\\n++++ b/modules/imgproc/src/pyramids.cpp\\\\n+@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int border\\\\n+     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+ \\\\n++    // Define maximum allowable image dimensions to prevent memory overflow\\\\n++    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n++    const size_t MAX_TOTAL_PIXELS = 1024 * 1024 * 1024; // 1 billion pixels max\\\\n+ \\\\n+     Mat src = _src.getMat();\\\\n+     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n++    \\\\n++    // Check for potential memory overflow before allocation\\\\n++    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n++        (size_t)dsz.width * dsz.height > MAX_TOTAL_PIXELS) {\\\\n++        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n++    }\\\\n++    \\\\n+     _dst.create( dsz, src.type() );\\\\n+     Mat dst = _dst.getMat();\\\\n+     int depth = src.depth();\\\\ndiff --git a/test_pyrUp_fix.py b/test_pyrUp_fix.py\\\\nnew file mode 100644\\\\nindex 000000000000..bfa2e941624c\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_fix.py\\\\n@@ -0,0 +1,158 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\n+import cv2\\\\n+import numpy as np\\\\n+import sys\\\\n+import time\\\\n+\\\\n+def test_pyrUp_overflow_fix():\\\\n+    \\\\\"\\\\\"\\\\\"Test that pyrUp throws an appropriate error instead of crashing\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"Testing pyrUp memory overflow fix...\\\\\")\\\\n+    \\\\n+    # Create a small test image\\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    print(f\\\\\"Initial image size: {image.shape[1]}x{image.shape[0]}\\\\\")\\\\n+    \\\\n+    current = image.copy()\\\\n+    iterations = 0\\\\n+    \\\\n+    try:\\\\n+        # Keep calling pyrUp until we hit the memory limit\\\\n+        for i in range(20):\\\\n+            start_time = time.time()\\\\n+            \\\\n+            # Calculate what the next size would be\\\\n+            next_height = current.shape[0] * 2\\\\n+            next_width = current.shape[1] * 2\\\\n+            next_pixels = next_height * next_width\\\\n+            \\\\n+            print(f\\\\\"Iteration {i+1}: {current.shape[1]}x{current.shape[0]} -> {next_width}x{next_height} ({next_pixels:,} pixels)\\\\\")\\\\n+            \\\\n+            # This should eventually throw an error instead of crashing\\\\n+            next_image = cv2.pyrUp(current)\\\\n+            \\\\n+            end_time = time.time()\\\\n+            print(f\\\\\"  Success in {(end_time - start_time)*1000:.1f}ms\\\\\")\\\\n+            \\\\n+            current = next_image\\\\n+            iterations = i + 1\\\\n+            \\\\n+            # Safety break to avoid going too far\\\\n+            if current.shape[0] > 25600 or current.shape[1] > 25600:\\\\n+                print(\\\\\"Reached safety limit, stopping...\\\\\")\\\\n+                break\\\\n+                \\\\n+    except cv2.error as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught OpenCV error (expected): {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except MemoryError as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught MemoryError: {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"\\\\\\\\nUnexpected error: {e}\\\\\")\\\\n+        return False\\\\n+        \\\\n+    print(f\\\\\"\\\\\\\\nCompleted {iterations} iterations without error\\\\\")\\\\n+    print(f\\\\\"Final image size: {current.shape[1]}x{current.shape[0]}\\\\\")\\\\n+    return True\\\\n+\\\\n+def test_pyrUp_normal_usage():\\\\n+    \\\\\"\\\\\"\\\\\"Test that normal pyrUp usage still works\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting normal pyrUp usage...\\\\\")\\\\n+    \\\\n+    # Test with various image sizes and types\\\\n+    test_cases = [\\\\n+        ((50, 50), np.uint8),\\\\n+        ((100, 100), np.uint8),\\\\n+        ((50, 50, 3), np.uint8),\\\\n+        ((100, 100, 3), np.uint8),\\\\n+        ((50, 50), np.float32),\\\\n+    ]\\\\n+    \\\\n+    for shape, dtype in test_cases:\\\\n+        try:\\\\n+            # Create test image\\\\n+            if len(shape) == 2:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            else:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            \\\\n+            # Apply pyrUp\\\\n+            result = cv2.pyrUp(image)\\\\n+            \\\\n+            # Check result dimensions\\\\n+            expected_h = image.shape[0] * 2\\\\n+            expected_w = image.shape[1] * 2\\\\n+            \\\\n+            if result.shape[0] == expected_h and result.shape[1] == expected_w:\\\\n+                print(f\\\\\"  \\\\u2713 {shape} -> {result.shape} (dtype: {dtype.__name__})\\\\\")\\\\n+            else:\\\\n+                print(f\\\\\"  \\\\u2717 {shape} -> {result.shape} (expected: {expected_h}x{expected_w})\\\\\")\\\\n+                return False\\\\n+                \\\\n+        except Exception as e:\\\\n+            print(f\\\\\"  \\\\u2717 Failed for {shape} ({dtype.__name__}): {e}\\\\\")\\\\n+            return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+def test_pyrUp_with_custom_size():\\\\n+    \\\\\"\\\\\"\\\\\"Test pyrUp with custom destination size\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting pyrUp with custom destination size...\\\\\")\\\\n+    \\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    try:\\\\n+        # Test with valid custom size\\\\n+        custom_size = (150, 150)\\\\n+        result = cv2.pyrUp(image, dstsize=custom_size)\\\\n+        \\\\n+        if result.shape[:2] == custom_size:\\\\n+            print(f\\\\\"  \\\\u2713 Custom size {custom_size} works\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"  \\\\u2717 Custom size failed: got {result.shape[:2]}, expected {custom_size}\\\\\")\\\\n+            return False\\\\n+            \\\\n+        # Test with oversized custom size (should fail)\\\\n+        huge_size = (100000, 100000)  # This should trigger the bounds check\\\\n+        try:\\\\n+            result = cv2.pyrUp(image, dstsize=huge_size)\\\\n+            print(f\\\\\"  \\\\u2717 Huge size {huge_size} should have failed but didn\\'t\\\\\")\\\\n+            return False\\\\n+        except cv2.error:\\\\n+            print(f\\\\\"  \\\\u2713 Huge size {huge_size} correctly rejected\\\\\")\\\\n+            \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"  \\\\u2717 Unexpected error: {e}\\\\\")\\\\n+        return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    print(\\\\\"OpenCV pyrUp Memory Overflow Fix Test\\\\\")\\\\n+    print(\\\\\"=\\\\\" * 50)\\\\n+    \\\\n+    # Test 1: Check that the overflow protection works\\\\n+    success1 = test_pyrUp_overflow_fix()\\\\n+    \\\\n+    # Test 2: Check that normal usage still works\\\\n+    success2 = test_pyrUp_normal_usage()\\\\n+    \\\\n+    # Test 3: Check custom size handling\\\\n+    success3 = test_pyrUp_with_custom_size()\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\n\\\\\" + \\\\\"=\\\\\" * 50)\\\\n+    if success1 and success2 and success3:\\\\n+        print(\\\\\"\\\\u2713 All tests passed! The fix is working correctly.\\\\\")\\\\n+        sys.exit(0)\\\\n+    else:\\\\n+        print(\\\\\"\\\\u2717 Some tests failed.\\\\\")\\\\n+        sys.exit(1)\\\\ndiff --git a/test_pyrUp_overflow.cpp b/test_pyrUp_overflow.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..30c3eb572ba8\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_overflow.cpp\\\\n@@ -0,0 +1,55 @@\\\\n+#include <opencv2/opencv.hpp>\\\\n+#include <iostream>\\\\n+#include <chrono>\\\\n+\\\\n+using namespace cv;\\\\n+using namespace std;\\\\n+\\\\n+int main() {\\\\n+    try {\\\\n+        // Create a small test image\\\\n+        Mat image(100, 100, CV_8UC3, Scalar(128, 128, 128));\\\\n+        \\\\n+        cout << \\\\\"Starting pyrUp sequence test...\\\\\" << endl;\\\\n+        cout << \\\\\"Initial image size: \\\\\" << image.cols << \\\\\"x\\\\\" << image.rows << endl;\\\\n+        \\\\n+        Mat current = image.clone();\\\\n+        \\\\n+        // Keep calling pyrUp until memory overflow\\\\n+        for (int i = 0; i < 20; i++) {\\\\n+            auto start = chrono::high_resolution_clock::now();\\\\n+            \\\\n+            Mat next;\\\\n+            pyrUp(current, next);\\\\n+            \\\\n+            auto end = chrono::high_resolution_clock::now();\\\\n+            auto duration = chrono::duration_cast<chrono::milliseconds>(end - start);\\\\n+            \\\\n+            cout << \\\\\"Iteration \\\\\" << i+1 << \\\\\": \\\\\" \\\\n+                 << current.cols << \\\\\"x\\\\\" << current.rows \\\\n+                 << \\\\\" -> \\\\\" << next.cols << \\\\\"x\\\\\" << next.rows\\\\n+                 << \\\\\" (Memory: \\\\\" << (size_t)next.cols * next.rows * next.channels() << \\\\\" bytes)\\\\\"\\\\n+                 << \\\\\" (Time: \\\\\" << duration.count() << \\\\\"ms)\\\\\" << endl;\\\\n+            \\\\n+            current = next;\\\\n+            \\\\n+            // Stop if image gets too large (before crash)\\\\n+            if (current.cols > 25600 || current.rows > 25600) {\\\\n+                cout << \\\\\"Stopping before potential crash...\\\\\" << endl;\\\\n+                break;\\\\n+            }\\\\n+        }\\\\n+        \\\\n+        cout << \\\\\"Final image size: \\\\\" << current.cols << \\\\\"x\\\\\" << current.rows << endl;\\\\n+        cout << \\\\\"Test completed successfully!\\\\\" << endl;\\\\n+        \\\\n+    } catch (const cv::Exception& e) {\\\\n+        cout << \\\\\"OpenCV Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    } catch (const std::exception& e) {\\\\n+        cout << \\\\\"Standard Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    }\\\\n+    \\\\n+    return 0;\\\\n+}\\\\n\",\\n  \"target_hunk\": \"@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n  \"target_line\": {\\n    \"line_number\": 1383,\\n    \"content\": \"+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n    \"type\": \"addition\",\\n    \"position_in_hunk\": 4\\n  },\\n  \"enhanced_context\": {\\n    \"function_signature\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\",\\n    \"full_function\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\\\\n\\\\n=== COMPLETE DIFF CONTEXT ===\\\\n    L1380:      CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n    L1381:                 ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n    L1382:  \\\\n>>> L1383: +    // Define maximum allowable image dimensions to prevent memory overflow\\\\n    L1384: +    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n    L1385: +    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n    L1386:  \\\\n    L1387:      Mat src = _src.getMat();\\\\n    L1388:      Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n    L1389: +    \\\\n    L1390: +    // Check for potential memory overflow before allocation\\\\n    L1391: +    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n    L1392: +        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n    L1393: +        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n    L1394: +    }\\\\n    L1395: +    \\\\n    L1396:      _dst.create( dsz, src.type() );\\\\n    L1397:      Mat dst = _dst.getMat();\\\\n    L1398:      int depth = src.depth();\\\\n\\\\n=== TARGET LINE BEING REVIEWED ===\\\\nLine 4:     // Define maximum allowable image dimensions to prevent memory overflow\\\\n\\\\n=== CONTEXT SUMMARY ===\\\\nTotal lines of context extracted: 19\\\\nLanguage: cpp\"\\n  }\\n}<|im_end|>\\n<|im_start|>assistant\\ni think you can use `validateInputImageSize`\\r\\nlook\\r\\nhttps://github.com/opencv/opencv/blob/4c024c35fbc7f0610501e087a9ef20c336a75e2b/modules/imgcodecs/src/loadsave.cpp#L72-L81<|im_end|>\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192f03e4-4252-498c-b7da-3da72bc933e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n# OpenCV Expert Code Reviewer\\n\\nYou are a **world-class expert code reviewer** for the OpenCV computer vision library. Your mission is to conduct thorough, actionable reviews that maintain OpenCV\\'s high standards.\\n\\n## üéØ **Core Objectives**\\n1. **Improve code health** - Every change should enhance the codebase\\n2. **Maintain OpenCV standards** - Enforce C++11 compliance and cross-platform compatibility  \\n3. **Provide actionable feedback** - Specific, educational comments with clear paths forward\\n4. **Balance quality with progress** - Approve improvements even if not perfect\\n\\n## üîç **Systematic Review Checklist**\\n\\n**1. Code Logic & Functionality**\\n-  Verify correctness and algorithm efficiency\\n-  Handle edge cases (empty Mat, null pointers, boundaries)\\n-  Check OpenCV-specific patterns (Mat operations, empty() checks)\\n\\n**2. Error Handling & Safety** \\n-  Use CV_Assert() for preconditions, cv::Exception for errors\\n-  Validate inputs early, check null pointers\\n-  Follow RAII principles for resource management\\n\\n**3. Code Quality & Design**\\n-  Follow OpenCV naming: camelCase functions, PascalCase classes, UPPER_CASE constants\\n-  Use cv::Ptr<> for complex objects, avoid raw pointers\\n-  Maintain API consistency (input, output, optional parameter order)\\n\\n**4. Performance & Memory**\\n-  Minimize unnecessary allocations, prefer in-place operations\\n-  Leverage SIMD/vectorization opportunities where applicable\\n-  Ensure proper memory alignment and efficient Mat handling\\n\\n**5. Documentation & Testing**\\n-  Include Doxygen documentation (@param, @return, @brief)\\n-  Provide clear usage examples for complex functions\\n-  Ensure adequate test coverage using GTest framework\\n\\n## üí¨ **Structured Feedback Format**\\n\\nUse **Conventional Comments** structure:\\n- `issue (blocking):` - Critical problems requiring fixes\\n- `suggestion (non-blocking):` - Improvements to consider\\n- `praise:` - Acknowledge good practices\\n- `question:` - Request clarification\\n- `nitpick (non-blocking):` - Minor style preferences\\n\\n## üìã **Review Output Structure**\\n```markdown\\n## Code Review Summary\\n**Overall Assessment**: [APPROVE/REQUEST_CHANGES/COMMENT]\\n**Priority**: [HIGH/MEDIUM/LOW]\\n**Focus Areas**: [Primary review categories]\\n\\n## Critical Issues (Blocking)\\n[Problems that must be fixed]\\n\\n## Suggestions for Improvement  \\n[Non-blocking enhancements with specific recommendations]\\n\\n## Positive Aspects\\n[Good practices and well-written code acknowledgment]\\n```\\n\\n\\n## üîí **Security Expert Specialization**\\n\\n**Your specialized focus:**\\n- **Input Validation**: Check for null pointers, empty Mat, invalid sizes/parameters\\n- **Memory Safety**: Buffer overflows, uninitialized memory, proper bounds checking\\n- **Resource Management**: Memory leaks, double-free issues, exception safety\\n- **Thread Safety**: Race conditions, synchronization, deadlock prevention\\n\\n**Key Areas to Scrutinize:**\\n- Potential security vulnerabilities and stability issues\\n- Proper error handling using CV_Assert and cv::Exception\\n- Memory allocation patterns and cleanup procedures\\n- Thread safety in multi-threaded contexts\\n- Input sanitization and validation completeness\\n\\n## üìã **Your Specific Task**\\n\\nReview the following code change and provide feedback on the specific line indicated. Consider code quality, best practices, API design, and potential improvements.\\n\\n---\\n\\n**Remember**: Focus on your area of expertise while maintaining the systematic review approach. Provide specific, actionable feedback that helps improve the OpenCV codebase.\\n\\nHere is the code:\\n{\\n  \"pr_title\": \"\\\\ud83d\\\\udc1b Fix: pyrUp throws allocation error for oversized matrix requests\",\\n  \"pr_description\": \"This PR ensures `cv::pyrUp` raises an allocation error when attempting to create a matrix larger than supported, preventing silent crashes or overflows.\",\\n  \"file_path\": \"modules/imgproc/src/pyramids.cpp\",\\n  \"language\": \"cpp\",\\n  \"full_diff\": \"diff --git a/GAPI_CUSTOM_STREAM_DESIGN.md b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\nnew file mode 100644\\\\nindex 000000000000..d95498075959\\\\n--- /dev/null\\\\n+++ b/GAPI_CUSTOM_STREAM_DESIGN.md\\\\n@@ -0,0 +1,268 @@\\\\n+# G-API Custom Stream Sources in Python - Design Document\\\\n+\\\\n+## Issue #27276: Add support for custom stream sources in Python for G-API\\\\n+\\\\n+### Problem Statement\\\\n+\\\\n+Currently, OpenCV G-API supports custom stream sources in C++ through the `IStreamSource` interface, but Python users are limited to predefined sources like:\\\\n+- `cv.gapi.wip.make_capture_src()` for video files/cameras\\\\n+- `QueueSource` for programmatic data feeding\\\\n+\\\\n+There\\'s no straightforward way for Python developers to create custom streaming sources for scenarios like:\\\\n+- Custom hardware device interfaces\\\\n+- Network streaming protocols\\\\n+- Database-backed data streams  \\\\n+- Real-time sensor data\\\\n+- Custom data transformations/generators\\\\n+\\\\n+### Current Architecture\\\\n+\\\\n+```cpp\\\\n+// C++ IStreamSource interface\\\\n+class IStreamSource: public std::enable_shared_from_this<IStreamSource>\\\\n+{\\\\n+public:\\\\n+    using Ptr = std::shared_ptr<IStreamSource>;\\\\n+    virtual bool pull(Data &data) = 0;\\\\n+    virtual GMetaArg descr_of() const = 0;\\\\n+    virtual void halt() = 0;\\\\n+    virtual ~IStreamSource() = default;\\\\n+};\\\\n+```\\\\n+\\\\n+Python currently only exposes:\\\\n+```python\\\\n+# Existing Python sources\\\\n+source = cv.gapi.wip.make_capture_src(path)  # VideoCapture wrapper\\\\n+# Limited to predefined implementations\\\\n+```\\\\n+\\\\n+### Proposed Solution\\\\n+\\\\n+#### 1. Python Stream Source Interface\\\\n+\\\\n+Create a Python-friendly interface that matches the C++ `IStreamSource` pattern:\\\\n+\\\\n+```python\\\\n+class PyStreamSource:\\\\n+    \\\\\"\\\\\"\\\\\"Base class for custom Python stream sources.\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def pull(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull next data item from stream.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success: bool, data: Any) where data can be:\\\\n+                   - cv.Mat for image streams\\\\n+                   - tuple of values for multi-input streams\\\\n+                   - None if stream ended\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of stream output.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output type\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        raise NotImplementedError\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"Stop the stream source (optional override).\\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+```\\\\n+\\\\n+#### 2. C++ Bridge Implementation\\\\n+\\\\n+Create a C++ wrapper that bridges Python implementations to `IStreamSource`:\\\\n+\\\\n+```cpp\\\\n+// modules/gapi/src/streaming/python_stream_source.hpp\\\\n+class PythonStreamSource : public cv::gapi::wip::IStreamSource\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    cv::GMetaArg m_meta;\\\\n+    \\\\n+public:\\\\n+    PythonStreamSource(PyObject* python_source);\\\\n+    bool pull(cv::gapi::wip::Data& data) override;\\\\n+    cv::GMetaArg descr_of() const override;\\\\n+    void halt() override;\\\\n+};\\\\n+```\\\\n+\\\\n+#### 3. Python Factory Function\\\\n+\\\\n+Expose a factory function in Python:\\\\n+\\\\n+```python\\\\n+def make_python_src(source_instance):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from Python object.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    return cv.gapi.wip.PythonStreamSource(source_instance)\\\\n+```\\\\n+\\\\n+### Implementation Files\\\\n+\\\\n+#### File 1: Python Interface Definition\\\\n+`modules/gapi/misc/python/pyopencv_custom_sources.hpp`\\\\n+\\\\n+#### File 2: C++ Bridge Implementation  \\\\n+`modules/gapi/src/streaming/python_stream_source.cpp`\\\\n+\\\\n+#### File 3: Python Bindings\\\\n+`modules/gapi/misc/python/shadow_gapi_custom.hpp`\\\\n+\\\\n+#### File 4: CMake Integration\\\\n+Updates to `modules/gapi/misc/python/CMakeLists.txt`\\\\n+\\\\n+### Usage Examples\\\\n+\\\\n+#### Example 1: Custom Image Generator\\\\n+```python\\\\n+class RandomImageSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, width, height, count):\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.generated = 0\\\\n+    \\\\n+    def pull(self):\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        img = np.random.randint(0, 255, (self.height, self.width, 3), dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(np.zeros((self.height, self.width, 3), dtype=np.uint8))\\\\n+\\\\n+# Usage\\\\n+source = cv.gapi.wip.make_python_src(RandomImageSource(640, 480, 100))\\\\n+```\\\\n+\\\\n+#### Example 2: Network Stream Source\\\\n+```python\\\\n+class NetworkStreamSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, url):\\\\n+        self.url = url\\\\n+        self.connection = None\\\\n+        self._connect()\\\\n+    \\\\n+    def _connect(self):\\\\n+        # Custom network connection logic\\\\n+        pass\\\\n+    \\\\n+    def pull(self):\\\\n+        try:\\\\n+            frame_data = self.connection.receive_frame()\\\\n+            if frame_data is None:\\\\n+                return False, None\\\\n+            \\\\n+            # Decode frame_data to cv.Mat\\\\n+            frame = self._decode_frame(frame_data)\\\\n+            return True, frame\\\\n+        except Exception:\\\\n+            return False, None\\\\n+    \\\\n+    def descr_of(self):\\\\n+        # Return expected frame metadata\\\\n+        return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+    \\\\n+    def halt(self):\\\\n+        if self.connection:\\\\n+            self.connection.close()\\\\n+```\\\\n+\\\\n+#### Example 3: Multi-Input Source  \\\\n+```python\\\\n+class MultiInputSource(cv.gapi.PyStreamSource):\\\\n+    def __init__(self, image_source, metadata_source):\\\\n+        self.image_source = image_source\\\\n+        self.metadata_source = metadata_source\\\\n+    \\\\n+    def pull(self):\\\\n+        img_success, img = self.image_source.get_next()\\\\n+        meta_success, meta = self.metadata_source.get_next()\\\\n+        \\\\n+        if not (img_success and meta_success):\\\\n+            return False, None\\\\n+            \\\\n+        return True, (img, meta)\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.GIn(\\\\n+            cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+            cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+        )\\\\n+```\\\\n+\\\\n+### Integration with Existing G-API\\\\n+\\\\n+The custom sources integrate seamlessly with existing G-API streaming:\\\\n+\\\\n+```python\\\\n+# Create custom source\\\\n+source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+\\\\n+# Use in G-API pipeline\\\\n+g_in = cv.GMat()\\\\n+g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+comp = cv.GComputation(g_in, g_out)\\\\n+\\\\n+# Compile for streaming\\\\n+compiled = comp.compileStreaming()\\\\n+compiled.setSource(cv.gin(source))\\\\n+compiled.start()\\\\n+\\\\n+# Process stream\\\\n+while True:\\\\n+    success, result = compiled.pull()\\\\n+    if not success:\\\\n+        break\\\\n+    # Process result\\\\n+```\\\\n+\\\\n+### Benefits\\\\n+\\\\n+1. **Flexibility**: Python developers can create sources for any data type or protocol\\\\n+2. **Performance**: C++ bridge ensures minimal overhead  \\\\n+3. **Compatibility**: Works with existing G-API streaming infrastructure\\\\n+4. **Simplicity**: Pythonic interface that\\'s easy to understand and implement\\\\n+5. **Extensibility**: Foundation for community-contributed streaming sources\\\\n+\\\\n+### Implementation Plan\\\\n+\\\\n+1. **Phase 1**: Core infrastructure\\\\n+   - C++ bridge implementation\\\\n+   - Basic Python interface  \\\\n+   - Simple example (random data generator)\\\\n+\\\\n+2. **Phase 2**: Advanced features\\\\n+   - Multi-input source support\\\\n+   - Error handling improvements\\\\n+   - Performance optimizations\\\\n+\\\\n+3. **Phase 3**: Documentation and examples\\\\n+   - Comprehensive documentation\\\\n+   - Real-world usage examples\\\\n+   - Performance benchmarks\\\\n+\\\\n+### Testing Strategy\\\\n+\\\\n+1. **Unit Tests**: Test Python-C++ bridge functionality\\\\n+2. **Integration Tests**: Test with existing G-API streaming pipeline  \\\\n+3. **Performance Tests**: Measure overhead vs native sources\\\\n+4. **Examples**: Working examples for common use cases\\\\n+\\\\n+This design provides a comprehensive solution for custom stream sources in Python G-API while maintaining compatibility with existing infrastructure and ensuring good performance.\\\\ndiff --git a/ISSUE_27535_SOLUTION.md b/ISSUE_27535_SOLUTION.md\\\\nnew file mode 100644\\\\nindex 000000000000..9ad7ba8142ed\\\\n--- /dev/null\\\\n+++ b/ISSUE_27535_SOLUTION.md\\\\n@@ -0,0 +1,128 @@\\\\n+# OpenCV Issue #27535: pyrUp() Memory Overflow Fix\\\\n+\\\\n+## Problem Description\\\\n+\\\\n+The `pyrUp()` function in OpenCV can cause segmentation faults or program crashes when called repeatedly in sequence. This occurs because:\\\\n+\\\\n+1. **Exponential Memory Growth**: Each call to `pyrUp()` doubles the image dimensions (width \\\\u00d7 2, height \\\\u00d7 2), resulting in 4\\\\u00d7 memory usage per iteration\\\\n+2. **No Bounds Checking**: The original implementation had no limits on the destination image size\\\\n+3. **Unbounded Allocation**: The function would attempt to allocate memory even for impossibly large images\\\\n+\\\\n+### Memory Growth Pattern\\\\n+- Iteration 1: 100\\\\u00d7100 \\\\u2192 200\\\\u00d7200 (160KB)\\\\n+- Iteration 2: 200\\\\u00d7200 \\\\u2192 400\\\\u00d7400 (640KB) \\\\n+- Iteration 3: 400\\\\u00d7400 \\\\u2192 800\\\\u00d7800 (2.5MB)\\\\n+- Iteration 4: 800\\\\u00d7800 \\\\u2192 1600\\\\u00d71600 (10MB)\\\\n+- Iteration 5: 1600\\\\u00d71600 \\\\u2192 3200\\\\u00d73200 (40MB)\\\\n+- Iteration 10: 51,200\\\\u00d751,200 \\\\u2192 102,400\\\\u00d7102,400 (41GB!)\\\\n+\\\\n+## Root Cause Analysis\\\\n+\\\\n+The issue is in `modules/imgproc/src/pyramids.cpp` at line 1388:\\\\n+\\\\n+```cpp\\\\n+Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+_dst.create( dsz, src.type() );  // No bounds checking here!\\\\n+```\\\\n+\\\\n+The function blindly doubles the image size and attempts allocation without verifying if the resulting image size is reasonable.\\\\n+\\\\n+## Solution\\\\n+\\\\n+Added bounds checking before memory allocation in the `pyrUp()` function:\\\\n+\\\\n+```cpp\\\\n+void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderType )\\\\n+{\\\\n+    CV_INSTRUMENT_REGION();\\\\n+\\\\n+    CV_Assert(borderType == BORDER_DEFAULT);\\\\n+\\\\n+    CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+               ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+\\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n+\\\\n+    Mat src = _src.getMat();\\\\n+    Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n+    _dst.create( dsz, src.type() );\\\\n+    // ... rest of function unchanged\\\\n+}\\\\n+```\\\\n+\\\\n+### Bounds Selected\\\\n+\\\\n+- **MAX_IMAGE_SIZE = 32,768**: Reasonable limit for individual dimensions\\\\n+- **MAX_TOTAL_PIXELS = 1,073,741,824**: Approximately 1 billion pixels (4GB for RGBA images)\\\\n+\\\\n+These limits prevent memory exhaustion while allowing legitimate use cases.\\\\n+\\\\n+## Benefits\\\\n+\\\\n+1. **Prevents Crashes**: Function throws a clear error instead of crashing\\\\n+2. **Early Detection**: Fails fast before attempting massive allocations\\\\n+3. **Backward Compatible**: Normal usage patterns continue to work\\\\n+4. **Clear Error Messages**: Users get descriptive error messages\\\\n+5. **Configurable**: Limits can be adjusted if needed\\\\n+\\\\n+## Testing\\\\n+\\\\n+### Before Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+for (int i = 0; i < 15; i++) {\\\\n+    pyrUp(current, current);  // Eventually crashes with segfault\\\\n+}\\\\n+```\\\\n+\\\\n+### After Fix\\\\n+```cpp\\\\n+Mat img(100, 100, CV_8UC3);\\\\n+Mat current = img;\\\\n+try {\\\\n+    for (int i = 0; i < 15; i++) {\\\\n+        pyrUp(current, current);\\\\n+    }\\\\n+} catch (cv::Exception& e) {\\\\n+    // Graceful error: \\\\\"pyrUp: Destination image size is too large...\\\\\"\\\\n+}\\\\n+```\\\\n+\\\\n+## Files Modified\\\\n+\\\\n+- `modules/imgproc/src/pyramids.cpp`: Added bounds checking in `pyrUp()` function\\\\n+\\\\n+## Test Files Created\\\\n+\\\\n+- `test_pyrUp_overflow.cpp`: C++ test demonstrating the issue and fix\\\\n+- `test_pyrUp_fix.py`: Python test script for validation\\\\n+- `pyrUp_memory_fix.patch`: Patch file with the solution\\\\n+\\\\n+## Verification\\\\n+\\\\n+The fix has been tested with:\\\\n+- \\\\u2705 Normal pyrUp operations (small to medium images)\\\\n+- \\\\u2705 Custom destination sizes\\\\n+- \\\\u2705 Various image types (CV_8U, CV_16S, CV_16U, CV_32F, CV_64F)\\\\n+- \\\\u2705 Multiple channel images (1, 2, 3, 4 channels)\\\\n+- \\\\u2705 Overflow prevention (catches oversized requests)\\\\n+- \\\\u2705 Error message clarity\\\\n+\\\\n+## Impact\\\\n+\\\\n+- **Security**: Prevents denial-of-service through memory exhaustion\\\\n+- **Stability**: Applications no longer crash unexpectedly\\\\n+- **User Experience**: Clear error messages help developers debug issues\\\\n+- **Performance**: No impact on normal operations\\\\n+\\\\n+This fix resolves Issue #27535 by adding necessary bounds checking while maintaining full backward compatibility for legitimate use cases.\\\\ndiff --git a/gapi_custom_stream_sources.py b/gapi_custom_stream_sources.py\\\\nnew file mode 100644\\\\nindex 000000000000..6cdf45a577d8\\\\n--- /dev/null\\\\n+++ b/gapi_custom_stream_sources.py\\\\n@@ -0,0 +1,303 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+OpenCV G-API Custom Stream Sources for Python\\\\n+\\\\n+This module provides the base interface and utilities for creating custom\\\\n+stream sources in Python for use with OpenCV G-API streaming computations.\\\\n+\\\\\"\\\\\"\\\\\"\\\\n+\\\\n+import cv2 as cv\\\\n+import numpy as np\\\\n+from abc import ABC, abstractmethod\\\\n+from typing import Tuple, Any, Union, Optional\\\\n+\\\\n+class PyStreamSource(ABC):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Abstract base class for custom Python stream sources.\\\\n+    \\\\n+    Subclass this to create custom stream sources that can be used with\\\\n+    G-API streaming computations. The source provides data to the G-API\\\\n+    pipeline on demand.\\\\n+    \\\\n+    Example:\\\\n+        class MyCustomSource(PyStreamSource):\\\\n+            def pull(self):\\\\n+                # Generate or fetch data\\\\n+                img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\\\\n+                return True, img\\\\n+            \\\\n+            def descr_of(self):\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+        \\\\n+        # Use with G-API\\\\n+        source = cv.gapi.wip.make_python_src(MyCustomSource())\\\\n+        compiled.setSource(cv.gin(source))\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    @abstractmethod\\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Pull the next data item from the stream.\\\\n+        \\\\n+        This method is called by the G-API framework when it needs new data\\\\n+        from the stream. It should return a tuple containing a success flag\\\\n+        and the data.\\\\n+        \\\\n+        Returns:\\\\n+            tuple: (success, data) where:\\\\n+                - success (bool): True if data was successfully retrieved,\\\\n+                                  False if the stream has ended\\\\n+                - data (Any): The data to pass to the G-API pipeline. Can be:\\\\n+                    * cv.Mat for single image streams\\\\n+                    * tuple of values for multi-input streams  \\\\n+                    * np.ndarray (will be converted to cv.Mat)\\\\n+                    * None if stream ended (success should be False)\\\\n+        \\\\n+        Raises:\\\\n+            Exception: Any exception raised will be propagated to the G-API\\\\n+                      framework and may cause the pipeline to fail.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    @abstractmethod  \\\\n+    def descr_of(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Return metadata description of the stream output.\\\\n+        \\\\n+        This method should return metadata that describes the type and shape\\\\n+        of data that will be produced by pull(). This is used by G-API for\\\\n+        pipeline compilation and optimization.\\\\n+        \\\\n+        Returns:\\\\n+            cv.GMetaArg: Metadata describing the stream output. Use\\\\n+                        cv.gapi.descr_of() to create appropriate metadata\\\\n+                        from example data.\\\\n+        \\\\n+        Example:\\\\n+            def descr_of(self):\\\\n+                # For single Mat output\\\\n+                return cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8))\\\\n+                \\\\n+            def descr_of(self):\\\\n+                # For multi-input output\\\\n+                return cv.GIn(\\\\n+                    cv.gapi.descr_of(np.zeros((480, 640, 3), dtype=np.uint8)),\\\\n+                    cv.gapi.descr_of(np.zeros((10,), dtype=np.float32))\\\\n+                )\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+    \\\\n+    def halt(self):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Request the stream source to halt/stop (optional override).\\\\n+        \\\\n+        This method is called when the G-API pipeline is being stopped.\\\\n+        Override this method if your source needs to perform cleanup,\\\\n+        close connections, or stop background processes.\\\\n+        \\\\n+        The default implementation does nothing.\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        pass\\\\n+\\\\n+\\\\n+class RandomImageSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates random images.\\\\n+    \\\\n+    This is a simple example source that generates random color images\\\\n+    of a specified size for a given number of frames.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, width: int, height: int, count: int, channels: int = 3):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the random image source.\\\\n+        \\\\n+        Args:\\\\n+            width (int): Image width in pixels\\\\n+            height (int): Image height in pixels  \\\\n+            count (int): Number of images to generate before ending stream\\\\n+            channels (int): Number of color channels (1 or 3)\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.width = width\\\\n+        self.height = height\\\\n+        self.count = count\\\\n+        self.channels = channels\\\\n+        self.generated = 0\\\\n+        \\\\n+        if channels not in [1, 3]:\\\\n+            raise ValueError(\\\\\"channels must be 1 (grayscale) or 3 (color)\\\\\")\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[np.ndarray]]:\\\\n+        if self.generated >= self.count:\\\\n+            return False, None\\\\n+        \\\\n+        if self.channels == 1:\\\\n+            shape = (self.height, self.width)\\\\n+        else:\\\\n+            shape = (self.height, self.width, self.channels)\\\\n+            \\\\n+        img = np.random.randint(0, 255, shape, dtype=np.uint8)\\\\n+        self.generated += 1\\\\n+        return True, img\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if self.channels == 1:\\\\n+            sample = np.zeros((self.height, self.width), dtype=np.uint8)\\\\n+        else:\\\\n+            sample = np.zeros((self.height, self.width, self.channels), dtype=np.uint8)\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+class CounterSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: generates incrementing counter values.\\\\n+    \\\\n+    This source generates integer counter values, useful for testing\\\\n+    or as a simple data generator.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, start: int = 0, end: int = 100, step: int = 1):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the counter source.\\\\n+        \\\\n+        Args:\\\\n+            start (int): Starting counter value\\\\n+            end (int): Ending counter value (exclusive)\\\\n+            step (int): Increment step\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.current = start\\\\n+        self.end = end\\\\n+        self.step = step\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Optional[int]]:\\\\n+        if self.current >= self.end:\\\\n+            return False, None\\\\n+        \\\\n+        value = self.current\\\\n+        self.current += self.step\\\\n+        return True, value\\\\n+    \\\\n+    def descr_of(self):\\\\n+        return cv.gapi.descr_of(0)  # int metadata\\\\n+\\\\n+\\\\n+class ListSource(PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Example implementation: streams data from a Python list.\\\\n+    \\\\n+    This source iterates through a pre-defined list of data items,\\\\n+    useful for testing with known data sets.\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    def __init__(self, data_list):\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        Initialize the list source.\\\\n+        \\\\n+        Args:\\\\n+            data_list: List of data items to stream\\\\n+        \\\\\"\\\\\"\\\\\"\\\\n+        self.data_list = data_list\\\\n+        self.index = 0\\\\n+    \\\\n+    def pull(self) -> Tuple[bool, Any]:\\\\n+        if self.index >= len(self.data_list):\\\\n+            return False, None\\\\n+        \\\\n+        data = self.data_list[self.index]\\\\n+        self.index += 1\\\\n+        return True, data\\\\n+    \\\\n+    def descr_of(self):\\\\n+        if not self.data_list:\\\\n+            raise ValueError(\\\\\"Cannot determine metadata from empty list\\\\\")\\\\n+        \\\\n+        # Use first item to determine metadata\\\\n+        sample = self.data_list[0]\\\\n+        return cv.gapi.descr_of(sample)\\\\n+\\\\n+\\\\n+# Factory function (to be exposed via Python bindings)\\\\n+def make_python_src(source_instance: PyStreamSource):\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    Create a G-API stream source from a Python object.\\\\n+    \\\\n+    This function creates a stream source that can be used with G-API\\\\n+    streaming computations from a Python object implementing the\\\\n+    PyStreamSource interface.\\\\n+    \\\\n+    Args:\\\\n+        source_instance: Instance of PyStreamSource subclass\\\\n+        \\\\n+    Returns:\\\\n+        Stream source compatible with G-API streaming compilation\\\\n+        \\\\n+    Example:\\\\n+        source = make_python_src(RandomImageSource(640, 480, 100))\\\\n+        \\\\n+        g_in = cv.GMat()\\\\n+        g_out = cv.gapi.medianBlur(g_in, 3)\\\\n+        comp = cv.GComputation(g_in, g_out)\\\\n+        \\\\n+        compiled = comp.compileStreaming()\\\\n+        compiled.setSource(cv.gin(source))\\\\n+        compiled.start()\\\\n+    \\\\\"\\\\\"\\\\\"\\\\n+    if not isinstance(source_instance, PyStreamSource):\\\\n+        raise TypeError(\\\\\"source_instance must be a PyStreamSource subclass\\\\\")\\\\n+    \\\\n+    # This will be implemented via Python bindings to call the C++ factory\\\\n+    # For now, raise NotImplementedError to indicate this needs C++ bridge\\\\n+    raise NotImplementedError(\\\\n+        \\\\\"make_python_src requires C++ Python bindings implementation. \\\\\"\\\\n+        \\\\\"This function should be exposed via cv.gapi.wip.make_python_src()\\\\\"\\\\n+    )\\\\n+\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    # Example usage and testing\\\\n+    print(\\\\\"OpenCV G-API Custom Stream Sources\\\\\")\\\\n+    print(\\\\\"==================================\\\\\")\\\\n+    \\\\n+    # Test RandomImageSource\\\\n+    print(\\\\\"\\\\\\\\nTesting RandomImageSource:\\\\\")\\\\n+    source = RandomImageSource(320, 240, 5)\\\\n+    print(f\\\\\"Metadata: {source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Frame {i}: Generated {data.shape} image\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Frame {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test CounterSource  \\\\n+    print(\\\\\"\\\\\\\\nTesting CounterSource:\\\\\")\\\\n+    counter = CounterSource(0, 5)\\\\n+    print(f\\\\\"Metadata: {counter.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(7):  # Test beyond count limit\\\\n+        success, data = counter.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"Counter {i}: {data}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"Counter {i}: Stream ended\\\\\")\\\\n+            break\\\\n+    \\\\n+    # Test ListSource\\\\n+    print(\\\\\"\\\\\\\\nTesting ListSource:\\\\\")\\\\n+    test_data = [\\\\n+        np.array([[1, 2], [3, 4]], dtype=np.int32),\\\\n+        np.array([[5, 6], [7, 8]], dtype=np.int32),\\\\n+        np.array([[9, 10], [11, 12]], dtype=np.int32)\\\\n+    ]\\\\n+    list_source = ListSource(test_data)\\\\n+    print(f\\\\\"Metadata: {list_source.descr_of()}\\\\\")\\\\n+    \\\\n+    for i in range(5):  # Test beyond list length\\\\n+        success, data = list_source.pull()\\\\n+        if success:\\\\n+            print(f\\\\\"List item {i}: {data.tolist()}\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"List item {i}: Stream ended\\\\\")\\\\n+            break\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.cpp b/modules/gapi/src/streaming/python_stream_source.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..206d1eb72cff\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.cpp\\\\n@@ -0,0 +1,278 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#include \\\\\"python_stream_source.hpp\\\\\"\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#ifndef CV_PYTHON_ENABLED\\\\n+// Stub implementation when Python is not available\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+PythonStreamSource::PythonStreamSource(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data&) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+GMetaArg PythonStreamSource::descr_of() const {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt() {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+IStreamSource::Ptr make_python_src(PyObject*) {\\\\n+    CV_Error(cv::Error::StsNotImplemented, \\\\\"OpenCV was built without Python support\\\\\");\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#else // CV_PYTHON_ENABLED\\\\n+\\\\n+#include <Python.h>\\\\n+#include <opencv2/gapi/streaming/gstreaming.hpp>\\\\n+#include <opencv2/core/cvdef.h>\\\\n+#include <opencv2/core/cv_cpu_dispatch.h>\\\\n+#include \\\\\"misc/python/pyopencv_gapi.hpp\\\\\" // For PyObjectHolder\\\\n+\\\\n+namespace cv {\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief Private implementation class for PythonStreamSource\\\\n+ */\\\\n+class PythonStreamSource::Impl\\\\n+{\\\\n+private:\\\\n+    cv::detail::PyObjectHolder m_python_source;\\\\n+    mutable cv::GMetaArg m_cached_meta;\\\\n+    mutable bool m_meta_cached;\\\\n+    \\\\n+    // Python method names\\\\n+    static constexpr const char* PULL_METHOD = \\\\\"pull\\\\\";\\\\n+    static constexpr const char* DESCR_METHOD = \\\\\"descr_of\\\\\";\\\\n+    static constexpr const char* HALT_METHOD = \\\\\"halt\\\\\";\\\\n+\\\\n+public:\\\\n+    explicit Impl(PyObject* python_source)\\\\n+        : m_python_source(python_source, true)\\\\n+        , m_meta_cached(false)\\\\n+    {\\\\n+        CV_Assert(python_source != nullptr);\\\\n+        \\\\n+        // Verify that the Python object has required methods\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, PULL_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'pull\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (!PyObject_HasAttrString(py_obj, DESCR_METHOD)) {\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source object must have \\'descr_of\\' method\\\\\");\\\\n+        }\\\\n+        \\\\n+        // halt method is optional - will be checked when called\\\\n+    }\\\\n+    \\\\n+    bool pull(Data& data)\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s pull() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, PULL_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call pull() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        // Expected return: (success: bool, data: Any)\\\\n+        if (!PyTuple_Check(py_result) || PyTuple_Size(py_result) != 2) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsBadArg, \\\\\"Python source pull() must return (bool, data) tuple\\\\\");\\\\n+        }\\\\n+        \\\\n+        PyObject* py_success = PyTuple_GetItem(py_result, 0);\\\\n+        PyObject* py_data = PyTuple_GetItem(py_result, 1);\\\\n+        \\\\n+        // Check success flag\\\\n+        int success = PyObject_IsTrue(py_success);\\\\n+        if (success == -1) {\\\\n+            Py_DECREF(py_result);\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to evaluate success flag from Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        if (success == 0) {\\\\n+            // Stream ended\\\\n+            Py_DECREF(py_result);\\\\n+            return false;\\\\n+        }\\\\n+        \\\\n+        // Convert Python data to cv::gapi::wip::Data\\\\n+        try {\\\\n+            if (py_data == Py_None) {\\\\n+                // No data available but success=True indicates continue\\\\n+                Py_DECREF(py_result);\\\\n+                return false;\\\\n+            }\\\\n+            \\\\n+            // Try to convert py_data to cv::Mat first (most common case)\\\\n+            cv::Mat mat;\\\\n+            if (pyopencv_to(py_data, mat, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{mat};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // Try to convert to tuple of values (multi-input case)\\\\n+            if (PyTuple_Check(py_data)) {\\\\n+                cv::GRunArgs args;\\\\n+                if (pyopencv_to(py_data, args, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                    data = Data{args};\\\\n+                    Py_DECREF(py_result);\\\\n+                    return true;\\\\n+                }\\\\n+            }\\\\n+            \\\\n+            // Try other common types\\\\n+            cv::Scalar scalar;\\\\n+            if (pyopencv_to(py_data, scalar, cv::ArgInfo(\\\\\"data\\\\\", false))) {\\\\n+                data = Data{scalar};\\\\n+                Py_DECREF(py_result);\\\\n+                return true;\\\\n+            }\\\\n+            \\\\n+            // If we get here, unsupported data type\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unsupported data type returned from Python source\\\\\");\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python data\\\\\");\\\\n+        }\\\\n+        \\\\n+        return false; // Should not reach here\\\\n+    }\\\\n+    \\\\n+    cv::GMetaArg descr_of() const\\\\n+    {\\\\n+        if (m_meta_cached) {\\\\n+            return m_cached_meta;\\\\n+        }\\\\n+        \\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Call Python object\\'s descr_of() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, DESCR_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Failed to call descr_of() method on Python source\\\\\");\\\\n+        }\\\\n+        \\\\n+        try {\\\\n+            // Convert Python result to GMetaArg\\\\n+            cv::GMetaArg meta;\\\\n+            if (!pyopencv_to(py_result, meta, cv::ArgInfo(\\\\\"meta\\\\\", false))) {\\\\n+                Py_DECREF(py_result);\\\\n+                CV_Error(cv::Error::StsError, \\\\\"Failed to convert Python descr_of() result to GMetaArg\\\\\");\\\\n+            }\\\\n+            \\\\n+            Py_DECREF(py_result);\\\\n+            \\\\n+            // Cache the result\\\\n+            m_cached_meta = meta;\\\\n+            m_meta_cached = true;\\\\n+            \\\\n+            return meta;\\\\n+            \\\\n+        } catch (const cv::Exception& e) {\\\\n+            Py_DECREF(py_result);\\\\n+            throw;\\\\n+        } catch (...) {\\\\n+            Py_DECREF(py_result);\\\\n+            CV_Error(cv::Error::StsError, \\\\\"Unknown error converting Python metadata\\\\\");\\\\n+        }\\\\n+    }\\\\n+    \\\\n+    void halt()\\\\n+    {\\\\n+        PyObject* py_obj = m_python_source.get();\\\\n+        CV_Assert(py_obj != nullptr);\\\\n+        \\\\n+        // Check if halt method exists (it\\'s optional)\\\\n+        if (!PyObject_HasAttrString(py_obj, HALT_METHOD)) {\\\\n+            return; // No halt method - that\\'s OK\\\\n+        }\\\\n+        \\\\n+        // Call Python object\\'s halt() method\\\\n+        PyObject* py_result = PyObject_CallMethod(py_obj, HALT_METHOD, nullptr);\\\\n+        \\\\n+        if (py_result == nullptr) {\\\\n+            PyErr_Print();\\\\n+            // Don\\'t throw error for halt - just log warning\\\\n+            CV_LOG_WARNING(nullptr, \\\\\"Failed to call halt() method on Python source\\\\\");\\\\n+            return;\\\\n+        }\\\\n+        \\\\n+        Py_DECREF(py_result);\\\\n+    }\\\\n+};\\\\n+\\\\n+// PythonStreamSource implementation\\\\n+PythonStreamSource::PythonStreamSource(PyObject* python_source)\\\\n+    : m_impl(std::make_unique<Impl>(python_source))\\\\n+{\\\\n+}\\\\n+\\\\n+bool PythonStreamSource::pull(Data& data)\\\\n+{\\\\n+    return m_impl->pull(data);\\\\n+}\\\\n+\\\\n+cv::GMetaArg PythonStreamSource::descr_of() const\\\\n+{\\\\n+    return m_impl->descr_of();\\\\n+}\\\\n+\\\\n+void PythonStreamSource::halt()\\\\n+{\\\\n+    m_impl->halt();\\\\n+}\\\\n+\\\\n+PythonStreamSource::~PythonStreamSource() = default;\\\\n+\\\\n+// Factory function\\\\n+IStreamSource::Ptr make_python_src(PyObject* python_source)\\\\n+{\\\\n+    auto src = std::make_shared<PythonStreamSource>(python_source);\\\\n+    return src->ptr();\\\\n+}\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // CV_PYTHON_ENABLED\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\ndiff --git a/modules/gapi/src/streaming/python_stream_source.hpp b/modules/gapi/src/streaming/python_stream_source.hpp\\\\nnew file mode 100644\\\\nindex 000000000000..39a29d32a362\\\\n--- /dev/null\\\\n+++ b/modules/gapi/src/streaming/python_stream_source.hpp\\\\n@@ -0,0 +1,88 @@\\\\n+// This file is part of OpenCV project.\\\\n+// It is subject to the license terms in the LICENSE file found in the top-level directory\\\\n+// of this distribution and at http://opencv.org/license.html.\\\\n+//\\\\n+// Copyright (C) 2024 Intel Corporation\\\\n+\\\\n+#ifndef OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+#define OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\n+\\\\n+#ifdef HAVE_OPENCV_GAPI\\\\n+\\\\n+#include <memory>\\\\n+#include <opencv2/gapi/streaming/source.hpp>\\\\n+#include <opencv2/gapi/gmetaarg.hpp>\\\\n+\\\\n+// Forward declarations to avoid Python.h inclusion in header\\\\n+struct _object;\\\\n+typedef _object PyObject;\\\\n+\\\\n+namespace cv {\\\\n+namespace detail {\\\\n+class PyObjectHolder; // Forward declaration\\\\n+}\\\\n+\\\\n+namespace gapi {\\\\n+namespace wip {\\\\n+\\\\n+/**\\\\n+ * @brief C++ bridge for Python-implemented stream sources.\\\\n+ * \\\\n+ * This class implements the IStreamSource interface and bridges calls\\\\n+ * to a Python object that implements the PyStreamSource protocol.\\\\n+ */\\\\n+class GAPI_EXPORTS PythonStreamSource : public IStreamSource\\\\n+{\\\\n+public:\\\\n+    /**\\\\n+     * @brief Construct a new Python Stream Source object\\\\n+     * \\\\n+     * @param python_source Python object implementing PyStreamSource protocol\\\\n+     */\\\\n+    explicit PythonStreamSource(PyObject* python_source);\\\\n+    \\\\n+    /**\\\\n+     * @brief Pull data from the Python stream source\\\\n+     * \\\\n+     * @param data Output data container\\\\n+     * @return true if data was successfully pulled, false if stream ended\\\\n+     */\\\\n+    bool pull(Data& data) override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Get metadata description of the stream\\\\n+     * \\\\n+     * @return GMetaArg Metadata describing the stream output\\\\n+     */\\\\n+    GMetaArg descr_of() const override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Request stream source to halt/stop\\\\n+     */\\\\n+    void halt() override;\\\\n+    \\\\n+    /**\\\\n+     * @brief Destructor\\\\n+     */\\\\n+    virtual ~PythonStreamSource();\\\\n+\\\\n+private:\\\\n+    class Impl;\\\\n+    std::unique_ptr<Impl> m_impl;\\\\n+};\\\\n+\\\\n+/**\\\\n+ * @brief Factory function to create PythonStreamSource from Python object\\\\n+ * \\\\n+ * @param python_source Python object implementing PyStreamSource protocol\\\\n+ * @return IStreamSource::Ptr Shared pointer to the created stream source\\\\n+ */\\\\n+GAPI_EXPORTS IStreamSource::Ptr make_python_src(PyObject* python_source);\\\\n+\\\\n+} // namespace wip\\\\n+} // namespace gapi\\\\n+} // namespace cv\\\\n+\\\\n+#endif // HAVE_OPENCV_GAPI\\\\n+\\\\n+#endif // OPENCV_GAPI_STREAMING_PYTHON_STREAM_SOURCE_HPP\\\\ndiff --git a/modules/imgproc/src/pyramids.cpp b/modules/imgproc/src/pyramids.cpp\\\\nindex b106def4bbf4..c47619896489 100644\\\\n--- a/modules/imgproc/src/pyramids.cpp\\\\n+++ b/modules/imgproc/src/pyramids.cpp\\\\n@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\\\\n+    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n+    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n \\\\n     Mat src = _src.getMat();\\\\n     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n+    \\\\n+    // Check for potential memory overflow before allocation\\\\n+    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n+        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n+        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n+    }\\\\n+    \\\\n     _dst.create( dsz, src.type() );\\\\n     Mat dst = _dst.getMat();\\\\n     int depth = src.depth();\\\\ndiff --git a/pyrUp_memory_fix.patch b/pyrUp_memory_fix.patch\\\\nnew file mode 100644\\\\nindex 000000000000..0d8707278fd5\\\\n--- /dev/null\\\\n+++ b/pyrUp_memory_fix.patch\\\\n@@ -0,0 +1,22 @@\\\\n+--- a/modules/imgproc/src/pyramids.cpp\\\\n++++ b/modules/imgproc/src/pyramids.cpp\\\\n+@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int border\\\\n+     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n+                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n+ \\\\n++    // Define maximum allowable image dimensions to prevent memory overflow\\\\n++    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n++    const size_t MAX_TOTAL_PIXELS = 1024 * 1024 * 1024; // 1 billion pixels max\\\\n+ \\\\n+     Mat src = _src.getMat();\\\\n+     Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n++    \\\\n++    // Check for potential memory overflow before allocation\\\\n++    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n++        (size_t)dsz.width * dsz.height > MAX_TOTAL_PIXELS) {\\\\n++        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n++    }\\\\n++    \\\\n+     _dst.create( dsz, src.type() );\\\\n+     Mat dst = _dst.getMat();\\\\n+     int depth = src.depth();\\\\ndiff --git a/test_pyrUp_fix.py b/test_pyrUp_fix.py\\\\nnew file mode 100644\\\\nindex 000000000000..bfa2e941624c\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_fix.py\\\\n@@ -0,0 +1,158 @@\\\\n+#!/usr/bin/env python3\\\\n+\\\\n+import cv2\\\\n+import numpy as np\\\\n+import sys\\\\n+import time\\\\n+\\\\n+def test_pyrUp_overflow_fix():\\\\n+    \\\\\"\\\\\"\\\\\"Test that pyrUp throws an appropriate error instead of crashing\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"Testing pyrUp memory overflow fix...\\\\\")\\\\n+    \\\\n+    # Create a small test image\\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    print(f\\\\\"Initial image size: {image.shape[1]}x{image.shape[0]}\\\\\")\\\\n+    \\\\n+    current = image.copy()\\\\n+    iterations = 0\\\\n+    \\\\n+    try:\\\\n+        # Keep calling pyrUp until we hit the memory limit\\\\n+        for i in range(20):\\\\n+            start_time = time.time()\\\\n+            \\\\n+            # Calculate what the next size would be\\\\n+            next_height = current.shape[0] * 2\\\\n+            next_width = current.shape[1] * 2\\\\n+            next_pixels = next_height * next_width\\\\n+            \\\\n+            print(f\\\\\"Iteration {i+1}: {current.shape[1]}x{current.shape[0]} -> {next_width}x{next_height} ({next_pixels:,} pixels)\\\\\")\\\\n+            \\\\n+            # This should eventually throw an error instead of crashing\\\\n+            next_image = cv2.pyrUp(current)\\\\n+            \\\\n+            end_time = time.time()\\\\n+            print(f\\\\\"  Success in {(end_time - start_time)*1000:.1f}ms\\\\\")\\\\n+            \\\\n+            current = next_image\\\\n+            iterations = i + 1\\\\n+            \\\\n+            # Safety break to avoid going too far\\\\n+            if current.shape[0] > 25600 or current.shape[1] > 25600:\\\\n+                print(\\\\\"Reached safety limit, stopping...\\\\\")\\\\n+                break\\\\n+                \\\\n+    except cv2.error as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught OpenCV error (expected): {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except MemoryError as e:\\\\n+        print(f\\\\\"\\\\\\\\nCaught MemoryError: {e}\\\\\")\\\\n+        print(f\\\\\"Stopped at iteration {iterations + 1}\\\\\")\\\\n+        return True\\\\n+        \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"\\\\\\\\nUnexpected error: {e}\\\\\")\\\\n+        return False\\\\n+        \\\\n+    print(f\\\\\"\\\\\\\\nCompleted {iterations} iterations without error\\\\\")\\\\n+    print(f\\\\\"Final image size: {current.shape[1]}x{current.shape[0]}\\\\\")\\\\n+    return True\\\\n+\\\\n+def test_pyrUp_normal_usage():\\\\n+    \\\\\"\\\\\"\\\\\"Test that normal pyrUp usage still works\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting normal pyrUp usage...\\\\\")\\\\n+    \\\\n+    # Test with various image sizes and types\\\\n+    test_cases = [\\\\n+        ((50, 50), np.uint8),\\\\n+        ((100, 100), np.uint8),\\\\n+        ((50, 50, 3), np.uint8),\\\\n+        ((100, 100, 3), np.uint8),\\\\n+        ((50, 50), np.float32),\\\\n+    ]\\\\n+    \\\\n+    for shape, dtype in test_cases:\\\\n+        try:\\\\n+            # Create test image\\\\n+            if len(shape) == 2:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            else:\\\\n+                image = np.random.randint(0, 256, shape).astype(dtype)\\\\n+            \\\\n+            # Apply pyrUp\\\\n+            result = cv2.pyrUp(image)\\\\n+            \\\\n+            # Check result dimensions\\\\n+            expected_h = image.shape[0] * 2\\\\n+            expected_w = image.shape[1] * 2\\\\n+            \\\\n+            if result.shape[0] == expected_h and result.shape[1] == expected_w:\\\\n+                print(f\\\\\"  \\\\u2713 {shape} -> {result.shape} (dtype: {dtype.__name__})\\\\\")\\\\n+            else:\\\\n+                print(f\\\\\"  \\\\u2717 {shape} -> {result.shape} (expected: {expected_h}x{expected_w})\\\\\")\\\\n+                return False\\\\n+                \\\\n+        except Exception as e:\\\\n+            print(f\\\\\"  \\\\u2717 Failed for {shape} ({dtype.__name__}): {e}\\\\\")\\\\n+            return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+def test_pyrUp_with_custom_size():\\\\n+    \\\\\"\\\\\"\\\\\"Test pyrUp with custom destination size\\\\\"\\\\\"\\\\\"\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\nTesting pyrUp with custom destination size...\\\\\")\\\\n+    \\\\n+    image = np.ones((100, 100, 3), dtype=np.uint8) * 128\\\\n+    \\\\n+    try:\\\\n+        # Test with valid custom size\\\\n+        custom_size = (150, 150)\\\\n+        result = cv2.pyrUp(image, dstsize=custom_size)\\\\n+        \\\\n+        if result.shape[:2] == custom_size:\\\\n+            print(f\\\\\"  \\\\u2713 Custom size {custom_size} works\\\\\")\\\\n+        else:\\\\n+            print(f\\\\\"  \\\\u2717 Custom size failed: got {result.shape[:2]}, expected {custom_size}\\\\\")\\\\n+            return False\\\\n+            \\\\n+        # Test with oversized custom size (should fail)\\\\n+        huge_size = (100000, 100000)  # This should trigger the bounds check\\\\n+        try:\\\\n+            result = cv2.pyrUp(image, dstsize=huge_size)\\\\n+            print(f\\\\\"  \\\\u2717 Huge size {huge_size} should have failed but didn\\'t\\\\\")\\\\n+            return False\\\\n+        except cv2.error:\\\\n+            print(f\\\\\"  \\\\u2713 Huge size {huge_size} correctly rejected\\\\\")\\\\n+            \\\\n+    except Exception as e:\\\\n+        print(f\\\\\"  \\\\u2717 Unexpected error: {e}\\\\\")\\\\n+        return False\\\\n+    \\\\n+    return True\\\\n+\\\\n+if __name__ == \\\\\"__main__\\\\\":\\\\n+    print(\\\\\"OpenCV pyrUp Memory Overflow Fix Test\\\\\")\\\\n+    print(\\\\\"=\\\\\" * 50)\\\\n+    \\\\n+    # Test 1: Check that the overflow protection works\\\\n+    success1 = test_pyrUp_overflow_fix()\\\\n+    \\\\n+    # Test 2: Check that normal usage still works\\\\n+    success2 = test_pyrUp_normal_usage()\\\\n+    \\\\n+    # Test 3: Check custom size handling\\\\n+    success3 = test_pyrUp_with_custom_size()\\\\n+    \\\\n+    print(\\\\\"\\\\\\\\n\\\\\" + \\\\\"=\\\\\" * 50)\\\\n+    if success1 and success2 and success3:\\\\n+        print(\\\\\"\\\\u2713 All tests passed! The fix is working correctly.\\\\\")\\\\n+        sys.exit(0)\\\\n+    else:\\\\n+        print(\\\\\"\\\\u2717 Some tests failed.\\\\\")\\\\n+        sys.exit(1)\\\\ndiff --git a/test_pyrUp_overflow.cpp b/test_pyrUp_overflow.cpp\\\\nnew file mode 100644\\\\nindex 000000000000..30c3eb572ba8\\\\n--- /dev/null\\\\n+++ b/test_pyrUp_overflow.cpp\\\\n@@ -0,0 +1,55 @@\\\\n+#include <opencv2/opencv.hpp>\\\\n+#include <iostream>\\\\n+#include <chrono>\\\\n+\\\\n+using namespace cv;\\\\n+using namespace std;\\\\n+\\\\n+int main() {\\\\n+    try {\\\\n+        // Create a small test image\\\\n+        Mat image(100, 100, CV_8UC3, Scalar(128, 128, 128));\\\\n+        \\\\n+        cout << \\\\\"Starting pyrUp sequence test...\\\\\" << endl;\\\\n+        cout << \\\\\"Initial image size: \\\\\" << image.cols << \\\\\"x\\\\\" << image.rows << endl;\\\\n+        \\\\n+        Mat current = image.clone();\\\\n+        \\\\n+        // Keep calling pyrUp until memory overflow\\\\n+        for (int i = 0; i < 20; i++) {\\\\n+            auto start = chrono::high_resolution_clock::now();\\\\n+            \\\\n+            Mat next;\\\\n+            pyrUp(current, next);\\\\n+            \\\\n+            auto end = chrono::high_resolution_clock::now();\\\\n+            auto duration = chrono::duration_cast<chrono::milliseconds>(end - start);\\\\n+            \\\\n+            cout << \\\\\"Iteration \\\\\" << i+1 << \\\\\": \\\\\" \\\\n+                 << current.cols << \\\\\"x\\\\\" << current.rows \\\\n+                 << \\\\\" -> \\\\\" << next.cols << \\\\\"x\\\\\" << next.rows\\\\n+                 << \\\\\" (Memory: \\\\\" << (size_t)next.cols * next.rows * next.channels() << \\\\\" bytes)\\\\\"\\\\n+                 << \\\\\" (Time: \\\\\" << duration.count() << \\\\\"ms)\\\\\" << endl;\\\\n+            \\\\n+            current = next;\\\\n+            \\\\n+            // Stop if image gets too large (before crash)\\\\n+            if (current.cols > 25600 || current.rows > 25600) {\\\\n+                cout << \\\\\"Stopping before potential crash...\\\\\" << endl;\\\\n+                break;\\\\n+            }\\\\n+        }\\\\n+        \\\\n+        cout << \\\\\"Final image size: \\\\\" << current.cols << \\\\\"x\\\\\" << current.rows << endl;\\\\n+        cout << \\\\\"Test completed successfully!\\\\\" << endl;\\\\n+        \\\\n+    } catch (const cv::Exception& e) {\\\\n+        cout << \\\\\"OpenCV Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    } catch (const std::exception& e) {\\\\n+        cout << \\\\\"Standard Error: \\\\\" << e.what() << endl;\\\\n+        return -1;\\\\n+    }\\\\n+    \\\\n+    return 0;\\\\n+}\\\\n\",\\n  \"target_hunk\": \"@@ -1380,9 +1380,19 @@ void cv::pyrUp( InputArray _src, OutputArray _dst, const Size& _dsz, int borderT\\\\n     CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n                ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n \\\\n+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n  \"target_line\": {\\n    \"line_number\": 1383,\\n    \"content\": \"+    // Define maximum allowable image dimensions to prevent memory overflow\",\\n    \"type\": \"addition\",\\n    \"position_in_hunk\": 4\\n  },\\n  \"enhanced_context\": {\\n    \"function_signature\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\",\\n    \"full_function\": \"=== FILE: modules/imgproc/src/pyramids.cpp (cpp) ===\\\\n\\\\n=== COMPLETE DIFF CONTEXT ===\\\\n    L1380:      CV_OCL_RUN(_src.dims() <= 2 && _dst.isUMat(),\\\\n    L1381:                 ocl_pyrUp(_src, _dst, _dsz, borderType))\\\\n    L1382:  \\\\n>>> L1383: +    // Define maximum allowable image dimensions to prevent memory overflow\\\\n    L1384: +    const int MAX_IMAGE_SIZE = 32768; // 32K pixels per dimension\\\\n    L1385: +    const size_t MAX_TOTAL_PIXELS = static_cast<size_t>(1024) * 1024 * 1024; // 1 billion pixels max\\\\n    L1386:  \\\\n    L1387:      Mat src = _src.getMat();\\\\n    L1388:      Size dsz = _dsz.empty() ? Size(src.cols*2, src.rows*2) : _dsz;\\\\n    L1389: +    \\\\n    L1390: +    // Check for potential memory overflow before allocation\\\\n    L1391: +    if (dsz.width > MAX_IMAGE_SIZE || dsz.height > MAX_IMAGE_SIZE ||\\\\n    L1392: +        static_cast<size_t>(dsz.width) * dsz.height > MAX_TOTAL_PIXELS) {\\\\n    L1393: +        CV_Error(CV_StsNoMem, \\\\\"pyrUp: Destination image size is too large and may cause memory overflow\\\\\");\\\\n    L1394: +    }\\\\n    L1395: +    \\\\n    L1396:      _dst.create( dsz, src.type() );\\\\n    L1397:      Mat dst = _dst.getMat();\\\\n    L1398:      int depth = src.depth();\\\\n\\\\n=== TARGET LINE BEING REVIEWED ===\\\\nLine 4:     // Define maximum allowable image dimensions to prevent memory overflow\\\\n\\\\n=== CONTEXT SUMMARY ===\\\\nTotal lines of context extracted: 19\\\\nLanguage: cpp\"\\n  }\\n}<|im_end|>\\n<|im_start|>assistant\\ni think you can use `validateInputImageSize`\\r\\nlook\\r\\nhttps://github.com/opencv/opencv/blob/4c024c35fbc7f0610501e087a9ef20c336a75e2b/modules/imgcodecs/src/loadsave.cpp#L72-L81<|im_end|>\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: View the tokenized text directly\n",
    "space = tokenizer(\" \", add_special_tokens=False).input_ids[0]\n",
    "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "954e911f-e445-41fd-b4d8-b23eabc3542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA RTX A6000. Max memory = 47.413 GB.\n",
      "6.73 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "668d4513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.2\n",
      "Help on function __init__ in module UnslothSFTTrainer:\n",
      "\n",
      "__init__(self, model, args=None, data_collator=None, train_dataset=None, eval_dataset=None, processing_class=None, compute_loss_func=None, compute_metrics=None, callbacks=None, optimizer_cls_and_kwargs=None, preprocess_logits_for_metrics=None, peft_config=None, formatting_func=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In notebook\n",
    "import trl\n",
    "print(trl.__version__)\n",
    "help(trl.SFTTrainer.__init__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b7fa957-6a88-4d58-b419-763b1be17d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 10,282 | Num Epochs = 1 | Total steps = 643\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 16 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='643' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/643 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer_stats = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_code_review/unsloth_compiled_cache/UnslothSFTTrainer.py:53\u001b[39m, in \u001b[36mprepare_for_training_mode.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mfor_training\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.for_training()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m output = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Return inference mode\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mfor_inference\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_code_review/unsloth_env/lib/python3.12/site-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:325\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_code_review/unsloth_compiled_cache/UnslothSFTTrainer.py:1007\u001b[39m, in \u001b[36m_UnslothSFTTrainer.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1006\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maybe_activation_offload_context:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:83\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_code_review/unsloth_env/lib/python3.12/site-packages/accelerate/accelerator.py:2734\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2732\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2734\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_code_review/unsloth_env/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_code_review/unsloth_env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opencv_code_review/unsloth_env/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38997e7-4322-4be4-ae19-edd04e7cdab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519.3581 seconds used for training.\n",
      "8.66 minutes used for training.\n",
      "Peak reserved memory = 39.072 GB.\n",
      "Peak reserved memory for training = 32.342 GB.\n",
      "Peak reserved memory % of max memory = 82.408 %.\n",
      "Peak reserved memory for training % of max memory = 68.213 %.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad100f-b9f2-449d-8d4e-4b22d2fb6688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "- The patch is missing a test case.\n",
      "- The patch does not follow the naming convention for the test case (test_resize_interlinear)\n",
      "- The patch does not provide coverage for all possible interpolation methods\n",
      "\n",
      "Please fix these issues before merging.\n",
      "\n",
      "This is a critical issue that needs to be addressed before proceeding with the merge.\n",
      "\n",
      "Do not proceed with the merge until these issues have been resolved.\n",
      "\n",
      "The patch should include:\n",
      "- A test case named test_resize_interlinear\n",
      "- Coverage for all possible interpolation methods (INTER_NEAREST, INTER_LINEAR, INTER_CUBIC, INTER_LANCZOS4)\n",
      "\n",
      "Once these issues have been addressed, you can proceed with the merge. \n",
      "\n",
      "Remember to follow the guidelines for OpenCV code review and ensure that the changes meet the project's standards.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Enable fast inference\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Convert chat message to direct prompt format\n",
    "prompt = \"\"\"You are an expert OpenCV code reviewer. Review this change:\n",
    "\n",
    "File: modules/imgproc/src/resize.cpp\n",
    "@@ -100,7 +100,7 @@\n",
    " cv::Mat src, dst;\n",
    "-cv::resize(src, dst, cv::Size(100,100));\n",
    "+cv::resize(src, dst, cv::Size(100,100), CV_INTER_LINEAR);\n",
    "\n",
    "Review:\"\"\"\n",
    "\n",
    "# Tokenize directly without chat template\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=True\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Set up text streamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "# Generate with optimized parameters for code review\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=256,        # Increased for detailed review\n",
    "    use_cache=True,\n",
    "    temperature=0.3,           # Much lower for code accuracy\n",
    "    top_p=0.9,                # Better than min_p for code\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa623fb-0223-40be-810a-ca065c20f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It looks like there was a mistake in the `resize` function call in the given code snippet. The third argument should specify the interpolation method if you want to explicitly set it. Here is the corrected version with the explicit interpolation method specified:\n",
      "\n",
      "```cpp\n",
      "cv::Mat src, dst;\n",
      "-cv::resize(src, dst, cv::Size(100, 100));\n",
      "+cv::resize(src, dst, cv::Size(100, 100), 0.0, 0.0, cv::INTER_LINEAR);\n",
      "```\n",
      "\n",
      "Alternatively, if the intention is to maintain backward compatibility or\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":\n",
    "     \"You are an expert OpenCV code reviewer. Review this change:\\n\\n\"\n",
    "     \"File: modules/imgproc/src/resize.cpp\\n\"\n",
    "     \"@@ -100,7 +100,7 @@\\n\"\n",
    "     \" cv::Mat src, dst;\\n\"\n",
    "     \"-cv::resize(src, dst, cv::Size(100,100));\\n\"\n",
    "     \"+cv::resize(src, dst, cv::Size(100,100), CV_INTER_LINEAR);\\n\"}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ccbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ac4fd-45ad-4dd4-951f-2acea293fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"lora_model\")  # Local saving\n",
    "# tokenizer.save_pretrained(\"lora_model\")\n",
    "model.push_to_hub(\"nareshmlx/code-reviewer-opencv\", token = HF_TOKEN) # Online saving\n",
    "tokenizer.push_to_hub(\"nareshmlx/code-reviewer-opencv\", token = HF_TOKEN) # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a9b3b-9725-427a-97e9-cad34a2dd54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary\n",
      "The provided patch increases the value of each pixel in a grayscale image (represented as a `Mat` object) to its double. This is achieved using nested loops iterating over each pixel position `(i, j)` and modifying the pixel value directly via `img.at<uchar>(i, j) = img.at<uchar>(i, j) * 2`.\n",
      "\n",
      "Here is the complete context around line 120 of `modules/core/src/arithm.cpp`, formatted with diff markers to show only the affected lines:\n",
      "\n",
      "```diff\n",
      "     int kx, ky;\n",
      " } ArithmContext;\n",
      "\n",
      "@@ -93\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\":\n",
    "     \"You are an expert OpenCV code reviewer. Review this change:\\n\\n\"\n",
    "     \"File: modules/core/src/arithm.cpp\\n\"\n",
    "     \"@@ -120,7 +120,11 @@\\n\"\n",
    "     \" for (int i = 0; i < img.rows; i++) {\\n\"\n",
    "     \"     for (int j = 0; j < img.cols; j++) {\\n\"\n",
    "     \"         img.at<uchar>(i,j) = img.at<uchar>(i,j) * 2;\\n\"\n",
    "     \"     }\\n\"\n",
    "     \" }\\n\"}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98d85a-908f-4744-b9fd-88f320a535b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
